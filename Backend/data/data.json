[
    {
        "url": "https://www.youtube.com/watch?v=tYrdMjVXyNg",
        "title": "Ben Shapiro vs Destiny Debate: Politics, Jan 6, Israel, Ukraine & Wokeism | Lex Fridman Podcast #410",
        "chapters": [
            {
                "title": "Introduction",
                "statements": "[00:00:00][Destiny][Something has to happen with Iran. There has to be some diplomatic bilateral communication there.].[00:00:04][Ben Shapiro][No. What has to happen is the containment of Iran.].[00:00:06][Destiny][History moves in one direction.].[00:00:07][Ben Shapiro][Why?].[00:00:09][Destiny][Because of time.].[00:00:10][Ben Shapiro][Communism, Nazism, all of that was a regression from what was happening at, for example, the beginning of the 19th century into the 20th century.].[00:00:16][Destiny][In what way?].[00:00:17][Ben Shapiro][Do you think that today Donald Trump knows that he lost the election?].[00:00:20][Destiny][Absolutely.].[00:00:21][Ben Shapiro][I don't.].[00:00:22][Destiny][This is one of the areas where we get into this, I don't understand if there's brain-breaking happening or what's going on. I don't know what world we can ever live in where we say that Trump is less divisive for the country than Biden.].[00:00:33][Ben Shapiro][Joe Biden literally used the Occupational Safety and Hazard Administration to try to cram down vax mandates on 80 million Americans. That's insane.].[00:00:41][Destiny][What about supercalifragilisticexpialidocious?].[00:00:43][Ben Shapiro][What about pneumonoultramicroscopicsilicovolcanoconiosis?].[00:00:45][Destiny][Yeah, or the science terms.].[00:00:45][Ben Shapiro][Yeah, exactly.].[00:00:46][Destiny][Or what about the 7,000 letter thing that's from part of a biochem.].[00:00:49][Lex Fridman][I got my education in the Soviet Union. So we just did math. We didn't run any of this.].[00:00:53][Ben Shapiro][That's why you're a useful person.].[00:00:54][Lex Fridman][Does body count matter? The following is a debate between Ben Shapiro and Destiny. Each arguably representing the right and left of American politics respectively. They are two of the most influential and skilled political debaters in the world. This debate has been a long time coming for many years. It's about 2.5 hours and we could have easily gone for many more. And I'm sure we will. It is only round one. This is the Lex Fridman Podcast to support it. Please check out our sponsors in the description. And now, dear friends, here's Ben Shapiro and Destiny.]."
            },
            {
                "title": "Liberalism vs Conservatism",
                "statements": "[00:01:36][Lex Fridman][Ben, you're conservative. Destiny, you're a liberal. Can you each describe what key values underpin your philosophy on politics and maybe life in the context of this left to right political spectrum? You want to go first?].[00:01:50][Destiny][Yeah. So I think that we have a huge country full of a lot of people, a lot of individual talents, capabilities, and I think that the goal of government, broadly speaking, should be to try to ensure that everybody is able to achieve as much as possible. So on a liberal level, that usually means some people might need a little bit of a boost when it comes to things like education. They might need a little bit of a boost when it comes to providing certain necessities like housing or food or clothing. But broadly speaking, I mean, I'm still a liberal, not a communist or a socialist. I don't believe in the total command economy, total communist takeover of all of the economy, but I think that broadly speaking, the government should kick in and help people when they need it.].[00:02:32][Lex Fridman][And that government can and should be big?].[00:02:34][Destiny][Not necessarily. I noticed that when liberals talk about government, especially taxes, it seems like they talk about it for taxes sake or bigness sake. So people talk about taxes sometimes as like a punishment, like tax the rich. I think taxing the rich is fine insofar as it funds the programs that we want to fund. But Democrats have a really big problem demonizing success or wealth. And I don't think that's a bad thing. I don't think it's a bad thing to be wealthy, to be a billionaire or whatever, as long as we're funding what we need to fund.].[00:03:03][Lex Fridman][Ben, what do you think it means to be a conservative? What's the philosophy that underlies your political view?].[00:03:07][Ben Shapiro][So first of all, I'm glad that Destiny, you're already coming out as a Republican. That's exciting. I mean, we hold a lot in common in terms of the basic idea that people ought to have as much opportunity as possible and also insofar as the government should do the minimum amount necessary to interfere in people's lives in order to pursue certain functions, particularly at the local level.].[00:03:33][Ben Shapiro][So a lot of governmental discussions on a pragmatic level end up being discussions about where government ought to be involved, but also at what level government ought to be involved. And I have an incredibly subsidiary view of government. I think that local governments, because you have higher levels of homogeneity and consent are capable of doing more things. And as you abstract up the chain, it becomes more and more impractical and more and more divisive to do more things.].[00:03:59][Ben Shapiro][In my view, government is basically there to preserve certain key liberties. Those key liberties pre-exist the government insofar as they're more important than what priorities the government has. The job of government is to maintain, for example, national defense, protection of property rights, protection of religious freedom. These are the key focuses of government as generally expressed in the Bill of Rights and the Constitution. And I agree with the general philosophy of the Bill of Rights and the Constitution.].[00:04:31][Ben Shapiro][Now, that doesn't mean by the way, that you can't do more on a governmental level again as you get closer to the ground, which by the way is also embedded in the Constitution. People forget the Constitution was originally applied to the federal government, not to local and state government. But if I were going to define conservatism, it would actually be a little broader than that because I think to understand how people interact with government, you have to go to core values.].[00:04:50][Ben Shapiro][And so for me, there are a couple of premises. One, human beings have a nature. That nature is neither good nor bad. We have aspects of goodness and we have aspects of badness. Human beings are sinful. We have temptations. What that means is that we have to be careful not to incentivize the bad and that we should incentivize the good. Human beings do have agency and are capable of making decisions in the vast majority of circumstances. And it's better for society if we act as though they do.].[00:05:17][Ben Shapiro][Second, the basic idea of human nature. There is an idea in my view that all human beings have equal value before the law. I'm a religious person, so I'd say equal value before God. But I think that's also sort of a key tenet of Western civilization being non-religious or religious, that every individual has equivalent value in sort of cosmic terms.].[00:05:36][Ben Shapiro][But that does not necessarily mean that every person is equally equipped to do everything equally well. And so it is not the job of government to rectify every imbalance of life. The quest for cosmic justice, as Thomas Sowell suggests, is something that government is generally incapable of doing, and more often than not, botches and makes things worse. So those are a few key tenets and that tends to materialize in a variety of ways. The easiest way to sum that up would the traditional kind of three legs of the conservative stool, although now obviously there's a very fragmented conservative movement in the United States would be a socially conservative view in which family is the chief institution of society, like the little platoons of society as Edmund Burke suggested, in which free markets and property rights are extraordinarily valuable and necessary because every individual has the ability to be creative with their property and to freely alienate that property.].[00:06:34][Ben Shapiro][Finally, I tend toward a hawkish foreign policy that suggests that the world is not filled with wonderful people who all agree with us and think like us. And those people will pursue adversarial interests if we do not protect our own interests.].[00:06:46][Destiny][Can I ask a question on that? I'm so curious.].[00:06:47][Lex Fridman][Okay.]."
            },
            {
                "title": "Education",
                "statements": "[00:06:49][Destiny][I'm excited for this conversation because I consider you to be really intelligent, but I feel like sometimes there are ways that conservatives talk about certain issues that seem to defy logic and reason, I guess. And I'm sure you feel the same way about... Well, I feel the same way about progressives, but even some liberals for sure. Before I ask this question, it's going to relate to education. We can agree broadly speaking that statistics are real and that not everybody could do everything. So for a grounded example, my life was pretty bad. I got into streaming and I turned my life around and that was really cool. But I can't expect everybody to do what I did. Right? Like everybody being able to join the NBA or to be like a streamer.].[00:07:27][Ben Shapiro][Of course, everybody has different qualities. Sure.].[00:07:29][Destiny][Okay. So I used to be a lot more libertarian when I was 20, 21. And one of the things that dramatically changed my view on government, manipulation of things in the, I guess, in society when it came time to deal with my son and the school that he went to. And one of the things that I noticed was when time to send my son to school, I could either do private education or I could do public.].[00:07:51][Destiny][Personally, I did 12 years of Catholic private education. However, the public schools in Nebraska, depending on where you lived, were very, very, very good. I opted for a certain district, I bought a house there, I moved there, and then my son was able to go to those schools. And he's been going through those schools and the difference of availability of technology, these kids are taking home iPads in first grade. They've got huge computer labs and everything. Do you think that there is some type of, I don't want to say injustice or unfairness because not even looking at it that way, just pragmatically that there might be children that are in certain schools that if they just had better funding or more access to technologies or things available to them, that those kids would become more productive members of society that would like a little bit of a help that they could actually achieve more and do better for all of society?].[00:08:39][Ben Shapiro][So I think that on the list of priorities when it comes to education, the availability of technology is actually fairly low on the list of priorities.].[00:08:46][Destiny][Sure. The two things I've heard are food availability, and I think air conditioning I think are the two biggest ones that I hear, but sure.].[00:08:51][Ben Shapiro][Well, I mean the biggest thing in terms of education itself, not just the physical facilities that we're talking about, would actually be two parent family households.].[00:08:59][Destiny][Sure.].[00:09:00][Ben Shapiro][Communities that have fathers in them. It's actually the number one decisive according to Roland Friar and many studies done on this particular topic. And the idea that money alone, that investment of resources is the top priority in schooling is belied by the fact that LAUSD, which is where I went to school when I was younger, they pour an enormous amount of money into LAUSD. We're talking about tens of thousands of dollars very often per student, and it does not result in better schooling outcomes.].[00:09:25][Ben Shapiro][So when you say, if we could give every kid an iPad, would you give every kid an iPad? The question is not, if I had a replicator machine from Star Trek, would I give everybody an enormous amount of stuff? Sure, I would. Every resource is fine. It every resource is limited, and you have to prioritize what are the outcomes that you seek in terms of the means with which you are seeking them.].[00:09:47][Ben Shapiro][And so, again, I think that the question is... I quibble with the premise of the question, which is that, again, the chief injustice when it comes to education on the list of injustices is lack of availability to technology or that it's a funding problem. I just don't think that's the case.].[00:10:02][Destiny][Sure. And I can half agree with you there, but I don't think any amount of changes in the schools will create two parent households. We can't bring a-].[00:10:10][Ben Shapiro][I totally agree with you. That's why I think that the fundamental educational problem is not in fact a schooling problem. I think that it preexist that.].[00:10:17][Destiny][Sure. Now, I feel like this is kind of the conservative merry-go-round where it's like, what can we do to help with schools? So two of the things that I've seen I think that are usually brought up in research is one is air conditioning that children in hotter environments just don't learn as well. And then the second one is access to food. So kids that are given a breakfast or a lunch that's provided at school increases educational outcomes.].[00:10:38][Destiny][Now, I agree that neither of these things might be determinative in, well, 20% of kids were graduating and now 80% of kids are graduating. Or these kids are all going with their GEDs into the workforce, and now these kids are all suddenly becoming engineers. But in terms of where we can help, do you think there should be some minimum threshold or minimum baseline of... At the very least, every school should have a non-leaky gym or every school should have... If children can't afford lunch or breakfast like some sort of food provided or every school should have these baseline things?].[00:11:07][Ben Shapiro][So again, I'm going to quibble with the premise of the question because I think that when it comes to, for example, food insecurity, school food programs... Again, you can always pour money into any program and at the margins create change. I mean, there's no doubt that pouring money onto anything will create change in a marginal way. The question is how large is the margin and how big is the movement? So the delta is what I'm looking at.].[00:11:28][Ben Shapiro][I think that you're starting at a second order question, which is what if we ignore what I would think are the big primary questions of education, namely family structure, value of education at home. How much you have parents who are capable or willing to help with homework? What are the incentive structures we can set up for a society that actually facilitate that? How local communities take ownership of their schools is a big one, right?].[00:11:48][Ben Shapiro][All of these issues we're ignoring in favor of, say, \u201cAir conditioning or lunch programs.\u201d And so in a vacuum, if you say air conditioning and lunch programs sounds great in a vacuum. In terms of prioritization of values and cost structure, are those the things that I think are going to move the needle in a major way in terms of public policy? I do not. And in fact, I think that many of them end up being disproportionate wastes of money. I've talked before pretty controversially about the fact that an enormous amount of school lunch programs are thrown out.].[00:12:17][Ben Shapiro][An enormous amount of that food ends up in the garbage can. Is there a better way to do that? If there is a better way to do it, then I'm perfectly willing to hear about that better way to do it. But it seems to me that one of the big flaws in the way that many people of the left approach government is what if we hit every gnat with a hammer? And my question is, what if the gnat isn't even the problem? What if there is a much bigger substructure problem that needs to be solved in order to... If you're shifting deck chairs on the Titanic, sure, you can make the Titanic slightly more balanced because the deck chairs are slightly better oriented. But the real question is the water that's gaping into the Titanic, right?].[00:12:50][Destiny][Yeah. And I agree with you 100%, but again, I feel like we're on the conservative merry-go-round then of never wanting to address-].[00:12:57][Ben Shapiro][That's not a conservative merry-go-round. I can give you 10 ways.].[00:12:59][Destiny][Well, sure. So here would be the merry-go-round. I would say that there is a minimum funding for schools that I think would help children, and then we go, \u201cWell, the thing that would help them the most is two parent household.\u201d Then they go, \u201cOkay. Well, two parent households actually aren't the problem. The issue is access to things like birth controls that people don't have children early on.\u201d And it's like, \u201cBut the issue isn't actually birth control, the issue is actually you need a certain amount of money to move out early and to get married and then to have a two-parent household.\u201d So it's actually like economic opportunity.].[00:13:21][Ben Shapiro][No.].[00:13:22][Destiny][Well, it's not...].[00:13:23][Ben Shapiro][Just two parent households. That's it.].[00:13:24][Destiny][But what are the pre-cursor-].[00:13:26][Ben Shapiro][Don't fuck people before you're married and have babies.].[00:13:27][Destiny][Sure.].[00:13:27][Ben Shapiro][Done.].[00:13:28][Destiny][That's great. We can say that and try to fight against however many hundreds of thousands of years of human evolution, but people will have sex and people will make babies.].[00:13:34][Ben Shapiro][And then they used to get married. The vast majority of people in this country with kids used to be married. The vast majority of people with kids in this country now are not married increasingly.].[00:13:44][Destiny][But a lot of those-].[00:13:44][Ben Shapiro][It's obviously a societal change. Something changed. It wasn't human evolution.].[00:13:46][Destiny][But a lot of those things in terms of resting on whether or not people get married, have to do with financial decisions. Do you have the money?].[00:13:52][Ben Shapiro][People are worse off now than they were 50, 60 years ago when the marriage rates were higher.].[00:13:54][Destiny][People are delaying the start of their careers because education is going to be increasingly important.].[00:13:58][Ben Shapiro][So in other words, people are richer now and they have more education now, and yet they're having more babies out of wedlock now because they're richer and have more education?].[00:14:05][Destiny][I'm saying that one of the biggest indicators for whether or not somebody is willing to get married is how much money both people are making if they can move out of their household. People don't tend to want to get married at 22 when they've just finished college, when they don't have the money to move out and they can't afford a house.].[00:14:16][Ben Shapiro][Because we have changed the moral status of marriage in the culture. Meaning that everyone poor, rich and in between used to get married. By the way, a huge percentage of marriages in the United States used to be what they would call shotgun marriages, meaning that somebody knocked somebody up and because they did not want the baby to be born outside of a two-parent household, they would then get married.].[00:14:32][Destiny][Do we think that shotgun marriages though are a way to bring back equilibrium to education?].[00:14:37][Ben Shapiro][Yes, absolutely. Yes, 100%. A child deserves a mother and a father because that is the basis for all of this, including education.].[00:14:44][Destiny][Do we think that shotgun marriages are... Well, let's say this. Do we think that that's a reasonable direction that society would ever take? Or is this-].[00:14:51][Ben Shapiro][Yes. It was the reasonable direction for nearly all of modern history].[00:14:53][Destiny][Was, but history moves in one direction.].[00:14:55][Ben Shapiro][Why?].[00:14:56][Destiny][Because of time.].[00:14:57][Ben Shapiro][People don't think that's... In what ways?].[00:15:00][Destiny][I don't think we've ever regressed social standards back to like, \u201cOh, well, let's go a hundred years back and do things that used to exist before.\u201d].[00:15:06][Ben Shapiro][The entire left right now is arguing that we regressed social standards by rejecting Roe v. Wade. So that's obviously not true.].[00:15:11][Destiny][The Roe v. Wade is not a social standard. It's a supreme court ruling, number one. But number two, if you read the actual majority opinion on Roe v. Wade, we can see that socially we ever actually never made huge progress on how society viewed abortion. This has always been an incredibly divisive thing. Even that was, I think, part of Alitos writing on it was that things like gay marriage, for instance, we've kind of moved past, and it's not really as debated anymore, but abortion was never a subtle topic despite Rove v. Wade.].[00:15:33][Ben Shapiro][The notion of the the arc of history constantly moves in one direction is belied by nearly all of the 20th century.].[00:15:39][Destiny][What do we mean by that? [inaudible 00:15:42] women's rights? Civil rights?].[00:15:42][Ben Shapiro][Barbarism, communism, Nazism, all of that was a regression from what was happening at, for example, the beginning of the 19th century and the 20th century.].[00:15:49][Destiny][In what way?].[00:15:51][Ben Shapiro][Nazis and communism weren't a regression from what was going on in 1905?].[00:15:54][Destiny][Well, in terms of communism being a regression, for instance... I'm not Not a communist, but the industrialization of the Soviet Union happened under communist society, the industrialization-].[00:16:03][Ben Shapiro][Except murder of tens of millions of people.].[00:16:04][Destiny][Yeah. There's-].[00:16:07][Ben Shapiro][I consider that regression, a moral regression, which is what we are talking about now, moral regression. And you're suggesting that moral regression, I wouldn't term. I would term return two traditional values a moral regression. You would. But your suggestion is that history only moves in one direction, and I'm suggesting that history does not only move in one direction, it tends to move actually back and forth.].[00:16:22][Destiny][Sure. I don't think that all of history moves in one direction. There are going to be wars, there are going to be times of peace. I think in general, we're more peaceful now than we have been in the past, but I think when we look at the way that people live their lives, I think that we tend to move in a certain direction socially. So when it comes to things like racism or when it comes to things like slavery or women's rights, I think that there are two huge things that probably aren't changing in the US and one is access to contraception and one is women working jobs.].[00:16:45][Destiny][I think that these two things are probably huge things that are moving us off of shotgun marriages or getting married very early on, and I don't see... Do you think that those two things are going to change fundamentally?].[00:16:54][Ben Shapiro][First of all, what the data tend to show is that actually more highly educated people, as you are saying, tend to get married more. So the idea is that women getting an education somehow throws them off marriage. It's the opposite. Usually it's women who are not educated-].[00:17:06][Destiny][But those women aren't getting shotgun marriages. Those women aren't having children.].[00:17:09][Ben Shapiro][But now you're shifting the topic. My topic was how to get more people married. And then you suggested that higher levels of education are delaying marriage and making it less probable. What I'm telling you, because this is what the data suggests, is that actually as you raise up the educational ladder, people tend to be married more than they are lower down on the educational ladder. If you're a high school graduate, you're less likely to be married than if you're a postdoc.].[00:17:33][Destiny][I agree with you, but that's because one of the biggest precursors to getting married is having a level of economic stability. So as people get more educated, they obtain this economic stability and then they're in a more comfortable position to explore more serious relationships.].[00:17:43][Ben Shapiro][There's another confound there. I mean, the confound is that people in stable marriages tend to be the children of stable marriages, and there's only one way to break that cycle, which is to create a stable marriage, and that is something that is in everyone's hands. Again, this notion that it is somehow an unbreakable, unshatterable barrier to get married and have kids, I don't understand where this is coming from. Why is that such a challenge? It's not a challenge.].[00:18:03][Destiny][I don't it's unbreakable or unshatterable. The initial point was for school, if we can provide a minimum level of educational stuff for children, that'd probably be good. But when we retreat back to, well, it has to be the families that are fixed first, fixing families is a multivariate problem that so many [inaudible 00:18:19]].[00:18:19][Ben Shapiro][I'm fine within my local community. Again, I've suggested that there's a difference between local community and federal. I'm fine with my local community voting for school lunches or air conditioning or whatever it is that we all agreed to do. Because the more local you get, the more homogeneity you get in terms of interest and the more interest you have in your neighbors. All of that is fine. I'm part of a very, very solid community. In our community, we give to each other. We have minimum standards of helping one another.].[00:18:41][Ben Shapiro][All that is wonderful. When it comes to the actual problem of education, what I object to in the political sphere, and this happens all the time, is everybody is arguing on top of the iceberg about how we can move the needle 0.5 percentage points as opposed to the entire iceberg melting beneath them. And we just ignore that and we pretend that that's just sort of the natural consequence of thing. The arc of history suggests that people are never going to get married again.].[00:19:04][Ben Shapiro][Well, I mean, actually what the arc of history suggests realistically speaking is that the people who are not getting married are not going to be having kids. And what it also suggests, the people who are married are going to be having kids. So the demographic profile actually over time is rather going to shift toward people who are having lots and lots of kids. I'm married, I have four kids. Everyone in my community is married. That's like minimum buy-in my community is four kids.].[00:19:24][Ben Shapiro][So what's happening actually in terms of demographics is that the people who are more religious and getting married are having more kids. And so if you're talking about the arc of history shifting toward marriage, I would suggest that actually demographically over time, long periods of time, not over one generation, over long periods of time, the only cure for low birth rate is going to be the people who get married and have lots of kids.].[00:19:42][Destiny][I don't necessarily disagree with any of that, but I'm just saying that, again, on the... I know you're upset when I bring up the term merry-go-round. I think that there are good conversations to be had about people getting married because stable families produce stable children that are less likely to commit crime, that are more likely to go to school, that are more likely to be productive members of society, et cetera, et cetera.].[00:19:58][Destiny][I'm not going to disagree with you on any of that. All of that is true. It's just frustrating that sometimes when you bring up any problem, all of it will circle back to other things that makes it seem like we can't make any progress in any area without fixing something [inaudible 00:20:10]].[00:20:10][Ben Shapiro][In what way? I literally just told you that on the local level, I'm fine for people voting for [inaudible 00:20:13]].[00:20:13][Destiny][For instance, on the local level. So for school funding, school funding is done, I think generally per district. So what do you do when you have poor districts that can't afford air conditioner for their schools?].[00:20:23][Ben Shapiro][I mean, the idea there would be that presumably if the society, meaning the state, and I generally don't mean the federal state. I mean the state of California, for example, decides that everybody ought to have air conditioning. People will vote for air conditioning, and that's perfectly legal. I don't think there's anything morally objectionable about that per se.].[00:20:40][Destiny][Cool.].[00:20:40][Ben Shapiro][I also don't think that that's going to heal anything remotely like the central problem.].[00:20:43][Destiny][Sure. I agree.].[00:20:43][Ben Shapiro][And I think that what tends to happen in terms of government is people love arguing about the problems that can be solved by opening a wallet. And nobody likes to solve a problem by closing their sex life to one person, for example, or having kids within a stable religious community. The things that actually build society... I'm fine with arguing about each of these policies and whether we apply them or not is a matter generally of pragmatism, not morality.].[00:21:10][Ben Shapiro][It's a matter of incentive structures, not per se morality, because incentive structures do have moral underpinnings. There's such a thing as... For example, if you're going to use a welfare program, you have to decide how effective it is to what crowd. It applies where the cutoffs are. Does it disincentivize work, does it not? All of these are pragmatic concerns. But on a moral level, the generalized objection that I have to people on the left side of the aisle is that they like to focus... In these conversations very often it feels as though it's a conversation with people who are drunk, searching under the lamp for their keys. The problems they want to look at are the problems that are solvable by government, and then all the problems they don't want to look at, which are the actual giant monsters lurking in the dark and not particularly solvable by government are the ones they want to ignore and assume are just the natural state of things. And I don't think that's correct at all.].[00:21:54][Destiny][And I 1 billion percent agree. But then obviously my criticism for the conservative side is the exact opposite where there are parts where government could remedy some issues. For instance, children having sex with each other and producing other children out of wedlock. Sometimes having afterschool programs is nice to prevent that. I didn't have time for these things. When I was in school, I was doing football practice, I was doing cross country practice. I went in early for a band. I agree with you that sometimes people only focus on one end of the problem as I hate to be that guy, but as somebody that... Have you ever watched The Wire?].[00:22:21][Ben Shapiro][Sure.].[00:22:22][Destiny][I'm not going to cite The Wire as a real life example, but obviously there's only so much you can do in a school when the children coming in are so beyond destroyed because of the family life and everything prior to them even getting to school that day. So I agree. Government is not like the solution to broken families. That would never be the case.].[00:22:36][Ben Shapiro][And it's actually not the solution to education depending on the kind of solutions that you're talking about. Some solutions, yes. Some solutions, no.].[00:22:43][Destiny][Yeah. The only thing I'm looking at is, as I said earlier, just these minimum threshold things where it's like, where can government make... Because you mentioned marginal, which I think is a really good way to look at things. Marginal costs and marginal utility to things where the first thousand dollars per student you spend might give you a huge return, but the extra 20,000 after is just a waste.].[00:22:59][Ben Shapiro][I think these are all pragmatic discussions.].[00:23:00][Destiny][Sure, of course.].[00:23:00][Ben Shapiro][And actually, this is what we used to hash out in legislatures before they turned into platforms for people grandstanding. But yes, sure.].[00:23:05][Destiny][Okay.]."
            },
            {
                "title": "Trump vs Biden",
                "statements": "[00:23:06][Lex Fridman][As we descend from the heavens of philosophical discussion of conservatism and liberalism, let's go to the pragmatic muck of politics. Trump versus Biden. Between the two of them, who was in their first term, the better president? And thus who should win if the two of them are, in fact, our choices should win a second term in 2024. Ben?].[00:23:30][Ben Shapiro][Sure. So in terms of actual job performance, you have to separate it into a few categories. In terms of actual performance informed policy, I think Trump's foreign policy record is significantly better than Biden's, the world being on fire right now, being a fairly good example of that. And we can get into each aspect of the world being on fire and where the incentive structures came from and how all of that happened in a moment.].[00:23:53][Ben Shapiro][When it comes to the economy, I think that Trump's economic record was better than Biden's. Doesn't mean he didn't overspend. He did. He wildly overspent. But he also had a very solid record of job creation. A huge percentage of the gains in the economy went to people on the lower end of the economic spectrum. Actually, the gross income to the average American was about $6,000 during his term. The unemployment rates were very, very low before COVID.].[00:24:18][Ben Shapiro][I think that you almost have to separate the Trump administration into sort of before COVID and during COVID, because COVID obviously is a black swan event, the most signal change in politics in our lifetime. And so governance during COVID is almost its own category, which we can discuss. But in terms of foreign policy, in terms of domestic policy, I think that Trump was significantly better than Biden has been. And that's on the upside for Trump.].[00:24:40][Ben Shapiro][On the downside, for Biden, obviously you're talking 40 or highs in inflation. You're talking about savings being eaten away. You're talking about everything being 20 to 30% more expensive. You're talking about massive increases to the deficit, even at a rate that was unknown under Trump. The deficit under Trump raised by about a little under a trillion dollars every year up until 2020. Again, 2020 was COVID year, so everybody decided that we're going to fire hose money at things.].[00:25:01][Ben Shapiro][But then Joe Biden continued to fire hose money at things in '21, '22, and '23. That obviously is, in my opinion, bad economic policy. And then you get to the rhetoric, and you get to the stuff that Donald Trump says. As I've said before, my view is that on Donald Trump's epitaph, on his gravestone, it will say, \u201cDonald Trump. He's said a lot of shit.\u201d I think that Donald Trump does say a lot of things. I think that that is basically baked into the cake, which is why everyone who's bewildered by the polls is ignoring human nature, which is at the beginning when you see something very shocking, it's very shocking.].[00:25:33][Ben Shapiro][And then if you see it over and over and over, and over for years on end, it is no longer shocking. It's just part of the background noise like tinnitus. It just becomes something that your brain adjusts for. And so do I like a lot of Donald Trump's rhetoric? No, and I never have. Do I think that that is dispositive as to his presidency? No, I do not. When it comes to Biden, again, I think he's underperforming economically. I think that his foreign policy has been really a problem.].[00:25:57][Ben Shapiro][Even the things I think he's done right are, I think, band- aids for things that he created by doing wrong. And when it comes to his own rhetoric, you can argue that it's grading on a curve because Trump was coming in with such wild rhetoric that just a maintenance of that wild rhetoric doesn't really change again the baseline. For Biden, he came in the same way that Obama did on the soaring rhetoric of American unity.].[00:26:20][Ben Shapiro][Trump came in and he is like, \u201cListen, I'm the president for what I am, and I'm going to say the things I want to say. I'm beyond the toilet and I'm tweeting.\u201d We're like, \u201cOkay, that's what it is.\u201d With Biden, he came in with, \u201cI'm a president for all Americans. I'm trying to unify everybody.\u201d And that pretty quickly broke down into a lot of oppositional language about his political opponents in particular, an attempt to lump in, for example, huge swaths of the conservative movement with the people who participated, for example, in January 6th, or who were fans of January 6th, and the sort of lumping in of everybody into MAGA Republicans who wasn't personally signed on to an infrastructure bill with him.].[00:26:56][Ben Shapiro][That sort of stuff I think has been truly terrible. I thought his Philadelphia speech was truly terrible. And again, I think that you do have the problem of he is no longer capable of certainly rhetorically unifying the country when every speech from him feels like watching Nik Wallenda walk across a volcano on a tightrope. It really is like you're just sort of waiting for him to fall.].[00:27:16][Ben Shapiro][I mean, it's sad to say. I mean, the other day he was speaking for what was, in effect, his campaign kickoff, and this was in Valley Forge. I mean, Jill rushed up there. As soon as he was done, Jill rushed up there like she'd been shot out of a cannon to come and try and guide him away so he didn't become the Shane Gillis Roomba. And that's not really... Let's put it this way. It does not quiet the soul to watch Joe Biden rhetorically. Again, that's a different problem than Trump's problem, but that's my analysis.].[00:27:47][Destiny][This is one of the areas where we get into this, I don't understand if there's brain-breaking happening or what's going on. I don't know what world we can ever live in where we say that Trump is less divisive for the country than Biden. I think it is so patently obvious. Trump is so divisive. Not only does Trump make an enemy out of every person in the opposition party, he makes an enemy out of his own party and every single person around him. We all watched him bully Jeff Sessions. We all watched him bully his own party on Twitter. We all watched all of these people walk away from him.].[00:28:18][Destiny][Even recently, I think the Secretary of Defense Esper and John Kelly, the chief of staff were saying, \u201cI think Trump is a threat to democracy.\u201d You've got all of his prior people that were around him, some of his closest allies. You've got Bill Barr that won't co-sign a single thing that he says. You've got all these people that he used to work with that all say, \u201cTrump is a horrible, evil person. He's ineffective as a leader. He doesn't accomplish anything.\u201d And he didn't.].[00:28:43][Destiny][To say that Biden has failed at bipartisanship when we've gotten the CHIPS Act, we've gotten the IRA, we've gotten the ARP, we've gotten the Bipartisan Infrastructure bill, when we've gotten all this major legislation that is working in this historically divided Congress as opposed to Trump that got us tax cuts and deficit spending. I don't understand where we ever are in this world where Biden is somehow-].[00:29:00][Destiny][I don't understand where we ever are in this world where Biden is somehow more divisive than Trump. Even the speeches that Ben is bringing up, they always bring up... I remember that one. I think we might've even done it on our episode. The one speech that Biden gave where at one point that the background is red and probably-].[00:29:17][Ben Shapiro][[inaudible 00:29:17] speech I referenced.].[00:29:17][Destiny][... Yeah. And they're like, \u201cOh my God, it's over. This is the end.\u201d And then meanwhile, you've got Donald Trump coming into office saying things like, \u201cIf you burn the flag, you should have your citizenship revoked\u201d or talking about MSDNC, that I'm going to investigate every single one of these media organizations for corruptness. I'm going to open the libel and defamation laws. I'm going to take all of these guys to court. You've got this weird Project 2025 stuff where is it John Paschal, I think, is talking about we're going to investigate all of these people and we're going to try to throw crimes at all these people.].[00:29:48][Destiny][Trump is like the most divisive president I think we've ever had, at least in my lifetime of being an American citizen. And the rhetoric from him is just, it's on a whole other level in terms of the demonization of political opponents. I mean, this is a guy that's known for giving his political opponents bad nicknames, right? That's what Trump does.].[00:30:08][Destiny][It's funny, but even as a resident of Florida, if Florida had another natural disaster, do you think Trump would withhold aid because you had... I think that was one of the few nice things that DeSantis actually said about Biden was that like, \u201cHey, listen, when the buildings collapsed in I think was Miami Beach.\u201d].[00:30:24][Ben Shapiro][Surfside. Yeah.].[00:30:24][Destiny][Yeah, that for the hurricane stuff, that Biden was there. He was saying, \u201cIf you guys need aid, however many billions, you can have it.\u201d Meanwhile, Trump, I think, was threatening to withhold federal funding from blue states that wouldn't... I think it had to do with the National Guard stuff, the deployment of the National Guard, that they weren't doing enough for the riots and Trump was threatening to withhold aid from some of these blue states. Yeah, Trump is literally the most divisive person in the world. I don't see how on any metric he has ever succeeding in the divisive category.].[00:30:52][Destiny][In terms of the economy. I do think it's funny that Republicans are very keen to say that, \u201cWell, we can't really grade Trump post-COVID\u201d because obviously, COVID messed everything up, which is fair. But pre-COVID, what did Trump do? He did deficit spending tax cuts. He presided over historical low interest rates and an economy that was already like blazing past the final years of Obama. We were posting all time highs in all the stock markets in 2013 onwards. Unemployment rates were falling. Now under Biden, unemployment rates are even lower than they were under Trump. But it sucks that for Trump, we can say, \u201cWell, we can't really hold him accountable for 2020. That was COVID.\u201d].[00:31:25][Destiny][Well, all we have for Biden is post-COVID. We don't have any pre-COVID Biden economy. And it was the same thing for Obama too, coming in right after the housing collapse as well. And it sucks that Republicans are able to walk out of office having burned the entire American society to the ground economically. And now, we've got to try to evaluate, \u201cOkay, well, what did Obama do during his first two to three to four years just trying to recover from where the housing crash left it.\u201d And then we look at Biden now who's trying to recover from COVID and now we're grading him on a totally different scale than what Trump is being graded on. Yeah, that sucks, I think. We can go into-].[00:31:58][Lex Fridman][Can you comment on the foreign policy policy?].[00:32:00][Destiny][On the foreign policy, I'm going to be honest, I am very liberal. I'm very not progressive. I'll probably come off as more hawkish than others because I'm not a big fan of this, which also, I mean, if Ben agrees, I think people like Trump are going to be the most dovish, isolationist people ever. They don't want to do anything internationally. They just want to protect America, be at home, protect our economy, don't do anything internationally, which is why he was constantly undermining NATO and constantly attacking all of the European Union and cheering on the UK for Brexiting away from the EU.].[00:32:34][Destiny][I think that being said, I think that Biden has done a phenomenal job when it comes to foreign policy. I think that the coalition building was so important for Ukraine, Russia, and I'm so happy that he decided to go to our European allies and our NATO allies and try to build a coalition of people to help Ukraine, so that that wasn't only the United States.].[00:32:53][Destiny][Personally, especially after doing a whole bunch of research, I do tend to side with Israel over Palestine in a lot of the Israeli-Palestinian conflicts. I'm glad that Biden, while remaining a staunch defender of Israel, is trying to rein in some of the more aggressive posturing towards the Palestinians and the Gaza Strip. I'm proud that Biden said, \u201cHey, listen, we are going to delay some of these attacks. Hey, listen, we are going to allow humanitarian aid here. Hey, listen, we are going to try to not kill as many Palestinian people down there\u201d while still signaling that he would be a staunch supporter of Israel in the conflict, assuming the civilian casualties don't go too high.].[00:33:29][Destiny][For foreign policy, I mean, blemishes, I mean, the biggest one you can give to Biden is Afghanistan and the pull-out there. But man, are we going to talk about the Inspector General report that says that one of the biggest reasons why the Afghanistan pull-out was so disastrous was because of the Doha Accords where Donald Trump headed talks that didn't even include the Afghanistan army. I mean, these were disasters. When Biden took office, we had 2,500 troops left in Afghanistan. What was the options even afforded to Biden at that point?].[00:33:59][Destiny][Obviously, you've got the abandonment of the Kurds in Northern Syria for the Turkish armies to lay waste to. You're talking about Iran and North Korea, although I'm not sure where Ben would land on those, but yeah, that's a broadly [inaudible 00:34:11].].[00:34:11][Lex Fridman][That's a lot from both, right? You want to pick at something where you disagree with here?].[00:34:14][Ben Shapiro][Well, I mean, there's a lot. So I want to ask a few questions on each one of these.].[00:34:19][Destiny][Yeah, sure.].[00:34:20][Ben Shapiro][So let's talk about divisiveness for a second. So there's no one who can make the case that Donald Trump is not divisive. Yeah, of course, he's incredibly divisive. It's a given. Do you treat Biden's rhetoric with the same level of seriousness that you treat Trump's rhetoric, or I should probably put that the other way around. Should we treat Trump's rhetoric with the same level of seriousness as Joe Biden or, say, Barack Obama's rhetoric?].[00:34:43][Destiny][I'm going to try to be concise when I say this. Broadly speaking, especially in studying Israel, Palestine and Ukraine, Russia, I try not to take politicians at their word because sometimes, they just say stuff to say stuff. I understand that. But broadly speaking, I'm going to look at the rhetoric and the actions and I am going to grade them the same. So yes, I would hold Biden and Trump to the same standard.].[00:35:00][Ben Shapiro][Right, so my feeling is, and this is one area where for clarification, we're going to have a division, is that I of course don't treat Trump's rhetoric in the same way that I treat Biden's or Obama's. He's utterly uncalibrated and he says whatever he wants to at any given time and it doesn't even match up with his policy very often.].[00:35:14][Destiny][Can I ask you, for our head of state, our chief executive, shouldn't rhetoric be arguably one of the most important things that he does?].[00:35:23][Ben Shapiro][The answer would be yes. And now, I've been given a choice between a person who I think in calibrated ways says things that are divisive and a person who in uncalibrated ways says things that are divisive. And so the evidence that Joe Biden is divisive is every poll taken since essentially August of 2021. He is, by all available metrics, incredibly divisive. A huge percentage of Americans are deeply unhappy not only with his performance, but don't believe he's a uniter. That's just the reality. And that may just be a reflection. I mean, honestly, we may be putting too much on Trump or Biden personally. It may just be that the American people themselves are rhetorically divided because of social media, and social media can, in fact, be assessable and [inaudible 00:36:02].].[00:36:02][Destiny][One thing that I would ask you about that, though...].[00:36:05][Ben Shapiro][Sure.].[00:36:05][Destiny][... is I agree, especially when you look at the favorability, but sometimes, when I look at these polls, when you start to disaggregate them by party, I wonder if it's actually is Biden historically divisive or I'm trying to think of a really polite way to say this. The people that like Trump worship Trump. I don't know. One of the most prescient things that Trump could have probably ever said was that I could kill someone on Fifth Street and nobody would hold him accountable. So is it really that Biden's historically divisive, or is it that every single Trump supporter will always say that Trump is great [inaudible 00:36:32].].[00:36:31][Ben Shapiro][No, the reason I would say that Biden is, in fact, historically divisive is because Republicans felt much more strongly about Barack Obama than Joe Biden, actually.].[00:36:40][Destiny][I agree. But they didn't feel as strongly about Trump as they did about Romney or McCain. Right?].[00:36:44][Ben Shapiro][In what way? I mean-].[00:36:45][Destiny][The allegiance to Trump.].[00:36:47][Ben Shapiro][... oh, no, there's certainly more allegiance to Trump than there is to Romney or McCain, largely because Trump won in 2016. But beyond that, the point that I'm making is that if you're looking at the stats in terms of divisiveness, Republicans always find the Democratic president divisive. The question is where the rest of the country is. And right now, there are a lot of Democrats who either don't agree with Biden or find him divisive. There are a lot of independents who find them divisive.].[00:37:08][Ben Shapiro][So when we're comparing these things, I don't think they're leagues apart in terms of the divisive effects of what they say, right? And I'm separating that off from the inherent content of what they say because obviously, what Trump says is more divisive just on the raw level. I mean, if he's insulting people as opposed to Joe Biden doing MAGA Republicans, if I were to just... if I were an alien come down from space and look at these two statements, I'd say this one's more divisive than this one. But then, there's the reality of being a human being in the world and that is everyone has baked Donald Trump into the cake. And Joe Biden, again, started off with a patina of being non-divisive and now has emerged as divisive.].[00:37:42][Ben Shapiro][If you don't mind, I actually want to get to the foreign policy questions because this one is actually slightly less interesting to me.].[00:37:45][Destiny][Sure. Can I ask just one quick thing, I guess.].[00:37:48][Ben Shapiro][[inaudible 00:37:48], go for it.].[00:37:48][Destiny][We can say the reality of it and we can look at opinion polls. What if we look at legislative accomplishments? Like Biden is working on a 50-50 divided Senate. Donald Trump had both House of Congress and the Supreme Court and got no major legislation passed.].[00:38:01][Ben Shapiro][Well, I mean, he did lose Congress in 2018.].[00:38:05][Destiny][But prior to that, we got the Infrastructure bill, I think, in one year, which Trump promised for his entire presidency, didn't get anywhere on it.].[00:38:12][Ben Shapiro][I mean, yes, his Republican base was not in favor of mass spending on infrastructure and neither am I. So there's that. I think that's mostly a state and local issue.].[00:38:18][Destiny][But they were in favor of mass spending for tax cuts?].[00:38:21][Ben Shapiro][That's not a spending. It-].[00:38:21][Destiny][I mean, effectively it is, right?].[00:38:24][Ben Shapiro][Effectively, it's not.].[00:38:25][Destiny][If you're cutting tax receipts, but you're not changing the level of spending like Biden did with the IRA.].[00:38:30][Ben Shapiro][Again, we have a fundamental philosophical difference here. I think that when the government takes my money, that is not the government somehow being more fiscally responsible, and when the government allows me to keep my money, I don't see that as the government spending. I see that as my money and the government is taking less of it.].[00:38:45][Destiny][That's great, but at the end of the day, the government is still going to be in a deficit spending and they're going to have to borrow money from the Treasury.].[00:38:49][Ben Shapiro][Right, we have a spending problem, in other words, not a receipts problem is the case that I'm making.].[00:38:52][Destiny][Right.].[00:38:52][Ben Shapiro][The problem with Donald Trump is not that he lowered taxes. The United States has one of the most progressive tax systems on the planet, and in fact, if you wish to have a European style social welfare state, what you actually need is to tax the middle class to death, the reality is that the top 20% of the American population pays literally all net taxes in the United States after state benefits and all of this.].[00:39:09][Destiny][Sure.].[00:39:09][Ben Shapiro][So if you actually wanted to have the kind of social welfare state that many liberals seem to want to have like Northern Europe, for example, you'd actually have to tax people who make 40, 50, $60,000.].[00:39:19][Destiny][And I don't want that. I agree with that, but how do you explain the lack of legislation, I mean, if he's such a uniter.].[00:39:24][Ben Shapiro][Because I think the Republican party itself is quite divided, and I think that Trump can-].[00:39:27][Destiny][But isn't that his job? He's the head of the Republican Party. He's the president, Republican President of the United States.].[00:39:31][Ben Shapiro][I mean, again, I don't think that Joe Biden has passed wildly historic legislation, other than-].[00:39:36][Destiny][The infrastructure bill was the largest [inaudible 00:39:38].].[00:39:38][Ben Shapiro][So here's the problem. If you're a Republican, the only bills that you can get consensus on tend to be bills that either... let's be real about this, that are tax cuts because as you would, I think, agree with. When it comes to polling data, Americans constantly say they want to cut the government and then the minute you ask them which program, they have no idea what they're...].[00:39:57][Destiny][Right.].[00:39:57][Ben Shapiro][... right, exactly. And so it's much harder to come up with a bill to cut things than it is to come up with a bill to add things, which is why spending was out of control under Trump as well. But there are some Republicans who still don't want to spend on those things, right? So inherently, the task that, this goes back to the first question, the task that Republicans think government is there to do is different than the task that Democrats think that government is there to do. So the way that the very metric of success for a Democratic president versus Republican president, namely, for example, pieces of legislation passed. As a Republican, one of my goals is to pass nearly no legislation because I don't actually want the government involved in more areas of our life.].[00:40:32][Ben Shapiro][I want to ask a couple of questions on the foreign policy. Sure.].[00:40:35][Destiny][Yeah. Okay, wait, real quick, just so for instance, Donald Trump wanted to punish China and he wanted to bring microprocessor manufacturing to the United States. Biden did that with legislation with the CHIPS Act. You talk about spending being out of control, and I mean, I can agree with that. I think anybody that looks at the numbers has to agree with that. But why not pass legislation like the Inflation Reduction Act, which is at least spending neutral, right? Why are there not bills where Donald Trump could take-].[00:40:57][Ben Shapiro][Well, first of all, I think that whenever the government says something is spending neutral, it rarely materializes that way. That is not going to be a spending neutral bill. [inaudible 00:41:02].].[00:41:01][Destiny][Sure, but there's difference between at least they say it's spending neutral versus this is a $500 billion bill over 10 years.].[00:41:07][Ben Shapiro][Well, but again, I don't see a tax cut as a matter of spending neutrality. The big problem is they keep spending, not that they are allowing me to keep the money that I earned and they did not earn, but [inaudible 00:41:16].].[00:41:15][Destiny][Okay. So then just to understand, so if somebody just did massive reductions in tax receipts, so tax cut after tax cut after tax cut, but they didn't change spending at all, you wouldn't consider that an increase in deficit spending or out of control spending. You would just say they're just tax cuts?].[00:41:29][Ben Shapiro][No, the opposite. I would consider it a wild overspending, meaning-].[00:41:34][Destiny][Okay. So then was it under Trump then when he did the tax [inaudible 00:41:36]?].[00:41:36][Ben Shapiro][... I mean, the deficit spending, by the way, under Biden is way worse than it was under Trump.].[00:41:39][Destiny][Of course, but we're in post-COVID, right?].[00:41:41][Ben Shapiro][COVID ended effectively... I mean, you live in Florida. COVID effectively ended in the state of Florida by the middle of 2021.].[00:41:46][Destiny][Yeah [inaudible 00:41:47].].[00:41:47][Ben Shapiro][Even if you're a vaccine fan, by April, May of 2021, there was wide availability of vaccines, whether or not you like the vaccines, and at that point, we were done. [inaudible 00:41:55].].[00:41:55][Destiny][I agree. But we're in a post... how many trillions of dollars have been dumped in worldwide that are leading to inflation, right? The inflation is a worldwide issue right now because of the economy shutting down for a year or two. It's not like those effects are gone in one year, right? COVID might be gone, but the after effects of all the stimulus spending and the unemployment and everything else.].[00:42:11][Ben Shapiro][The definition of inflation is too much money chasing too few goods. So pouring more money on top of that makes for more inflation. That's what it does.].[00:42:17][Destiny][Sure. I agree. But there's also the definition of when do you deficit spend is when economies are headed for recessions, right, rather than when economies are doing really well that we're under Trump and he was deficit spending, whereas Biden can at least make the argument that I ought to be deficit spending because the economy is heading for potential recession.].[00:42:31][Ben Shapiro][So here's the thing. I don't think that the economy was actually headed for a recession. In fact, if you look at the economics statistics-].[00:42:37][Destiny][And every economist said it was.].[00:42:38][Ben Shapiro][... no, [inaudible 00:42:39].].[00:42:39][Destiny][They're still saying that there's a recession coming, right?].[00:42:41][Ben Shapiro][But that was largely because of the after effects of inflation, meaning if you inflate the economy, what you are going to end up doing is bursting a bubble and then when that bubble bursts, you'll get a recession. I mean, that was the basic idea, right? The idea, the question was whether you're going to get a soft landing. But if you actually look at, for example, the employment statistics or the economic growth statistics in the United States, what they look like under the last year's Obama and then Trump, I mean, this is what the chart looks like. Because it looks like this and then it hits March of 2020. It goes like that, right, and then by September, it bounces back up, right? It's a V-shaped recovery, and then it starts to peter out.].[00:43:09][Destiny][Sure. A lot because of the American Recovery Plan, right, that Biden did as well.].[00:43:13][Ben Shapiro][I mean-].[00:43:13][Destiny][4 million jobs. Yeah.].[00:43:14][Ben Shapiro][... no, I'm not going to attribute it to that because the rates of growth in job growth from September, October, November were actually very similar to the rates of job growth after Joe Biden took office. What you see is actually kind of a straight line. I mean, what the chart looks like-].[00:43:15][Lex Fridman][Let's get on.].[00:43:27][Ben Shapiro][In any case, okay, on the foreign policy stuff, this is getting abstruse.]."
            },
            {
                "title": "Foreign policy",
                "statements": "[00:43:31][Destiny][[inaudible 00:43:31].].[00:43:30][Ben Shapiro][But on the foreign policy stuff, so the questions that I have with regard to Biden on foreign policy, very, very simple question. Do you think that the situation in the Middle East is better now than it was under Donald Trump?].[00:43:51][Destiny][Probably. That's a hard one.].[00:43:54][Ben Shapiro][Why?].[00:43:55][Destiny][The factors that I'm making right now are obviously you've got the Israel- Palestinian War that's going on right now, which is kind of bad, but broadly speaking, I'm not sure how much that affects the Middle East as much as the collapse of Syria. 2013 Syrian Civil War sent millions of immigrants throughout all of Europe-].[00:44:12][Ben Shapiro][Which was under...].[00:44:13][Destiny][... which was under Obama and continued under Trump.].[00:44:13][Ben Shapiro][Right.].[00:44:15][Destiny][Trump didn't do anything to alleviate any of the Syrian Civil War. [inaudible 00:44:18].].[00:44:18][Ben Shapiro][Why did Syria end up as a preserve of Russia again?].[00:44:22][Destiny][How did Syria end up as a preserve of Russia?].[00:44:24][Ben Shapiro][Yes. Why did it end up being essentially a client state of Russia?].[00:44:28][Destiny][I know that Putin enjoys access to the ports down there. I don't know. You tell me.].[00:44:32][Ben Shapiro][I mean, the reason is because Barack Obama suggested that there was a red line that would be drawn in the face of chemical weapons used.].[00:44:36][Destiny][Sure.].[00:44:36][Ben Shapiro][Bashir Assad then used chemical weapons in Syria, and Barack Obama was unwilling to then essentially create consequences for Syria in the form of any sort of Western strike and so instead, he outsourced it to Russia. This is 2013, 2014.].[00:44:49][Destiny][Sure. Do you think there might've been some hesitancy after seeing how Libya ended up that maybe us intervening [inaudible 00:44:55].].[00:44:54][Ben Shapiro][Who's president during Libya? Yeah. I mean, [inaudible 00:44:57].].[00:44:59][Destiny][But what does that have to do with anything, though? I'm just saying there might've been a mistake learned.].[00:45:01][Ben Shapiro][The point that I'm making is that actually the Middle East, I mean just historically speaking, was historically good under Donald Trump. I mean, it's very difficult to make the case that either before or after Trump were better than during Donald Trump.].[00:45:10][Destiny][Was it? I don't think that Trump contributed to the Syrian situation improving much. He wrecked a lot of-].[00:45:18][Ben Shapiro][I mean, he wrecked ISIS. He did wreck ISIS, which was in the [inaudible 00:45:20].].[00:45:19][Destiny][I mean, ISIS had been getting wrecked by the Kurds in Iraq, by every single person, by Assad's army, by Putin, by Turkey.].[00:45:26][Ben Shapiro][[inaudible 00:45:26].].[00:45:26][Destiny][Literally, everybody was fighting against ISIS at that point.].[00:45:29][Ben Shapiro][There's a spike in violence and then the Trump... I mean, you get credit for when you're president, presumably. I mean, things got better with ISIS under Trump.].[00:45:36][Destiny][I mean, yeah, they did. I mean-].[00:45:37][Ben Shapiro][Things got worse with ISIS under Obama.].[00:45:40][Destiny][... for sure.].[00:45:40][Ben Shapiro][He called them the JV squad, and then they became not the JV squad.].[00:45:44][Destiny][But I don't know if ISIS is originating in Syria and Baghdadi and all of the growth of that is necessarily Obama's fault. I know that we like to say that Obama created ISIS. I don't know if you say that, but I've heard that saying a lot. I think that's a little bit simplistic. I don't think that when I'm looking at actions that presidents have taken, the biggest criticism I have for Middle Eastern policy is I think the Doha accords were a disaster and I think that's one of the biggest blemishes that we have right now. I would also argue that moving the embassy to Jerusalem was also kind of silly and arguably contributed to some of the conflict we see right now between [inaudible 00:46:16].].[00:46:16][Ben Shapiro][No, I'll argue precisely the opposite, especially given the fact that after the movement of the embassy to Jerusalem, the Abraham Accords continued to sign and actually expand and that if Donald Trump had been elected, I have no doubt in my mind that Saudi Arabia would now be a part of the Abraham Accords. In fact, that was basically pre-negotiated and then when Joe Biden took office, Joe Biden took a very anti-Saudi stance on a wide variety of issues. The biggest single effect in the Middle East of Joe Biden's presidency, and again, I agree with you that not every foreign policy issue can be laid at the hands of a president. Joe Biden's main approach to the Middle East was very similar to the Obama approach, which is why the Middle East was chaotic under Obama and chaotic under Biden and that was to alienate allies like Saudi Arabia and Israel and instead, to try to make common cause or cut deals with Iran.].[00:47:00][Ben Shapiro][What that did is incentivize terrorism from Iran. What we're watching in the Middle East is Iran attempting to use every one of its terror proxies in the Middle East and it was specifically launched in an attempt to avoid what Biden actually was trying to do, which was good, which was after two years of failure with Saudi Arabia, try to bring them into the Abraham Accords, right? That was what was burgeoning at the end of last year and Iran saw that and Iran decided that they were going to throw grenade into the middle of those negotiations by essentially activating Hamas. Hamas activates. Hamas commits October 7th. Israel, as a sovereign nation state, has to respond to the murder of 1,200 of its citizens in the taking, kidnapping of 240. Israel has to do that not only to go after its own hostages and try to restore them, but also to reestablish military deterrence in the most violent region of the world.].[00:47:40][Ben Shapiro][Hezbollah gets active on Israel's northern border. Hezbollah is an Iranian proxy. They get active on the northern border. The Houthis in Yemen get active. The only reason all this is happening at the same time is because Iran is doing this, right?].[00:47:53][Destiny][[inaudible 00:47:53].].[00:47:53][Ben Shapiro][Not just that, they're threatening global shipping.].[00:47:56][Destiny][Sure.].[00:47:56][Ben Shapiro][If you're talking about the effects of global supply lines, which I totally agree, had a major inflationary effect on the economy, thanks to COVID. Right now, the cost of shipping is nearly double what it was just a few weeks ago and that is because a ragtag group of Houthi barbarians are attacking international shipping and forcing everybody to stop using the Bab-el-Mandeb freight, instead of going around the Cape of Good Hope in Africa.].[00:48:17][Destiny][Sure.].[00:48:18][Ben Shapiro][All of that is the result of the fact that Joe Biden reoriented the United States in the very early days in favor of a more pro-Iranian stance. He appointed Robert Malley to negotiate the Iran deal who, as it turns out, was using proxies. Many of his aides were actually taking money from Iran. The Biden administration, literally one of their first acts was to delist the Houthis as a terror organization and sanctions against the Houthis. These are all moves that Biden made very early on. They were disastrous moves. But when it comes to domestic policy, I think he hasn't been nearly as damaging in domestic policy as-].[00:48:18][Destiny][Wait, wait. Domestic policy. Let's do...].[00:48:18][Ben Shapiro][Foreign policy.].[00:48:47][Destiny][... sure, sure. So just on a couple of Middle Eastern things. So one of the big things that threw the Middle East into disaster was what we all traumatized by it now was the Iraq invasion [inaudible 00:48:56] Republican president.].[00:48:56][Ben Shapiro][Sure.].[00:48:57][Destiny][You hear that, right?].[00:48:57][Ben Shapiro][Sure.].[00:48:58][Destiny][The deposition of Saddam Hussein and everything that followed after probably contributed more to the growth of ISIS and the destabilization of that entire region probably more than anything else. I think that prior to Bush for Clinton and even at the beginning of Bush's presidency, we were on some kind of road to normalcy with Iran, which I think has to happen whether we liked them or not until Bush, for whatever reason, decides to throw Iran into the Axis of Evil.].[00:49:21][Ben Shapiro][You emphasized that we're on a road to normalcy with Iran in the 1990s.].[00:49:23][Destiny][We do in the... wait, what?].[00:49:25][Ben Shapiro][That we are on a road to normalcy with Iran in the 1990s.].[00:49:27][Destiny][My understanding is that, yeah, from the late '90s and prior to the Axis of Evil labeling of Iran, that there was going to be some path forward to where we could start to normalize relationships with them.].[00:49:36][Ben Shapiro][I find that very difficult to believe, and I don't see a lot of evidence. I mean, we can just disagree on that.].[00:49:41][Destiny][Sure, okay, yeah, sure. We can disagree on that, but I know that once I [inaudible 00:49:43].].[00:49:43][Ben Shapiro][By the way, the after effects, just a quick note, the after effect of the Iraq War that was the most devastating was the increase in power of Iran.].[00:49:48][Destiny][I agree, yeah, because of the destabilization of Iraq and Iraq not having a government there that was functional for at least a decade.].[00:49:55][Ben Shapiro][And was, in fact, a Sunni government, right? Originally, it was a Sunni government. The Sunni army was one of the worst things that the Bush administration did.].[00:50:01][Destiny][Banning all the former Ba'ath party [inaudible 00:50:03].].[00:50:02][Ben Shapiro][Sectarian, yeah.].[00:50:03][Destiny][All horrible under a Republican president.].[00:50:06][Ben Shapiro][Don't disagree.].[00:50:07][Destiny][That that probably contributed more to ISIS, to the growth of power in Iran, maybe even to the destabilization of Syria, probably more than anything that Obama did. Also, when we look at Iran funding people in the region, I don't disagree with that as well. I think Iran is the number one instigator of bad-guy things right now in the Middle East. Iran, the IRGC I supported when Donald Trump killed Soleimani. I think that was a great thing. I think that Iran is a major problem.].[00:50:30][Destiny][However, I don't know if the path forward is constantly being a belligerent to Iran or trying to figure out some road to normalcy. I don't know if the collapse of Iran or the destruction of that country, considering how unpopular the Ayatollah even is there. The citizens of Iran, I don't think, are big supporters of the government there. I feel like moving on a path where, let's do our nuclear inspections. We had that Iranian nuclear deal that Trump pulled out of. Let's do the nuclear inspections. Make sure you're not on the way to nuclear weapons. Let's unfree some funds. Let's move in some direction where we get on a good term with you. I feel like that's the most important thing that needs to happen in the Middle East. As much as people like to look at the Abraham Accords, who cares if... what was it? Bahrain, I think Oman. I think [inaudible 00:51:10].].[00:51:10][Ben Shapiro][UAE, Morocco.].[00:51:10][Destiny][The UAE and Morocco... like all of these people, even Saudi Arabia already have like de facto normalization with Israel anyway. They're all trading [inaudible 00:51:18].].[00:51:17][Ben Shapiro][No, I mean, to pretend that anybody even 15 years ago would've been talking about normalization between Saudi Arabia and Israel is insane. I mean, that's insane.].[00:51:26][Destiny][They were already on that path. They were already de facto trading partners with each other. They had already been collaborating [inaudible 00:51:34].].[00:51:33][Ben Shapiro][That's a wild claim that Israel and Saudi Arabia were going to normalize 15 years ago?].[00:51:38][Destiny][15 years ago might've been a wild claim, but after Turkey, after Jordan, and then in the past 20 years of economic relations and ties with each other, all of the leadership in the Middle East and you'll agree with this. Look at Israel. Then they go, okay, well, we've got Palestinians who God bless them, do nothing, and then you've got Israel, which is on a region with no natural resources to somehow become an economic giant. They're good to trade with their population's educated. They have military power. All of the leadership in these Middle Eastern countries are wanting to be friendly with Israel and are engaging in trade de facto with Israel and the idea that the UAE and Bahrain were brought in to say like, oh, well, now we're going to officially say this.].[00:52:15][Ben Shapiro][Those were the first steps toward obviously the formation of a new Middle East in which economics would predominate over sectarian conflict. The chief obstacle to that is Iran. I agree. The notion that negotiations with the Ayatollah, were going to be a solution to any of this is, but do we think Absolutely. The night,].[00:52:32][Destiny][Is it the Abraham Accords that's convincing Saudi Arabia to take a stance against Iran?].[00:52:37][Ben Shapiro][No. I mean, they're].[00:52:39][Destiny][Already fighting. They're already fighting with each other. Right. I don't think the Abraham Accords moved us any closer towards any type of real peace in the region. It has to happen is something has to happen with Iran. There has to be some diplomatic bilateral communication there.].[00:52:49][Ben Shapiro][No. What has to happen is the containment of Iran, which was what was taking place with the increased normalization with the Sunni Arab world and Israel combined with significant economic sanctions. The notion that there's this far-fetched notion in foreign policy circles that diplomacy can sort of be wish cast out of thin air. That if you sit around a table that you can always come to an agreement with somebody. The Ayatollahs do not have common interests with the United States. They do not, and this idea that they're willing to take money in exchange, for example, some sort of peaceful acquiescence to Israel's existence is obviously untrue, literally,].[00:53:23][Destiny][Historically. Hasn't that been the case though, that you've had a region with tons of sectarian violence for a long time, and then finally Turkey was like, you know what? This isn't worth it. The United States paid them a lot of money. They had conversations with Israel, and you know what? The economy, the economic gains, same thing with Jordan. Same thing with].[00:53:40][Ben Shapiro][Turkish politics, but the situation with Turkey was actually quite warm between Israel and Turkey in the nineties when you had the sort of secular Muslim regime].[00:53:52][Destiny][In the nineties, but they signed].[00:53:53][Ben Shapiro][Out of Turk in place, and now Erdogan has joined in the fray. Erdogan is significantly more radical than].[00:53:59][Destiny][What came before. Sure. I'm so sorry if I said Turga in Egypt, my].[00:54:02][Ben Shapiro][Bad. Egypt].[00:54:05][Destiny][In terms of Egypt and Jordan, right, we're the first two you].[00:54:08][Ben Shapiro][Need big, so here's the thing. Is it possible that you could theoretically come to a deal with Iran only with a new leadership crew? Okay. This is true for every peace agreement in the region. You could not, Israel could not have made peace with. Well, they].[00:54:20][Destiny][Made peace with Egypt, and Sadat was the leader for Yom Kippur.].[00:54:23][Ben Shapiro][They did not make peace with Nasser. Right. The point is that this is a different regime. You need a different regime,].[00:54:28][Destiny][But I'm saying the same regime that part of the Yom, Kippur war was the same regime that negotiated peace with Israel.].[00:54:34][Ben Shapiro][I mean, that's true. It is also true that that is a relationship that could be cultivated specifically because it was Sadat who made clear he was going to come to the table. Have the Iranians ever made clear that they would come to the table over, for example, the existence of the state of Israel?].[00:54:48][Destiny][No.].[00:54:50][Ben Shapiro][That is not a thing that's going to happen, but].[00:54:51][Destiny][I think people probably thought the same.].[00:54:53][Ben Shapiro][Every single one of their proxy rules, every one of them not only calls for the destruction of the state of Israel, they also call for the destruction of America. I mean, this is literally the Houthi slogan. They're busy hitting ships, and their slogan is literally Ahu Akbar, death to America, death to the Jews, death to Israel. It doesn't fit on a bumper sticker, but it's not all like catchy, but that is in fact their slogan. The notion that the regime that propagates that is going to be approached with diplomacy is not only wrong, the problem is that it's easy to say the stakes of diplomacy are okay, so we try to talk jaw-jaw is better than war-war. Sure. The only problem is that in the Middle East, weakness is taken as a sign that aggression might be an appropriate response. That is how things work in the Middle East, and the fact that Barack, that Joe Biden rather came into office with an orientation toward continuing the Obama policies in Iran has led to conflagrations these sort of brushfires breaking out everywhere that Iran has borders with either the West or Israel or both. Right. Any place that's happening, it's leading to Brushfires because again, the logic of violence in the Middle East is not quite the logic of violence in other places in the world. By the way, I think the logic of violence in the Middle East is actually closer to what most international politics looks like than we wish that it were. I mean, I think that's part of what's happening in Ukraine as well, which brings me, by the way, here's my question about Ukraine. Well, just real quick-].[00:56:13][Destiny][So you think that for Iran, right, a country that has been sanctioned for God knows how many years now, you think that for Iran just continuing to sanction them and contain them is an effective way, is more effective than trying to engage them in bilateral or multilateral peace talks?].[00:56:26][Ben Shapiro][Yes, 100% and the proof is in the pudding.]."
            },
            {
                "title": "Israel-Palestine",
                "statements": "[00:56:28][Lex Fridman][Before we go to Ukraine, can I ask about Israel? So you're both mostly in agreement, but what is Israel?].[00:56:34][Destiny][I don't know if I'd say that.].[00:56:35][Lex Fridman][Okay, but as I'm learning what is Israel doing right? What is Israel doing wrong in this very specific current war in Gaza?].[00:56:47][Ben Shapiro][I mean, frankly, I think that what Israel's doing wrong is if I were Israel, again, America's interests are not coincident with Israel's interests. If I were an Israeli leader, I would've swiveled up and I would've knocked the bleep out of Hezbollah early. What does that mean mean? What does that mean? So I would have Yoav Galant, who is the defense minister of Israel, was encouraging Netanyahu, who's the prime minister and the war cabinet, including Benny Gantz. People talk about the Netanyahu government. That's not what's in place right now. There's a unity war government in place that includes the political opposition. The reason I point that out is because there are a lot of people politically who will suggest that the actions Israel is currently taking are somehow the manifestation of a right-wing government. Israel currently does not have a quote, right-wing government, they have unity government that includes the opposition.].[00:57:27][Ben Shapiro][In any case, Yoav Galant was urging in the very early days of the war that Israel should turn North and instead of hitting Hamas, they should actually take the opportunity to knock Hezbollah out because Hezbollah is significantly more dangerous to the existence of the state of Israel than Hamas. I actually agree with that. As far as what Israel has been doing wrong in the actual war, I mean, I think that, again, from an American perspective, I think that Israel is doing pretty well from an Israeli perspective via Israeli. I would actually want Israel to be less loose about sending its soldiers in on the ground level. So Israel's attempting to minimize civilian casualties, and the cost of that has been the high.].[00:58:00][Ben Shapiro][... on the ground level. So Israel's attempting to minimize civilian casualties, and the cost of that has been the highest military death toll that Israel has had since the 1973 Yom Kippur War. I mean, I personally know, through one degree of separation, three separate people who have been killed in Gaza, and that's because they're going in door to door, it's because they're attempting to minimize civilian casualties and they're losing a lot of guys in this particular war. The problem that Israel has had historically speaking is that Israel got very complacent about its own security situation. They believed the technology was going to somehow correct for the hatred on the other side of the wall. That, okay, so our people have to live underground for two weeks at a time while some rockets fall, but at least it's not a war.].[00:58:40][Ben Shapiro][And that complacence bred what happened on October 7th. So to me, what Israel did wrong was years and years and years of complacence and belief in an Oslo System that is at root a failure because you cannot make a peace agreement with people who do not want to make peace with you. So that's what I think Israel is doing wrong. I have a feeling that there's going to be wide divergence on this point.].[00:59:02][Destiny][Maybe. So in terms of broadly speaking, I generally oppose settlement expansion is a thing that Israel does incorrectly that I think is kind of provocative to at least all the Palestinians in the West Bank, and it probably energizes hatred in the Gaza Strip for them as well. In terms of conducting warfare, the one thing that I always say to everybody, especially Americans, is you can't evaluate things from an American perspective. It's very stupid. It happened a lot with Ukraine where people are like, \u201cOh, well, they work with the Nazis?\u201d and \u201cWeren't the Soviets the good guys?\u201d And it's like, well, in other parts of the world, it's not quite as simple. And I think the same is true for Israel-Palestine, that a lot of Americans will analyze the conflict as just being one between only Israel and Palestine, which it's not, it's a conflict between Israel and then Palestine, Hezbollah, the Houthis, and Iran. Right now, it is.].[00:59:51][Destiny][However, one area where I'll break with, Ben, is I think that minimizing civilian casualties and everything is very, very, very important I think on the Israeli side. I don't think it's important so that the US will stay with them because I think the US is probably going to stick with Israel as long as they're not doing anything crazy, and I don't even think it matters for the international community. It definitely doesn't matter for the UN because Jesus Christ. However, I think it's really, really, really important that... I think that in the Middle East, broadly speaking, I think that leadership, especially in the Gulf, has gotten over the Palestinian issue.].[01:00:22][Destiny][I think that leadership is kind of like they don't care as much anymore, but the populations still care quite a bit. And I think that the main issue that Israel could run into is if the civilian death toll does climb too high, and if they start to hit this 40, 50, 60,000 number of civilian casualties, they run the risk of the civilian populations in the surrounding Middle Eastern states becoming so antagonistic towards Israel that they start to take steps back towards normalization in the region.].[01:00:47][Destiny][So for instance, I know that Bahrain, I think, already pulled out their ambassador to Israel. My guess is going to be it's temporary. I know that on the public speaking side, you've got a lot of people condemning Israel for the attacks. And on the private side, you've got people telling Israel, \u201cPlease kill all of Hamas because this is untenable and nobody wants to work in this situation.\u201d I don't know if this ended up being true or not. I'm guessing it didn't, but I saw on a couple of Twitter accounts, it was leaked that potentially, Saudi Arabia was considering installing a government in the West Bank that they would run.].[01:01:18][Ben Shapiro][No, I mean, I think Israel would love nothing better than that, but that is [inaudible 01:01:21].].[01:01:21][Destiny][For sure.].[01:01:22][Ben Shapiro][One of the big problems in the Middle East is literally no one wants to preside over the Palestinians. No one. In the Arab states, Israel, no one.].[01:01:29][Destiny][So I think the issue, and I'm largely actually, I'm very sympathetic towards the Palestinians because I think that since '48 and onwards, I think that all of the Arab states super gassed them up on that. They wanted the Palestinians to fight because they wanted to fight with Israel. However, as time has gone on and they've realized that it's kind of a lost cause, states have started to drop out. So you're getting these bilateral peace treaties with Egypt and with Jordan, you're getting multilateral agreements like the Abraham Accords, and now, the Palestinians are looking around. I'm like, \u201cOkay, well, you guys told us to fight all this time, and now, the only people that we have supporting us are Iranian proxies.\u201d So the Palestinians are in a very weird spot where they've lost all their support.].[01:02:06][Destiny][Yeah, I think that Israel, what I would say to be, quote, unquote, \u201ccritical\u201d of Israel is Israel needs to take strong steps towards peace that probably involves them enduring some undue hardship. So not the October 7th attacks, because Jesus, that's way too much, but other types of attacks that they might have to deal with that might cause some civilians to die that they don't come out over the top with and retaliate with if there's ever going to be peace in that region. However, another thing that I've always said is a huge problem between Israel and Palestine is I think that both sides think that if they continue to fight, it will be good for them. But the problem is one side is delusional. I think Israel wants to continue to fight because they get justifications for the annexation of the Golan Heights. They get justifications for expansions, especially in the Area C that, I think, they're probably going to try to annex soon. They get justifications for the increased military posturing towards the Gaza Strip and the embargoes.].[01:02:59][Destiny][And Israel is right that if the conflict continues, really, the situation only improves for Israel over time. But the Palestinians also all believe that if they keep fighting, they thought this since 2000 under Arafat, that if they just keep fighting, they'll get better gains too. But that's not the case.].[01:03:12][Lex Fridman][Is there a difference between Palestinian citizens and the leadership when you say that?].[01:03:16][Destiny][I love all people. I love all people around the world, and I think that when we analyze issues, I think that we have to be very honest with what the people on the ground think. And the idea that Hamas is just this one-off thing in the Gaza Strip is not only incorrect with the situation on the ground, it's also incredibly ahistorical. And the idea that the Palestinians in the West Bank, of which I believe the most recent polling shows, I want to say 75 to 80% support the October 7th attacks. Palestinians, in general, want to fight in violent conflict with Israel. That's not just the position of the government. That's not just people. There's a reason why Abbas doesn't want to do elections in the West Bank, and it's because the Palestinian people really do want to fight with Israel.].[01:03:57][Destiny][But to combat that problem is like you have to get the UN on board, we've got to do an actual addressing of the Palestinian refugee problem, which is handled like a joke right now. Iran has to be brought to the table in terms of negotiations. There has to be huge efforts made to economically revitalize these Palestinian areas. Even though they're one of the highest recipients of aid in the world. You have to do something about the embargo and the blockade and the Gaza Strip, which isn't just maintained by Israel, it's also maintained by Egypt. You should ask why. Yeah, there's a lot of things that have to happen to fix that problem. But the reality is I don't think Israel really wants to because they get to continue their expansion into the West Bank, and I don't think anybody around the world really cares that much because in a month, we won't be talking [inaudible 01:04:36].].[01:04:36][Ben Shapiro][I will argue with that. The idea that Israel does not want to end the conflict is belied by the history of what just happened with the Gaza Strip. So when we talk about settlements for example, Israel did have settlements inside the Gaza Strip. There were 8,000 Jews who were living inside the Gaza Strip in Gush Katif. Up until 2005, they withdrew all of those people, I mean, took them literally out of their homes, and the result was not the burgeoning of a better attitude toward the state of Israel with regard to, for example, the Palestinian population in Gaza. In fact, it was more radical in Gaza than it was in the West Bank. The result was obviously the election of Hamas, the October 7th attacks, in which unfortunately, many civilians took part in the October 7th attacks. There's video of people rushing, who are civilians and dressed in civilian clothing, into Israeli villages.].[01:05:22][Destiny][Oh, careful. Not always the same thing.].[01:05:23][Ben Shapiro][Well, no, no. That is 100% true, obviously. And when it comes to Area C and Israel's supposed deep and abiding desire for territorial expansion in Area C. Area C, so for those who are not familiar with the Oslo Accords, and again, this is getting very abstruse, but the Oslo Accords are broken down into three areas of the West Bank. Area A is under full Palestinian control. That'd be like Jenin and Nablus, the major cities, for example. There's Area B, which is mixed Israeli-Palestinian control, where Israel provides some level of military security and control, and then there's Area C. And Area C was like to be decided later. It was left up for possible concessions to the Palestinian authority if the Oslo accords have moved forward. Those are disputed territories. There is building taking place in Area C by both, actually no one talks about this, but by Palestinians as well as Israelis.].[01:06:10][Ben Shapiro][And the question as to whether if Israel stopped building, there've been many settlement freeze in the past, including some undertaken by Netanyahu, and it actually has not done one iota of good in moving the ball forward in terms of actual negotiations. Again, the biggest problem is that the leadership for Palestinians has spent every day since, really, '67. It's not even '48. Because between '48 and '67, Jordan was in charge of the West Bank and Egypt was in charge of the Gaza Strip. And at no point did either of those powers say, \u201cHey, maybe we ought to hand this over to an independent Palestinian state.\u201d Which was originally the division that was promoted by the UN Partition Plan in '47. Because of that, the leadership post '67, and really, starting in '64, the Palestine Liberation Organization was founded in '64, and it called for the liberation of the land in '64. They had the West Bank and they had the Gaza Strip. So they're talking about Tel Aviv.].[01:07:02][Ben Shapiro][When it was founded in '64, the basic idea, as kind of indicated by that, was Israel will not exist, and that was a promise that's been made by pretty much every Palestinian leader in Arabic to the people that they are talking to. Yasser Arafat famously would do this sort of thing. He'd speak in English and talk about how he wanted a two-state solution, and then he'd go back to his own people and say, \u201cThis is a Trojan Horse and we're going to...\u201d If Israel could, if you think that Israeli parents want to send their kids at the age of 18 to go and monitor Jenin and Nablus and be in Khan Yunis, you're out of your mind. You're out of your mind. Israelis do not want that. In fact, Israelis didn't want that so much that they allowed rockets to fall in their cities for full on 18 years in order to avoid sending soldiers en masse back into the Gaza Strip.].[01:07:45][Destiny][True. But I think Israel does want to continue to expand settlements into the West Bank, right? They want to continue to build, they want to have all of Jerusalem, East Jerusalem as well.].[01:07:52][Ben Shapiro][Well, I mean, East Jerusalem has already been annexed. So East Jerusalem is, according to Israel, a part of Israel. That's not a settlement.].[01:07:56][Destiny][Sure.].[01:07:56][Ben Shapiro][Okay. So there's that. With regard to does Israel have an interest in expanding settlements in the West Bank? Why would they not until there's a peace partner?].[01:08:04][Destiny][Sure.].[01:08:05][Ben Shapiro][[inaudible 01:08:05].].[01:08:05][Destiny][That's what I mean. But I'm saying as long as the conflict continues, because even when you talk about-].[01:08:08][Ben Shapiro][But no, your suggestion is that they're incentivizing the conflict to continue so they can grab more land.].[01:08:12][Destiny][Well, no, let me be very clear. I don't think there's a... So some people say, for instance, they'll take that one quote from Netanyahu and they'll try to say that he was funding the people on the Gaza Strip by allowing Qatari money to come in, even though he was actually speaking in opposition to Abbas, allowing the Gaza Strip to fall for Netanyahu to clear it out for him and they give it back, et cetera, et cetera. I'm not claiming those theories. I'm just saying that I think that Israel will take a relatively neutral stance towards conflict and enduring, because as long as the conflict endures, and as long as the settlements can expand, I think that ultimately benefits Israel.].[01:08:42][Ben Shapiro][I think there would be... Let's put it this way, if suddenly there are arose among the Palestinians, a deep and abiding desire for peace approved by a vast majority of the population with serious security guarantees, I think you'd be very hard-pressed to find Israelis who would not be willing to at least consider that. [inaudible 01:08:57] not expanding bathrooms [inaudible 01:08:59].].[01:09:00][Destiny][I would've agreed with you on October 6th. I think we're probably a year or two away from that right now.].[01:09:04][Ben Shapiro][No, no. But no, the point I'm making is that Israelis now realize that the entire peace process was a sham, meaning the people who were on the other side of the table were using it as a Trojan Horse in the first place. The death of Oslo is not the death of Israeli hopefulness. It's the death of the illusion that on the other side of the table was anyone worth bargaining with. That's what's happening, and that's why you have this sort of insane disconnect right now between the United States and the Israeli government. Again, it's a unity government. No one in Israel is talking about making concessions to the Palestinian authority for a wide variety of reasons, including the fact that Mahmoud Abbas' Fatah continues to pay actual families of terrorists who killed Jews.].[01:09:35][Destiny][Sure, the Martyr fund. Yeah.].[01:09:35][Ben Shapiro][Right. And the fact-].[01:09:37][Destiny][Which is from the moderate West Bank.].[01:09:39][Ben Shapiro][Right, exactly. So again, the taste in Israel for this is even the people who are the Hilonim, those are the most secular people in Israel, which was, by the way, the place that was attacked on October 7th. I mean, what people should understand is that October 7th was not an attack against settlements in the West Bank. It was an attack on peace villages that were essentially disarmed, and many of these people who were killed were peace activists who were literally trying to work with people in Gaza to get them... I mean, it's mind-boggling. That's why you've had this ground shift in Israel. The next 20 years in Israel is going to be about security and economic development. Period, end of story. Everything else goes second, third place.].[01:10:12][Destiny][And I will say, I agree essentially with everything you're saying. Not to loop back on another topic, but this is one of the reasons then why I was so critical. I don't want to say critical, but kind of nonchalant about the Abraham Accord because they didn't address anything with the Palestinians whatsoever. They brought countries that weren't super relevant to the conflict. They didn't bring in Qatar, which is where a lot of the money and support for the Gaza Strip comes from. It didn't involve Iran at all. They involved bilateral [inaudible 01:10:33].].[01:10:32][Ben Shapiro][No, but it's totally changed the mentality, and this is why what I'm seeing right now, this is why... Listen, I think that Biden has done better than I certainly expected him to do in terms of support for Israel. Obama was way less supportive of Israel than Biden by every metric. With that said, the rhetoric that he's been using recently and the blanket have been using recently about Israel needs to make painful concessions for peace, Israel... Re-centering, this issue at the center of relations in the Middle East is doomed to failure.].[01:10:55][Ben Shapiro][The magic, magic is a strong word... The benefit of the Abraham Accords was proof of what you're saying, which is true, which is that all of these surrounding countries, in reality, have abandoned the idea that there's a centrality to the Palestinian-Israeli conflict. That is not the central conflict in the Middle East. And by the way, one of the reasons it's not the central conflict in the Middle East is because actually, ironically, because of the rise of Iran. It's SUNY states that are largely signing up with Israel because they're realizing they need some sort of counterweight to a burgeoning nuclear power in Iran.]."
            },
            {
                "title": "Russia-Ukraine",
                "statements": "[01:11:25][Lex Fridman][Can we talk about Ukraine?].[01:11:26][Destiny][Sure.].[01:11:27][Lex Fridman][Do you have a disagreement with what Destiny said?].[01:11:31][Ben Shapiro][My main problem with Biden's policy with regard to Ukraine is that he outsourced the end goal of the war to Zelenskyy early on. Now, that might make sense if that goal were something that he was willing to fund to the point of achievement or if Zelenskyy could have achieved it on his own. But right now, and this has been true since pretty early on in the war, it's a point Henry Kissinger made, that pretty early on in the war, it was very clear that for example, Crimea was going nowhere. The Russians had control of Crimea, barring the United States giving permission to fly F-16s over Crimea, nothing was going to change over there. The same thing was true in most of the Donbas, in Luhansk and Donetsk. That was not going to change. Zelenskyy's stated goal, and you understand it, he's the leader of Ukraine, is that there was a predation on his territory in 2014 and that the Russian sent their little green men across the border, and then they took all of these areas. And so he, as the leader of Ukraine, is saying, \u201cOkay, I want all of that back.\u201d].[01:12:25][Ben Shapiro][Now, the reality is that the US' interests had largely been achieved in the first few months of the war, meaning the revocation of the ability of Russia to take Ukraine and just ingest it. And two, the devastation of Russia's military capability. I mean, Russia has just been wrecked. I mean, the military is in serious straits because of the war in Ukraine. From an American perspective, I'm very much pro all of that. I think that we have an interest in Ukraine maintaining a buffer status against a territorially aggressive Russia. I think that the United States does have an interest in degrading the Russian military to the extent that it can't threaten the Baltic states or threaten Kazakhstan or other countries in the region. The problem I have with Biden's strategy is as always, I think that it's a muddle, and I think muddles tend to end with misperceptions.].[01:13:10][Ben Shapiro][War tends to break out and maintain because of misperception, misperception of the other side's strength, the other side's intentions, and all of the rest. People misperceive what's going to happen. They say, \u201cI'll cross that line and nothing will happen.\u201d This is what Putin thought. He thought, \u201cI'll cross that line. They'll greet me as a liberator. And because the United States just surrendered in Afghanistan, essentially, they won't do anything, and the West is fragmenting because NATO's fragmenting and all the rest of this.\u201d And obviously, he was wrong on all of those scores.].[01:13:32][Ben Shapiro][The problem for Biden is that as with virtually every war, no end line was set. And so it became out recently that it was widely reported that actually there was a peace deal that was on the table in the first few months that Putin was on board with that basically would've seeded Luhansk and Donetsk and Crimea to Russia in return for solidification of those lines. American and Western security guarantees to Ukraine, right? Ukraine wouldn't formally join NATO, but there would be security guarantees to Ukraine. We're ending up there anyway. It's just taking a lot more money and a lot more time to get there.].[01:14:04][Lex Fridman][And do you think Trump would've helped push that peace?].[01:14:07][Ben Shapiro][Yes, and I think that Biden actually did Zelenskyy a bit of a disservice because Zelenskyy knows where this war is going to end, and it's not going to end with Luhansk and Donetsk and Crimea in Ukrainian hands. It's just not going to, and he knows that. What actually, in my opinion, Zelenskyy needed was for Joe Biden to be the person who foisted that deal upon him so that he could then go back to his own people and say, \u201cListen, guys. I wanted all those things, but the Americans weren't willing to allow me to have all those things.\u201d And so we did an amazing job, we did a heroic job in defending our own land. We devastated the Russian military even though no one expected us to, but we can't get back those things because it's unrealistic to get back to those things because America basically, they're a big funder and they're the ones who want the deal.].[01:14:46][Ben Shapiro][Instead, what Biden said, and this was reported in the Washington Post last year, the Biden administration said, \u201cWe're going to fight for as long as it takes with as much as it takes.\u201d And when they were asked until when, they said, \u201cWhatever Zelenskyy says.\u201d And that's not a policy, that's just a recipe for a frozen conflict with endless funding. Now, it may be that Putin has walked away from the table and that deal is no longer available. If that deal is available right now, I certainly hope that's being pursued behind closed doors. My main critique again of Biden is that when you outsource the end goal to another country without stating what America's interest is, that's a problem. I also think that Biden did really quite a poor job of sort of explaining what America's realistic interests are. I don't like it when American leaders... It's weird for me to say this, but I'm not a huge fan of the we're in it to protect democracy kind of rhetoric because frankly, we are allied with many, many countries that are not democracies, and that's not actually how foreign policy works.].[01:15:41][Ben Shapiro][We should, as an overall 30,000-foot goal, advance democracy and rights where we can, but the reason that we were fighting in favor of Ukraine, and when I say fighting, I mean giving them money and giving them weaponry, the reason that we were doing that in favor of Ukraine is not because of Ukraine's long history of clean voting and non-corruption. The reason that we were doing that is to counter Russian interest in the region. I mean, it was a pure, real politic play, and that real politic play is hard to deny no matter what side of the aisle you're on. I think that what many Americans are going to, are reverting to is we have no interest there. Why are we spending the money there and not spending the money here? And that kind of stuff. And that argument can always be applied unless you actually articulate the reason why it is good for Americans beyond simply the ideological for the United States to be involved in a thing.].[01:16:26][Ben Shapiro][So for example, I think right now, when Biden is taught, I think that what Biden just did, the United States as we speak, is striking the Houthis. I think that that's a really, really good thing. I think that's a necessary thing, and I think American people should understand why that is happening. It's not because of, quote, unquote, \u201cideology\u201d. It is, I mean, on a very root level, but really, it's because you're screwing up the straits. I mean, you can't do that. You can't screw up free trade, and Americans have an interest in not seeing all of our prices at the grocery store double and triple because a bunch of ragtag pirates akin to the Barbary pirates from 1800 are bothering everyone. Right?].[01:17:00][Lex Fridman][So Ben said a lot there. Do you disagree with any aspect on the Ukraine side [inaudible 01:17:04]?].[01:17:04][Destiny][A little bit, yeah. I think on the macro, I agree. Maybe we get into weasel a little bit on some things. On the final thing that he said, though, I wish that Americans could have honest conversations about foreign policy. I think that it would just be better for everybody. I don't know if it's Red Scare after the Cold War where it was literally the behemoths, we're fighting against communism and we felt like after '91, every single foreign policy decision needs to be able to be explained in seven words, like he's the bad guy, and that's it. I wish we had more honest conversations about what our foreign policy interest is in a particular region, because I don't think most Americans honestly could even articulate why Israel would be an important ally or why it's important to defend Ukraine against Russia or why should we care about Taiwan at all. I don't know if most Americans could articulate anything there, even though they might have very strong opinions about why we ought to be involved in certain conflicts. So I do agree with that. I wish we had more honest conversations about foreign policy. In terms of how Biden has handled Ukraine. The things that I liked the most were one, that he was very clear in the beginning about what we wouldn't do. So Biden saying that, \u201cWe're not going to do not a red line, no-fly zones over Ukraine. We're not going to be deploying troops on the ground in Ukraine. We're not going to be doing anything that would have US soldiers and Russian soldiers crossing swords with each other. That's not going to happen.\u201d I liked that he made that very clear at the beginning, and I liked that he coalition-built between NATO and the EU to get people to send funds, training, soldiers, airplanes and everything to Ukraine. I thought those two things were really good. In terms of basically writing Zelenskyy a blank check, I would like to hope that Biden and the entire United States learned a lesson from Iraq and Afghanistan, that open-ended missions with unlimited budgets and no clear goal are like the worst foreign policy decisions you can ever do. They've defined US foreign policy for the past two or three decades, which is unfortunate, but seems to be the case.].[01:18:57][Destiny][My feeling would be, and this is just a feeling, I don't know if internal cables have leaked that say otherwise, is the Biden administration has probably always had a quiet position of at some point, there's going to be an off-ramp here, and I think even a month or two ago, I think those talks were being leaked, that discussion had begun with Zelenskyy looking for an off-ramp. But publicly, of course, the United States is never going to come out and say, \u201cWe are going to support you guys to fight as much as you want for three months. And then after that, it's no more.\u201d Obviously, that can't be the statement. It's always going to be that, \u201cWe're going to support you in your fight against Russia [inaudible 01:19:28].\u201d].[01:19:28][Ben Shapiro][Yeah, we tried that under Obama with Afghanistan. It was terrible.].[01:19:30][Destiny][Sure. You can't-].[01:19:31][Ben Shapiro][We'll escalate the troops levels to X, but only for six months and then we'll [inaudible 01:19:34].].[01:19:34][Destiny][You just can't do that. It's always going to come off as, \u201cWe're going to support you forever and as long as it takes and as long as you need, whatever we have to do to defend freedom and democracy in your country.\u201d And any other statement would be absurd. So I can understand why it feels like on a public level, a blank check and an indefinite time period was granted to Zelenskyy, but I don't think that's going to be the case. I think, again, I hope we've learned our lessons in the Middle East about the forever wars, that this isn't going to be a forever funding to Ukraine to fight for as long as they want. I do disagree. I feel like we're playing a little bit retrospectively, saying that, \u201cWell, it's obvious that they're not going to capture the Donbas. It's obvious that they're not going to capture Crimea.\u201d I agree, for Crimea, that was incredibly obvious, but it was also really obvious that in two weeks, Russia would own Kyiv and Ukraine was going to be Belarus 2.0.].[01:20:14][Destiny][I think that even for a lot of military people and analysts around the world, that that was an expectation or at least a significant probability. Nobody knew, the phrase that's thrown right now is paper tiger, that Russia's military was as ill-equipped as they were. So I can understand why, especially if you're Ukraine and if you've repelled an invasion from one of the world's largest armies, why you might feel like, \u201cWell, fuck it, let's fight for a few months. Let's fight for a year. Let's see what happens.\u201d And I can understand the United States supporting them, but I agree that there has to be some reasonable off-ramp, but we're not going to fight forever. I think the US State Department has already begun those conversations with Zelenskyy to look at what that off-ramp looks like. But yeah, I'm not too sure other than explicitly stating publicly you can only fight until this date. I don't really know what else I would... I don't think the Biden administration should have done that. I don't know what else-].[01:21:02][Ben Shapiro][Do you think Biden should cut this deal on the funding? Meaning there's this $105 billion deal that's been held up by debate between Republicans and Democrats over border. So basically, it contains $60 billion for Ukraine, $14 billion for Israel, another several billion dollars for Taiwanese defense against China, and then includes some border funding and some border provisions. Republicans want the border funding and the border provisions because we can get into the illegal immigration issue, but that's a pretty serious issue, and Biden Democrats have been unwilling to hold that up, and that seems to me like just from, put aside Republicans, Democrats, it seems like political malpractice, meaning there's a widespread perception in the United States that the border's a disaster area. Joe Biden wants these things. Many republicans don't want these things. If he caves on the border stuff, he gets all the things that he wants, and he's going to be able to go back to the moderates in the country and say, \u201cI did something about the border.\u201d It seems like such an obvious win.].[01:21:48][Destiny][If he caves on the border stuff, you mean on the Ukraine stuff?].[01:21:50][Ben Shapiro][Yes, because then he gets the whole package, meaning he can go back to his own base and he can say, \u201cListen, guys, I want it to be easy on the border. The Republicans forced me to it, but we needed the Ukraine aid. We needed the Taiwan [inaudible 01:21:59].\u201d].[01:22:00][Destiny][Honestly, you're going to be more educated than me on this. I don't like, or maybe I just don't know enough. I don't like the principle that when we negotiate things in the United States, there's like 50 million hostages at all points in time for every single thing. Like, \u201cOh, boy, here comes the debt ceiling. What do the Republicans want? What do the Democrats want? Oh, boy, we can't fund our government.\u201d But I mean, obviously, the argument is going to be that if the Ukraine funding doesn't come in this bill, and if Biden and his administration feel like it's really important that not unilaterally, but as a single issue, it's not going to pass. So I would say that at this point, and I don't know what the conversations look like between the Biden administration and Zelenskyy, I would say at this point, that it's probably fair to start making contingencies on the money that we give to Ukraine that, \u201cListen, this conflict has waged on now. Now, we need to start looking for potential peace. We can't just write you an unlimited check.\u201d So I mean, if those strings are attached, I'd be okay with it. But the broader question of is it okay to make this particular piece of legislation with all this funding contingent on the Ukrainian funding? I mean, that just seems to be the way the government works now, unfortunately.]."
            },
            {
                "title": "January 6",
                "statements": "[01:23:02][Lex Fridman][Quick pause, bathroom break. One of the big issues in this presidential election is going to be January 6th. It's in the news now, and I think it's going to become bigger and bigger and bigger. So question for Destiny first. The Donald Trump incite and insurrection on January 6th, 2021.].[01:23:22][Destiny][Absolutely. This is probably ignoring every other issue we've talked about, of which I think there are plenty that I would say disqualified Trump from holding office. I think that the conduct and the behavior leading up to and including January 6th, I think is wildly indefensible. I am excited to see Ben try to... Yeah, the three to four stages are the taking what I think any reasonable [inaudible 01:23:48] knowingly false information about elections being rigged or ballot box is being stuffed, or Ruby Freeman running the ballots three times in Georgia. Taking that knowingly false information and trying to call state secretaries and stuff to have them flip their electoral vote, that was horrible. The plot that Eastman hatched in order to have these false slates of electors where all seven states had citizens go in and falsely say that they were the duly elected electors that could submit votes to Congress, that was insane. That happened. Asking or begging Pence to accept these false states of electors initially, and then just say you should just throw it out completely and throw it to the house delegation, which was majority Republican, that was absolutely unbelievable.].[01:24:36][Destiny][And then on the day of January 6th, trying to capitalize on the violence by him, Giuliani, and Eastman making phone calls to senators and congressmen saying, \u201cWell, don't you think maybe you guys should delay the vote a little bit? Don't you think they're just really mad about the election?\u201d I think he said to McCarthy, \u201cThey're more upset than you.\u201d And his utter dereliction of duty and not doing anything to stop the rioting that happened on January 6th because he was too busy taking advantage of it, I think all of these things are horrible. I look forward to seeing the Jack Smith indictments play out in court, maybe even the Georgia RICO case. But yeah, I think all of these things are unfathomable, and I think when you look at the plot from start to finish, clearly, the goal the entire time was to circumvent the peaceful transfer of power. That was the goal from start to finish, whether it was through false claims, whether it was through illegal schemes, or whether it was through violence at the Capitol to delay the certification of the vote.].[01:25:28][Lex Fridman][Ben.].[01:25:29][Ben Shapiro][So I'm glad you're excited. It's always fun. So there are two elements to incitement of insurrection. One is incitement, the other is insurrection. So incitement has a legal standard, so does insurrection. Neither of those standards are met. So if you're asking me, morally speaking, did Donald Trump do the right thing between November 4th and January 6th? I said, I will continue to say no, he did not. I think he was saying things that are false with just factually false about his theories with regard to the election, about the election being stolen, about fraud. This is all adjudicated in court. He did not even bring many of the claims that he has brought publicly and all the rest of that. If we're talking about incitement of insurrection as a legal standard, he doesn't meet any of those standards.].[01:26:05][Ben Shapiro][When it comes to incitement, it has to be incitement to immediate lawless action. That's the standard for incitement. And I'm very meticulous in how I use this because I happen to speak publicly a lot, and that means there are lots of people who listen to me, which means some of those people are probably crazy and some of them may go and do a crazy thing. Did I incite them? The media tends to use the word incitement very loosely with regard to this sort of stuff, in the same way that Bernie Sanders, quote, unquote, \u201cincited\u201d the congressional baseball shooting. He did not. Bernie Sanders has a lot of things I disagree with. I think Bernie's a schmuck, doesn't matter. He did not incite that.].[01:26:34][Ben Shapiro][So saying bad things is not the same thing as inciting violence. Inciting violence, the legal standard in the United States is, I want you to go punch that guy in the face. That's inciting. With regard to insurrection, typically, in insurrection, and there are some descriptions in case law, though none in statutory law as far as [inaudible 01:26:50]. The typical description in case law is the replacement of one legitimate government of the United States with another by violent means. The notion that Donald Trump coordinated any such insurrection is belied by the FBI itself. The FBI put out a report in, I believe it was...].[01:27:00][Ben Shapiro][... is belied by the FBI itself. The FBI put out a report in, I believe it was August of 2021, suggesting that there was no well-coordinated insurrectionist attempt coordinated by the White House. In fact, what you had was Donald Trump thrashing around like that weird alien in the movie, Life. I don't if you ever saw it with Jake Gyllenhaal, where he's like kind of thrashing up against this glass box, just an alien just thrashing up against the glass box. That I think is more what you were seeing from November 4th to January 6th.].[01:27:25][Ben Shapiro][And then again, the claim that January 6th itself was an insurrection... I'm not aware that anyone was charged with actual insurrection. There were some people who were charged with seditious conspiracy. There are insurrection statutes that do exist. No one was charged under those particular statutes. There were some people who you could say informally had insurrectionist ideas. Those would be the people who wanted to hang Nancy Pelosi or kill Mike Pence, and those people are in jail right now. And the election went forward. The election was certified. Mike Pence presided over the certification. Mitch McConnell presided over the certification. Joe Biden has been the President for the last three years.].[01:28:01][Ben Shapiro][Donald Trump, by the way, was still President at that point. If he had actually wanted to do what other people who've actually launched coups have done, he would've theoretically called the National Guard not to put down the riot but to actually depose the sitting Government of the United States in the name of a specious legal theory. He did not do that, he did not attempt that. Nobody working for him did that. The most you can say, I think, about what everybody was doing... and I don't want to say everybody. We can talk about Trump because this is really about Trump.].[01:28:28][Ben Shapiro][He used a phrase that Trump was disseminating knowingly false information. The word that's carrying a lot of weight there is the word knowingly. Knowingly implies a knower. Do I think the information he was disseminating was false? Yes. Do I think that Donald Trump has unique capacity to convince himself of nearly anything that is to his own benefit? Absolutely. And I think that that's actually what Donald Trump was doing there, and the evidence for that is Donald Trump being a human and all of us watching him for the last several years.].[01:28:54][Ben Shapiro][So the idea that he knew it to be false, I'm not even sure those standards apply in any... just assessing him as a human, which is really what we're being asked to do because there's an intent element to this crime. Do you think that today, Donald Trump knows that he lost the election?].[01:29:09][Destiny][Absolutely.].[01:29:10][Ben Shapiro][So I don't, actually. I think that-].[01:29:13][Destiny][So I'm glad that you have the attorney background. When we are assessing mens rea, when we're looking at certain criminal statutes where intent is required, it's a reasonable person standard, right?].[01:29:14][Ben Shapiro][Well-].[01:29:22][Destiny][Would a reasonable person have known that they were-].[01:29:24][Ben Shapiro][No, it depends on the mens rea standard. So it's not the same in every case. If you have to establish individual intent, then it's not enough to say a reasonable person should have known. That would be enough for a negligent statute.].[01:29:35][Destiny][Sure, but for-].[01:29:35][Ben Shapiro][Usually when you're talking about reasonable person statutes, just legally speaking, a reasonable person statute is should a reasonable person have known. That's when you get to manslaughter. You can't do a reasonable person standard on first degree murder.].[01:29:45][Destiny][So for-].[01:29:46][Ben Shapiro][You have to establish actual motive and first degree murder.].[01:29:47][Destiny][But for first degree murder, you don't need the statement of, \u201cI plan to kill this person,\u201d or \u201cI intend to kill this person.\u201d].[01:29:55][Ben Shapiro][No. No, you need a-].[01:29:55][Destiny][We can prove that state of mind from a ton of other circumstantial evidence.].[01:29:57][Ben Shapiro][Correct. Yes, sure. You can prove it.].[01:29:58][Destiny][So I feel like my feeling for Donald Trump was there were all these people around him that he trusted to investigate election fraud. He trusted Barr and the DOJ. He asked Pence, his Vice President, to look into it. He asked his chief of staff, he asked his legal counsel. He asked so many people that, ostensibly, he trusts them if he's asked them to look into it, and when all of them looked into it and reported back to him, \u201cNo, we found nothing.\u201d Unless we're going to literally make the concession that Trump might actually be a delusional psycho man, at that point, should he not have realized, well, okay, maybe this thing-].[01:30:26][Ben Shapiro][I think he should have realized the day of the election that he lost the election, but that's not what-].[01:30:29][Destiny][Sure. But I'm saying that, at that point, should he not have known that for him to go and propagate those claims that he'd asked all of the people he trusted to research, and then for him to take those claims to Michigan and to Georgia and then publicly and to try to convince people to throw out the election. You don't think that-].[01:30:45][Ben Shapiro][But you're doing the same thing. You're reverting to should a reasonable person have known. Yes, a reasonable person should have known. Did Donald Trump know? That's a different question, and so conflating those two questions is going to get you into some messy territory. By the way, this is why Jack Smith charged the way Jack Smith charged.].[01:30:58][Destiny][Yeah, which was-].[01:30:59][Ben Shapiro][But Jack Smith did not charge conspiracy. Jack Smith did not charge insurrection. He did not charge seditious conspiracy, right?].[01:31:05][Destiny][But I think for Jack Smith-].[01:31:07][Ben Shapiro][Jack Smith is a good lawyer. What he's doing is he's actually broadly, I would say pretty obviously, expanding statutory coverage in weird areas in order to cover a thing that doesn't quite fit into any of these legal categories. But the point that I'm making is that Jack Smith is on my side of this. He doesn't think that he can actually establish the intent necessary to convict under a seditious conspiracy or an insurrection charge.].[01:31:29][Destiny][I agree with that, but I think a lot of the underlying facts though, because he does bring up those calls to Raffensperger in Georgia, he does bring up and the indictments that they were knowingly false information. So it seems like that's going to be part of the case. Maybe not to convict on any of the four particular charges that he mentioned, but it seems like that's probably going to be part of what he's going to have to establish in court to convict Trump.].[01:31:47][Ben Shapiro][So I want to look at the actual text of the charges. So I'm sorry that I don't have them memorized. I believe one's a fraud charge that generally does not apply to cases like this. Generally, the fraud charge is like you're trying to steal money from the Government. One is-].[01:31:59][Destiny][Sure. Fraud has been used pretty broadly in the past though. Because Smith has done oral arguments in response to a lot of the claims by Trump's lawyers. This was one of them. The infinite civil and criminal immunity was another one of them where he cites past cases where these types of things, because I think it was to defraud of civil rights, I think was the fourth charge.].[01:32:13][Ben Shapiro][Right. So the defraud of civil rights is usually somebody standing in the actual voting house door and preventing you from voting, not you have a specious legal theory that you espouse in court about whether those votes should be thrown out.].[01:32:24][Destiny][Sure, although I don't like... when we say specious legal theory and novel application, which I do agree, some of these in some ways is novel. I don't think we've ever also had a President try to do this before. It is a novel situation-].[01:32:36][Ben Shapiro][Well-].[01:32:36][Destiny][... where somebody has resisted the peaceful transfer of power this clearly in so many different ways.].[01:32:40][Ben Shapiro][Well, if you're talking about the legal cases, I mean that's not true. Gore sued in 2000. I mean, if we're talking legal cases, right?].[01:32:47][Destiny][If this was comparable to Gore, then-].[01:32:48][Ben Shapiro][I'm not saying it's comparable to Gore. I'm saying that if the idea is that espousing a legal theory in court amounts to de facto some form of election-].[01:32:56][Destiny][Well, I'm just saying that Gore-].[01:32:57][Ben Shapiro][... denial or interference in some way, that's not true. As a general principle, it's over inclusive.].[01:33:04][Destiny][Sure. Gore wasn't trying to de-certify the vote though for states. Right? They challenged their thing to the Supreme Court, they lost their case in the Supreme Court and then power transfer happened afterwards.].[01:33:12][Ben Shapiro][Right, and Donald Trump had a bunch of legal challenges, and then he had a rally, and then there was a riot, and then he left power.].[01:33:16][Destiny][Yeah, but the Eastman theory of what Pence could do in Congress is a far cry away from-].[01:33:22][Ben Shapiro][A truly shitty theory. I mean, make no mistake. It's a really shitty theory.].[01:33:24][Destiny][But not just shitty. I think that if any Democrat had done this, I feel like we'd be looking at it in a far different lens. As in we would be using terms like attempted coup, a subversion of peaceful transfer of power. If a Democrat Vice President had tried to essentially say that in Congress, they could throw away the vote.].[01:33:44][Ben Shapiro][So I think what I want to get to here actually, so we can be more specific, is why are these terms important? We agree on, largely speaking, what happened. I think, the characterization of the term, we keep kind of bouncing around between two different categories, and I want to make sure we-].[01:33:44][Destiny][We can dump the legal stuff actually-].[01:34:02][Ben Shapiro][Okay. So we're just talking... Fine, fine, fine.].[01:34:03][Destiny][We're not looking at incite... because like you said, Jack Smith... nobody's charging with incitement, and I don't believe insurrection is part of that. So we're dumping legal. Just in terms of like a President that is trying to prevent the peaceful transfer of power. So we do call that a bloodless coup or a coup or whatever contemporaneous term you want to use.].[01:34:17][Ben Shapiro][So prevent the peaceful transfer of power with all means or using means that are inappropriate, not quite the same thing. Meaning means that-].[01:34:25][Destiny][Using means that are inappropriate or illegal.].[01:34:26][Ben Shapiro][Okay. So illegal? I don't think so. I don't think that these charges actually meet the criteria for the various charges, and we can discuss each case if you want. As far as inappropriate, sure, I think tons of inappropriate stuff. I mean, inappropriate seems not-].[01:34:42][Destiny][The reason why I don't like the word inappropriate though is because then conservatives are very quick to say, \u201cWell, sure he was inappropriate, but everybody who's inappropriate.\u201d].[01:34:47][Ben Shapiro][I mean, I'll concede that he's more inappropriate than others. I just don't see that-].[01:34:50][Destiny][Okay, the most inappropriate?].[01:34:51][Ben Shapiro][Sure. I mean-].[01:34:52][Destiny][Okay. That's important to me though. Does it not bother you that Donald Trump sought, through legal and extralegal and Trump magical ways of trying to entrench his power as President passed when he should have been able to? Is that not something that was incredibly troublesome?].[01:35:09][Ben Shapiro][I mean, the question to me is... the bigger question that I think the Democrats are trying to promote in this election cycle, which is this means he's a threat to democracy sufficient that if he were to win the election, there would not be another. And my answer that is-].[01:35:24][Destiny][But he tried to do that last time. Could he not try it next time?].[01:35:26][Ben Shapiro][I mean, he could try to do whatever he wants, presumably, and he would fail the same way that he did last time.].[01:35:30][Destiny][Why do we think that?].[01:35:31][Ben Shapiro][Because he failed.].[01:35:33][Destiny][So [inaudible 01:35:33]-].[01:35:33][Ben Shapiro][Because there was a riot and in three hours... Yes.].[01:35:38][Destiny][Lord, save me. Let's say hypothetically Giuliani was the next head of the Department of Justice, Giuliani was the next Attorney General.].[01:35:46][Ben Shapiro][How would he be confirmed?].[01:35:49][Destiny][Well, I'm not entirely sure because so much of the Republican party, despite feeling like they don't support Trump when it comes time to actually back him in Congress-].[01:35:56][Ben Shapiro][Also, I would have to check whether he would be barred by a criminal conviction from holding... I don't know the answer to that.].[01:36:02][Destiny][Sure. Well, yeah, especially with the 14th Amendment. We're figuring out a lot of this right now. Yeah, but I mean, say if not Giuliani, say if there are any other number of insane people that Trump could theoretically put on his side of the Government that wouldn't tell him no next time, because there were a lot of people that rebuked him. There were Republicans in a lot of the states. Right? Raffensperger is one of them. There were Republicans in his own administration. You've got Rosen. You've got Barr. There was his own Vice President. But theoretically next time, and I feel like last time going in, I'm going to do a little bit of mind reading and macro... Maybe you'll agree, maybe you'll disagree.].[01:36:35][Destiny][I think that Trump kind of thought... One, I don't think Trump knows much at all about how the Government works. I think we probably agree with that. I think Trump probably thought that if he had people that were at least in his party and kind of camp, that they'll basically do whatever needs to be done to give him what he wants, and with no respect for process. But now that he sees that, well, it's not enough to just have allies; I need people that are fiercely alleged to me, would we not be worried that a guy that tried to essentially steal the election for real wouldn't try to pick people that would be more amenable to his plans in the next administration?].[01:37:04][Ben Shapiro][I believe in the checks and balances of American Government. I believe they worked on January 6th. So if you're asking me, do I think that Trump has bad intent or could have bad intent with that sort of stuff, sure. Do I believe that the guardrails held and will continue to hold? Also sure.].[01:37:18][Destiny][So if somebody was running and they blatantly said, \u201cI...\u201d I don't want to use the fascist word, but if they said, \u201cI want to be an authoritarian, I'm going to abolish all elections,\u201d you would say, \u201d Sure, he's saying that, but I don't think he can actually do it. So it's okay if he runs for President.\u201d You don't care at all as long as you feel like the guardrails [inaudible 01:37:36]?].[01:37:36][Ben Shapiro][I mean, I might prefer other candidates, but I think that also one of the things that you do is that politicians... Again, this would be an exceptional circumstance, but politicians constantly make promises about the things that they're going to do and then don't fulfill, and we tend to take those out in the wash, meaning that, if I promise that day one, as Donald Trump has pledged to do that, he's going to deport literally every illegal immigrant into the country, do I think he's actually going to do that? I mean, I really highly doubt it. He didn't do it last time he was in office. There are many examples of this.].[01:38:03][Destiny][I agree.].[01:38:04][Ben Shapiro][Here's my question. Do you think the guardrails are going to fail to hold?].[01:38:07][Destiny][I'm not sure.].[01:38:08][Ben Shapiro][Really?].[01:38:09][Destiny][Yeah, because I think the issue is one, when it's election time, Republicans are spineless in office, and I don't know how many congressmen would support what he wants just because they want to win reelection or because they think it's inevitable anyway.].[01:38:20][Ben Shapiro][I mean, I think that one of the things that happened in 2022 is Democrats ran directly on this platform, and a bunch of Republicans who were running on this platform. Literally every Secretary of State who ran on the Donald Trump, we should deny elections platform, lost in every state.].[01:38:33][Destiny][Sure, but are there Republicans that have been-].[01:38:34][Ben Shapiro][A great way to lose local office is this.].[01:38:36][Destiny][Sure, but I mean, look at what happened with like Kinzinger and Cheney, right, who were very staunchly anti-Trump after J6 for that select committee, right? Kinzinger even run again, and Cheney lost her election by I think the widest margin that anybody has ever lost an election ever, in the history of all of US politics.].[01:38:54][Ben Shapiro][Right, yeah. People who were not yet born voted against her, yes.].[01:38:54][Destiny][Yeah. I guess it's a surprising position to me for me, if we're looking at principled stances of Government, the idea that a man who has... and I think we both agree on this, that Donald Trump's only allegiance is to Donald Trump, right? We agree on that. The only thing he cares about is Donald Trump.]."
            },
            {
                "title": "Abuse of power",
                "statements": "[01:39:08][Ben Shapiro][I don't think it's the only thing he care about it. I think it's certainly the largest thing he cares about.].[01:39:10][Destiny][It's the largest thing he cares about, right?].[01:39:10][Ben Shapiro][Sure.].[01:39:11][Destiny][So you've got a man who only cares about himself.].[01:39:14][Ben Shapiro][Welcome to politics. I mean, it may more-].[01:39:16][Destiny][But that's not even-].[01:39:16][Ben Shapiro][It may be more with Trump, but it's certainly not unique to Trump.].[01:39:19][Destiny][I think that the issue with Trump too though is I think he's even a threat to the Republican party in which I think... I think you would mostly agree with me, maybe not overall, but on every individual point. Trump picks bad candidates. He has no concern for the future of the Republican Party. For instance, I think there is a chance... I don't think it'll happen because of the polling looks now, but if Trump didn't get the nomination, I think Trump would say, screw it and run as an independent because he thinks he can win or whatever.].[01:39:41][Ben Shapiro][I doubt that he would do that, but theoretically-].[01:39:44][Destiny][It's possible.].[01:39:45][Ben Shapiro][Yeah. I mean, again-].[01:39:45][Destiny][He was really content to throw Georgia... the two runoff elections under the bus because Raffensperger didn't support him for the election stuff.].[01:39:52][Ben Shapiro][What is all of this in serVice of? What's the generalized argument that you're making. I'll go back to my question.].[01:39:58][Destiny][[inaudible 01:39:58]-].[01:39:58][Ben Shapiro][Do you think if Trump wins, there will be no more elections?].[01:40:02][Destiny][I don't-].[01:40:03][Ben Shapiro][Put a percentage on it. What percentage do you think that that's a reality, that if Donald Trump becomes President-].[01:40:06][Destiny][Comes general Trump wins, I think there is a 100% chance that he will try to prevent the peaceful transfer of power. In terms of would he succeed-].[01:40:12][Ben Shapiro][I can guarantee you he will not do that.].[01:40:14][Destiny][Why is that?].[01:40:14][Ben Shapiro][Because he's in the second term and he's no longer eligible, and he will believe he won and he will leave.].[01:40:17][Destiny][But hasn't Donald Trump himself joked about running for a third term?].[01:40:20][Ben Shapiro][That's not-].[01:40:21][Destiny][I think that having a third term-].[01:40:22][Ben Shapiro][What has Donald Trump not joked about? I mean, for god's sake.].[01:40:25][Destiny][Okay, hold on. Here's another-].[01:40:28][Ben Shapiro][If you want to prevent him from creating a revolution, you probably should actually just appoint the President and he can't run again, so...].[01:40:32][Destiny][Here's another broad argument that I don't like in favor of Trump, and this was brought up earlier in terms of we talk about not grading Presidents on a curve, but then earlier we said we take Biden's rhetoric seriously-].[01:40:40][Ben Shapiro][No, I totally grade Trump... No, I 100% grade Presidents on a curve. Are you kidding?].[01:40:43][Destiny][Oh, okay. Well, then I feel like-].[01:40:44][Ben Shapiro][I grade pretty much everybody on a curve.].[01:40:44][Destiny][I feel like-].[01:40:45][Ben Shapiro][I don't treat my seven-year-old the same way that I treat my nine-year-old. And I don't treat Trump the same way I treat Biden.].[01:40:49][Destiny][Sure, but I don't like that it feels like we're treating Donald Trump like a seven-year-old or a nine-year-old. I think we should treat him like the President of the United States. I don't think having a President that has taken concrete steps to prevent the transfer of power, which he did with the electorate sham, which he did with Pence, and which he did with trying to capitalize on the J6 violence. A President that's taken concrete steps towards coup-ing the Government essentially. I don't know why that guy, we'd say, \u201cWell, it's Trump, he does Trump things. The guardrails held. They'll probably hold next time. Let's throw him in.\u201d].[01:41:11][Ben Shapiro][I mean, when we say we shouldn't, do you mean that he should be actually barred from office?].[01:41:15][Destiny][I'm just talking about support form. I don't even think Republicans should support Trump. You lose your incumbent advantage. The guy's obviously self-destructive. He's destructive to the political party itself.].[01:41:24][Lex Fridman][Do you think he should be on the ballot? You think there's a case to be made to remove him from the ballot?].[01:41:30][Destiny][I think there's a case to be made, but man, the phrasing... For as much as our Governmental founding fathers and everybody else wrote nice amendments and wrote nice in the Constitution, some of the phrasing is very, very, very... And the section three, the not requiring any type of actual conviction, I don't have a strong feeling on it. I will say I'm very interested in reading the majority opinion from the Supreme Court. I seriously doubt the Supreme Court is going to uphold that States should be able to decide if they leave him off the ballot or not. I think for the political future of the United States, it's probably not healthy that the leading opposition candidate is now going to be barred from the ballot. It's probably not healthy for us, because then what-].[01:42:08][Ben Shapiro][You want to talk about threats of democracy, that would be a pretty serious one, applied across the board by-].[01:42:13][Destiny][It would be. However, that threat to democracy was earned by Donald Trump and the conservatives that supported him. I think conservatives made a dangerous gamble when they threw Trump into office, and now all of the fallout from that is something that we all as Americans have to deal with.].[01:42:25][Ben Shapiro][I mean, I think that the unprecedented legal theory that a state can simply bar somebody from the ballot in an informal way, believing that he's, quote, unquote, an insurrectionist is pretty wild. I mean that is-].[01:42:36][Destiny][We can say it's pretty wild, but there is an amendment in the Constitution, the 14th Amendment, that says that if they have engaged in this, they shall not be, or you shall... I don't remember the phrasing because it doesn't require conviction, but it's a self-executing, arguably thing.].[01:42:47][Ben Shapiro][If we're getting into constitutional law, I mean there are a number of provisions that suggest that this is, number one, not self-executing. I mean, minority opinions in the Colorado Supreme Court case are pretty thorough. The number one contention, which is that this is not self-executing because other elements are not self-executing, that ignores subsequent actual law that happened. I mean, the Congress passed a law, for example, in 1872 defining who was an insurrectionist, who is not an insurrectionist for purposes of elections. In 1994, Congress passed a law that specifically defined insurrection as a criminal activity so that somebody could theoretically be convicted of insurrection and therefore ineligible to run for office.].[01:43:20][Ben Shapiro][It is unlike, say, the analogs that are used by the majority opinion, like age. Obviously this is not the same thing. We can all tell what somebody's age is by looking at their birth certificate. I can't tell whether somebody's an insurrectionist without any reference to a legal statute or definition of the term.].[01:43:34][Destiny][I would also be careful with that because remember, one of Trump's first big political actions was challenging Obama's birth certificate.].[01:43:40][Ben Shapiro][And I thought that was dumb at the time, but in any case...].[01:43:43][Lex Fridman][I like that you both said, 100% chance that Trump will try to go for third term and 0% chance, which statistically-].[01:43:50][Ben Shapiro][Third term? He's done, man. Are you kidding?].[01:43:51][Destiny][He would want to.].[01:43:51][Lex Fridman][But try.].[01:43:52][Ben Shapiro][Trump's going to walk around, hands up high. He's going to be like, \u201cI'm a two-term President. I'm the only President since Grover Cleveland...\u201d He wouldn't know, but since Grover Cleveland who served two non-consecutive terms. I kicked Joe Biden out of office and I kicked Hillary Clinton out of office. Dude would be... he'd be living large. Are you kidding? He doesn't want the presidency anymore after that.].[01:44:06][Destiny][I think it's scary that Donald Trump... It feels like for all of the accusations that are made sometimes against Democrats, like Biden is ordering Garland to investigate Donald Trump and blah, blah, blah, it seems like Donald Trump would actually do that with his DOJ. Would give them orders.].[01:44:21][Ben Shapiro][He didn't. He didn't. He didn't do it with his DOJ.].[01:44:22][Destiny][Well, he kind of did though, right? So for instance, with Jeffrey Clark, Jeffrey Clark went to Rosen and Donahue and said, \u201cHey, listen, I need you guys to sign off on a letter that we're going to use, essentially to bully states into overturning their elections by saying we found significant election fraud.\u201d And part of that threat was Jeffrey Clark saying, \u201cListen, if you're not going to do it, Rosen, Trump's going to fire you and just make me the acting attorney general.\u201d That was the threat that he carried, and I think Trump repeated that threat in a meeting later on that was only rebuked when I think like half the White House staff said, \u201cIf you do this, we're resigning.\u201d].[01:44:53][Ben Shapiro][Okay, so that's a slightly different topic because now you're getting into all the election shenanigans and all of this, but-].[01:44:57][Destiny][Sure. I'm just saying he threatened to fire his acting attorney general if he wouldn't carry the same platform essentially. If Trump could order his DOJ to do something, would he? It's not beyond the pale for him, right?].[01:45:08][Ben Shapiro][It's not beyond the pale for him to order them to do it, and then it's not beyond the pale for them to reject him doing that, which is the story of his entire administration-].[01:45:12][Destiny][I agree.].[01:45:13][Ben Shapiro][... whereas Joe Biden orders his DOJ to do things and then they just do them.].[01:45:15][Destiny][Well, we can get into the specifics there. It-].[01:45:20][Ben Shapiro][This is one of the big problems that I have with... I mean, for example, all the talk about Trump tyrant, Trump executive power... I mean, Joe Biden has used executive power in ways that far outstrip anything that Donald Trump-].[01:45:29][Destiny][Every President has been stretching and stretching and stretching executive power. That's-].[01:45:33][Ben Shapiro][Joe Biden has gone well beyond anything Trump even remotely attempted to maintain via just pure executive power. And actually Trump's use of executive power is nowhere near even what Obama's was. Obama used executive power [inaudible 01:45:44] ways.].[01:45:43][Destiny][I mean,  Trump's inability to get border policy passed literally had him using executive power to march the military down to the border to do border policy. I mean-].[01:45:51][Ben Shapiro][I mean, Joe Biden literally used the Occupational Safety and Hazard Administration to try to cram down vax mandates on 80 million Americans. That's insane.].[01:45:59][Destiny][Sure, but why can't-].[01:46:00][Ben Shapiro][He literally said, \u201d I cannot relieve student loan debt,\u201d and then tried to relieve hundreds of billions of dollars in student loan debt.].[01:46:05][Destiny][Yeah, but what happened to that?].[01:46:07][Ben Shapiro][It got struck down by the Supreme Court, and then they still did it. They still did it. Biden brags about it. He brags about having relief [inaudible 01:46:13].].[01:46:14][Destiny][For what he was able to relieve, which I think were related to particular types of student loan debt. But I'm just saying that well, the guardrails are holding with Biden as much as they're holding with Trump. The only difference is that once Biden exhausts his executive power, he's not running around lying to people or trying to extort people or trying to and concoct insane schemes.].[01:46:31][Ben Shapiro][Well, I mean, here's the way I would think of this. Think of the guardrails holding as the filter, meaning the coffee is in the filter. What you want is going to get through and all the stuff that the guardrails prevent the other stuff from getting through. Now the question becomes what liquid are you pouring into the filter? Meaning if the filter exists, if the guardrails hold, and if Donald Trump can't steal elections, what's the policy that comes through the other end of the filter? The policy I get from Donald Trump on the other end of the filter is a bunch of stuff that I like. The policy that I get from Joe Biden on the other end of the filter is a bunch of bullshit I don't. So that's the basic calculation.].[01:47:01][Destiny][Okay, so then the idea is essentially that Donald Trump's rhetoric is insane, but we don't care. Donald Trump would probably try to steal an election if he could, but he probably won't be able to.].[01:47:11][Ben Shapiro][He's not going to do it again. I told you. He's not-].[01:47:14][Destiny][You don't think he has any... Why not?].[01:47:16][Ben Shapiro][Because he won't be eligible to be on the ballot in... I mean, by the way, you want to talk about 14th Amendment? That's where the 14th Amendment applies. Okay? That's where it actually applies, meaning he's not qualified to be on the ballot in 2028 if he's the President of the United States. States can literally, in self-executing fashion, take him off the ballot. Just like he's passed the age of 35, once you have been President two times, you're no longer eligible to be President of the United States.].[01:47:39][Destiny][Why-].[01:47:39][Ben Shapiro][Then you actually have a strong case to keep him off the ballot.].[01:47:42][Destiny][Yeah, but why would the 14th Amendment stop him if he thought Vice President Pence could unilaterally decide the outcome of the election?].[01:47:48][Ben Shapiro][When he's not on the ballot? So now your theory is that he's going to get re-elected, and then in 2028, he's not even going to be on the ballot and he's going to direct his new Vice President, Kerry Lake, to simply declare him President of the United States when he has not been on a ballot?].[01:48:02][Destiny][I don't know what the scheme would be. I think we can kind of laugh and say there's no scheme we could even concoct, but I think that-].[01:48:08][Ben Shapiro][Macho, like with the machine gun, he's going to walk into the-].[01:48:10][Destiny][I think the issue though is that the idea of electing another President that has tried to circumvent the peaceful transfer of power using extralegal means and then pretending like we can't concoct a single scheme that he could try to circumvent other legal processes to have a third term or to have a longer term or to install who he wants as the next President... When a person has already shown you who they are and when every single person around him agrees with that, when every single person that's worked with him, save for, what? Sydney Powell, Eastman and Giuliani, which I don't think anybody would want to throw their lot in with those three, it just seems wild to me that we would say like, \u201cYeah, we're just going to go ahead and trust this guy with another term or President, but he can't run for a third term, so it's fine,\u201d when there's like 50 million other things he could concoct-].[01:48:50][Ben Shapiro][I'll make you the case that if you want him not to make election trouble, you should elect him President in the next election cycle, and then he will be ineligible.].[01:48:56][Destiny][Okay. I find that be a wholly unconvincing argument, but okay.]."
            },
            {
                "title": "Wokeism",
                "statements": "[01:49:00][Lex Fridman][Well, recently in the news, the Presidents of Harvard, Penn and MIT failed to fully denounce calls for genocide, and that rose questions about the influence of DEI programs at universities. And so maybe either looking at this or zooming out more broadly at identity politics at universities or identity politics, wokeism in our culture, how big of a threat is it to our culture to Western civilization, Ben?].[01:49:30][Ben Shapiro][So obviously I'm going to say it's a huge threat. The reason that I think this is a huge threat... I want to give a definition of wokeism because people are very often accused of not using wokeism properly or believing that it's sort of a catchall phrase. I don't think it's a catchall term. I think that wokeism has its roots in postmodernism, which essentially suggests that every principle is a reflection of underlying structures of power, and that therefore any inequality that emerges under such a system is a reflection, again, of that structure of power.].[01:50:01][Ben Shapiro][That used to be applied in sort of Marxist ways, the suggestion being that economic inequality was the result of misallocation of power in the structure preserved by an upper crust of people who wanted to cram down exploitation on people. That was sort of the Marxist version of postmodernism, and that got transmuted into sort of a racial version of postmodernism in which the systems of the United States are white supremacist in orientation, and are perpetuated by a group of people who are in fact in favor of the preservation of white power and white supremacy. That is the generalized theory of Critical Race Theory as proposed by, for example, Jean Stefancic and Richard Delgado in their book on Critical Race Theory.].[01:50:41][Ben Shapiro][That has taken a softer form that we refer to as DEI. The key in DEI is the E, meaning equity. So equity is a term that does not mean equality. People mix it up. Equality is the idea that we all ought to have equal rights, that we all ought to be treated equally by the law. Equity is the idea that if there is an inequality that emerges from any system, it is therefore due to discrimination, and the best way to tell whether somebody has been victimized is by dint of their race, and we can tell whether you're a member of an oppressed group or an oppressor group by the intersectional identity that you carry, and by the nature of your group's success or failure predominantly along economic and power lines in American life.].[01:51:22][Ben Shapiro][This means that if one group is predominantly successful economically, they must be a member of the victimizing class, and the only corrective for that would be, as Ibram X. Kendi likes to suggest, effectively anti-racist policies, racism in the serVice of destroying racism. That you're going to have to in order to correct for discrimination that's baked into the system. That's incredibly dangerous. It leads to a victim-victimizer narrative that is unhealthy for individuals and terrible for societies. It relieves people of individual responsibility and it destroys the very notion of an objective metric by which we can decide meritocracy and meritocracy is the only system human beings have ever devised that has positive externalities in literally any area of life.].[01:52:06][Ben Shapiro][Every other distribution of wealth, power done along other lines that is not having to do with merit, has negative externalities. Every system having to do with merit has positive externalities because presumably the most effective and useful people are going to succeed under those systems. That's the very basis of a meritocracy. And the externalities of that mean that other people benefit from the meritorious and excellent performance of those people.].[01:52:29][Lex Fridman][Maybe it would be good to get your comments... your old stomping ground Harvard. Do you think the President Harvard should have been fired, forced out-].[01:52:37][Ben Shapiro][I mean, I think she should've been fired not over the plagiarism allegations. I think she should have been fired based on her performance just at that congressional hearing. If the word black had been substituted for Jew in that statement by Elise Stefanik, that she was asking about-].[01:52:51][Destiny][Or trans.].[01:52:52][Ben Shapiro][... or literally any other minority in America, maybe with the exception of Asian, then the answer would've been very different coming from Claudine Gay. With that said, I don't think the firing of Claudine Gay really accomplishes very much. Did she get what she deserved? Sure. Does that mean that the underlying DEI equity-based system has been in any way severely damaged? No. I think that this is a way for universities, this is true for McGill and Penn also, to basically throw somebody overboard as the sacrifice to maintain the underlying system that continues to predominate at American universities where they spend literally billions of dollars every year on DEI initiatives and diversity hires and diversity administrators and all of this.].[01:53:31][Ben Shapiro][I mean, one of the costs of education escalating is in the massive administrative function that is now undertaken by universities, as opposed to teaching and cost of dorms and such.].[01:53:42][Lex Fridman][You guys probably agree on a lot of this, right?].[01:53:44][Destiny][Kind of. Maybe, yeah. I don't know what makes things do this, but it feels like we can never have a good thing and then have it end as a good thing. Things always get taken to their extreme, and then we have to fight on those extremes. I would argue that... Back in my day, we called it SJWs, Social Justice Warriors, before it became woke. I think it was like 2013 onwards, whatever. There are aspects to wokeism that I think are good. Like I like the additional representation that we have in media now. I like how, as much as people complain about the internet and how it's regulated, that there are way more groups that are represented on the internet, whether we're talking X, the platform formerly known as Twitter, or Facebook or whatever. Or whether we're pushing women's achievements in school and in the wider workforce. I think that these are all good things.].[01:54:31][Destiny][The issue that you run into is people don't ever have a stopping point, and I think people kind of get lost in this woke-for-woke-sake thing where we start to see these very weird workings of these academic, I guess, arguments that are used for really horrible things. So for instance, I think that you can talk about in the United States, things like white supremacy or things like Oppression or certain demographics, especially with Jim Crow laws and pre-Jim Crow, and you can even talk about effects from that.].[01:54:58][Destiny][But then when you run into this weird world where we've kind of worked these things so that not only is white supremacy still as present today as it ever has been, well actually black people and other minorities can't even be racist. They don't have the power to, because we're going to use a different definition of racism and we can only talk about punching up as opposed to punching down. And then we're actually going to say it's totally okay for these people to say or do whatever they want, and it's never bad. But white people, who have always been the oppressors, even if you're like a trailer park guy whose family's addicted to meth, you have all this privilege, etc, etc.].[01:55:24][Destiny][I think that you run into these issues where woke ism, it starts off as a really good idea and I would argue has achieved really good things, especially in regards to women's education and everything, and then it just gets so academia-ized... There's a word there, academic, whatever, where you take something and you put it into school too much and then it comes out as some Frankenstein cancer baby of horrible things, such that today when I'm reading stuff, and I know Ben is the same way, if I even hear somebody say the word anti-racism, I'm probably ignoring every other thing you have to say.]."
            },
            {
                "title": "Institutional capture",
                "statements": "[01:55:50][Destiny][If you utter the word like colonial anything, I'm probably going to say you probably don't have anything good to say. Yeah, a lot of it has just taken way too far. But you know what I will blame on some of this is I will blame conservatives for some of this-].[01:56:00][Destiny][But you know what I will blame on some of this is I will blame conservatives for some of this because I think one issue that happens, and I think Ben might even agree with me here too, is I think there's two huge problems that have happened in the United States I think broadly speaking is that, one, we become more different than we ever have been. And, two, we become more similar than we ever have been. And when I say this, what I mean is like we're splitting off into these groups and then these groups are enforcing this insane homogeneity between these two separate groups. I think one of these schisms has been conservatives' reluctancy to participate in things related to higher education.].[01:56:33][Destiny][For a long time, conservatives are saying, oh, the educational institutions are against us. Rush Limbaugh talks about how evil the colleges are and blah, blah, blah. And then what happens is conservatives are less and less willing to engage in them. So then you get this scenario or this environment where everybody that's engaged in academia on the administrative side are fucking insane. They're even more so to, and I also want to draw a distinction between the administrators and the faculty because oftentimes when you're reading story after story after story of all of these insane admins that are pushing further and further left, usually the faculty is fighting against it. A lot of the tenure professors, a lot of people in their departments are saying, hold on, well, we actually don't agree with this.].[01:57:09][Destiny][But I feel like, because conservatives for so long have demonized these institutions rather than critically evaluated them and tried to have honest critique and engagement, that they've just completely broken off. And when you only have a bunch of lefties or righties together, all they'll do is they veer off even more into their insane directions. I feel like that's a big problem that we've run into in the country to where conservatives have totally broken off some conversations, broken away from where they won't participate in them anymore, and then the people that you have left just run as far to the left as possible.].[01:57:39][Ben Shapiro][Certainly when you look at certain institutions, I think that one of the things that people on both sides of the aisle are constantly looking at is has the institution suffered such capture that there is just no capacity to fix it? And when you talk about the universities, I'm not going to blame conservatives for the failure of the universities because they haven't been present in major positions at universities since effectively the late 1960s. You can go read Shelby Steele's work on this where he talks about how he used to be, he's now a conservative black person. He was a liberal black person at the time. He was actually quite a radical black activist at the time in the '60s. And he talks about walking into the office of liberal administrators who were largely on his side with regard to civil rights, and being a radical, him claiming that the systems of the university were inherently broken, were inherently wrong, unfixable.].[01:58:24][Ben Shapiro][And he talks about this, it's a very evocative episode where he's talking about how he's smoking, and as he's smoking, the ash is growing more and more, and the ash falls down on this very expensive carpet. And the president of the university who's listening to him rant and rave, Shelby Steele says, \u201cI thought he was going to say something about this. I mean, I was wrecking a thousand dollar carpet in his office being a jackass, and instead, I could see him wilt inside. I could see him collapse. He didn't have the institutional credibility or sort of the spiritual strength to just say, \u2018Listen, I agree with you on some of these things, but you're acting like a jackass.'\u201d And what you see in the late 1960s and early 1970s is in fact the collapse of these institutions to the point where, by the time I was going to college, there was this radical disproportion between conservatives and liberals.].[01:59:08][Ben Shapiro][The problem is that when it comes to a system like the universities, basically you have to separate the universities off into two separate categories. One is STEM, where the universities are still pretty damn good. American universities, when it comes to STEM, are still leading universities in the world. Harvard's main creations these days are coming from actual hard science field. Then you have the liberal arts field in which you basically have a self-perpetuating elite because that's actually how dissertations work. If you have somebody who's very far to the left and you decide that you're going to write a dissertation on the history of American gun rights, the chances that that is going to be approved by your dissertation advisor are much lower than if you happen to write something that tends to agree with the political positions of your dissertation advisor. Now, listen, I think there are open and tolerant professors, even in the liberal arts at these universities.].[01:59:48][Ben Shapiro][I went to these universities. I went to UCLA, I went to Harvard Law School. When I was at Harvard Law School, one of my favorite professors was Lani Guinier. Lani Guinier, they tried to appoint her, I believe, Secretary of Labor under Clinton. And she was too liberal and she got rejected. So she was like a full- on communist. By the time I went there, she was great. We had debates every day. It was wonderful. She used to write me recommendations for my legal jobs. After we left, Randall Kennedy, I don't agree with him very much. Randall Kennedy was terrific professor. There are some professors who are like this. Unfortunately, there tends to be, in these echo chambers, more and more ideological conformity that is rigorously enforced, and it is by left on left. So, for example, when I was at Harvard Law School, the president of the university was another president who ended up being ousted, Larry Summers.].[02:00:26][Ben Shapiro][Larry Summers had been the Secretary of Treasury under Bill Clinton, and he made the critical error of suggesting that perhaps the dearth of women in hard sciences in prestigious positions was due to possibly two factors that people were refusing to talk about. One was the possibility that women actually didn't want to be in hard sciences at nearly the rates that men do, which happens to be true. And, two, was the distribution of STEM IQ, which is something that you certainly were not allowed to talk about. The idea that the men's bell curve when it comes to IQ, particularly on STEM subjects, tends to be shallower than the women's bell curve. So when you get to the very end of the bell curve, what you tend to see is a lot of really dumb guys and a lot of really smarter guys.].[02:01:01][Ben Shapiro][And so when you're talking about the top universities, maybe that has something to do with the disproportion. And he's trying to explain that to say that our systems are not discriminating if we end up with more men than women, maybe more men are applying and more men are qualified. That's quite a... He was ousted for that by a left-wing faculty and general alum network at Harvard University. There's a lot to blame conservatives for surrendering the playing field. I totally agree that conservatives should not have surrendered the playing field in some institutions. Colleges were surrendered a lot earlier than 20 years ago. They were surrendered in the late 1960s, early 1970s.].[02:01:32][Destiny][I think that, a couple of things. One of the big issues that I have with this, I don't know if we call it era of Trumpism or populism, is this total disregard for institutions and this disconnect from participation in the system. So it's one of the big things that I fight with progressives about, who cares because they're all 20 years old, they don't vote anyway. But it's another thing that I noticed with a lot of people that are Trump voters, Trump fans, or whatever, is this idea where we say, this institution is irrevocably destroyed, it's irredeemable, it can't be saved. Nothing that we do can fix it. And I think that what that leads people to doing is, one, they disconnect further.].[02:02:08][Destiny][And then, two, there's a general hopelessness when it comes to how society is ran or structured, such that you fall into that populist brain rot of the only person that can save me is Donald Trump. I can't trust literally anything. And I think that when you start driving people into that direction, all it does is it further amplifies all the problems that you're complaining about. So that's one of the reasons why when we talk about conservative participation, I want there to be more conservatives that are trying to participate in academia. But I feel like the leading thought or the leading speaking out against it is basically saying it's a waste of time. It's completely lost.].[02:02:38][Ben Shapiro][So I think that the alternative to that is that you are seeing on the right a growth of, for example, alternative universities, saying-].[02:02:44][Destiny][Yeah, but this is the worst thing.].[02:02:45][Ben Shapiro][No, I don't think so at all. I think competition is a great way of incentivizing some change on behalf of universities that may have forgotten that there's an entire another side of the aisle in the United States, meaning-].[02:02:54][Destiny][No shot. I don't believe. I don't think even you think that.].[02:02:56][Ben Shapiro][So first of all, first all, let me be clear.].[02:02:57][Destiny][Go ahead.].[02:02:59][Ben Shapiro][I think the entire educational system at the upper levels, if you're not in STEM, is a complete scam. I think it's a complete waste of money. I think it's a complete waste of time. And I think that it's all it is is a formalized, very expensive sorting mechanism for people of IQ. That's all it is. People take an SAT, you go to a good school, you take four years of bullshit. I know. I did it at UCLA. And then, we analyze based on your degree where you should go to law school. I could have gone directly from high school to law school with maybe one year of training, and then done one year of law school, and been done. Okay. The reality is that this is a giant scam, and this is, again, it's a bipartisan problem, but it's just a generalized problem. You want to talk about things that hurt the lower classes in the United States? The bleeding of degrees up is so wild and crazy. There're so many jobs in the United States that should not require a college degree that we now require a college degree to do because there was this weird idea that came over Americans where they mistook correlation for causation. They would say, oh, look, people who go to college are making more money than people who don't go to college, therefore everyone should go to college. Well, maybe the reason is because people who are going to college were better qualified for particular jobs because, on average, not all the time, but on average, a lot of those people were smarter and making more money because of that. And so all you've done is you've now created these additional layers of stratification. So a person who used to be able to get a job with a college degree now has to have a postdoc degree in order to go get that degree.].[02:04:10][Ben Shapiro][A person who used to be able to just graduate high school, now it's de facto, you got to go to JuCo, and then you got to go to college, or nobody's even going to look at your resume. It's really, really terrible for people who can't afford all of that. It's led to this massive increase in educational cost that is inexplicable other than this particular sort of bleed up. And by the way, federal subsidies for higher education, again, one of my problems with federal subsidies for higher education, I'd love for everyone to be able to go to college if qualified to do so and if it is productive. But one of the things I did when I went to law school is I took loans because a bank said I was going to get my money back if I got a law degree from Harvard. But you know when you're not going to get your money back? If you're a bank, you're not going to lend to some dude who wants to major in Art Theory because is that a good bet? There's no collateral.].[02:04:50][Ben Shapiro][If I give a loan for a house, I can go repossess the house. How do I repossess your garbage college degree from UCLA? There's no way to do that. This is the broader conversation about education in general. I think the educational system is cruising for a bruising, and I think all that's necessary for it to completely collapse on the non-STEM side where you actually learn things is for people who employ to simply say, give me your SAT score and I will hire you for an apprenticeship directly out of high school. That it would cut out so much of the middleman. But as far as the general point that you're making about institutions, I may disagree on the education and how far it's gone. In general, I agree with you. So in general, I agree. And, I guess, to use my favorite longest word in the English language here, I would consider myself in many cases an anti-disestablishmentarianist.].[02:05:34][Lex Fridman][Nice.].[02:05:35][Ben Shapiro][See that? I like to drop that because if you're an establishmentarian, that means you like the establishment.].[02:05:39][Destiny][The opposite is disestablishmentarianism.].[02:05:40][Ben Shapiro][Disestablishmentarianism, right? So I'm an anti-].[02:05:41][Lex Fridman][Can you say that word, Destiny?].[02:05:42][Destiny][That's the one we all learned growing up, anti-disestablishmentarianism.].[02:05:44][Ben Shapiro][There you go.].[02:05:45][Destiny][The longest word in the dictionary.].[02:05:48][Ben Shapiro][And so he is also. But I think-].[02:05:48][Destiny][Then some candidate group say, what about supercalifragilisti- and then you're-].[02:05:50][Ben Shapiro][What about [inaudible 02:05:51]?].[02:05:50][Destiny][Or the science terms.].[02:05:53][Ben Shapiro][Exactly.].[02:05:53][Destiny][Or what about the 7,000 letter thing that's from part of biochem.].[02:05:56][Lex Fridman][I got my education in the Soviet Union, so we just did math. Didn't learn any of this.].[02:06:00][Ben Shapiro][That's why you're a useful person.].[02:06:02][Destiny][Soviet Union Math. Was that one plus one, how to make that equal three?].[02:06:04][Ben Shapiro][We know long words, and he streams on the internet, and I talk for a living, so anyway. But the point is that I don't disagree that there is a general populist tendency on all sides of the aisle to look at the institutions and then throw them overboard. I think that some of that is earned by people who are in positions of power at institutions who have completely undermined the faith and credibility of those institutions. I think that you have to examine institution by institutions, which ones are salvageable and which ones are not. So I'm not a full anti-disestablishmentarianism. I'd be partially in that camp. There are certain institutions like higher education in the liberal arts that I think we may be better off without. And then there are certain institutions like, say, participation in American government where when people talk about we need a revolution, like, no, we don't. That's not a thing. We need an evolution. We need change. We can use the system. But I think you have to establish, you have to look at it industry by industry, just institution by institution.].[02:06:58][Destiny][On that position, are institutions, do you think Biden or Trump would salvage you more?].[02:07:01][Ben Shapiro][As far as the institutions?].[02:07:02][Destiny][Yeah.].[02:07:02][Ben Shapiro][I think the institutions in the United States at the governmental level are robust. I think the social institutions are fair.].[02:07:06][Destiny][But I'm just curious on your general view of institutions, do you think Biden or Trump would salvage you more on how you view them?].[02:07:11][Ben Shapiro][I mean, I think that, in rhetoric, Biden would, and then I think that he would tear out the face of the institution wearing it around like a mask, like Hannibal Lecter. I mean-].[02:07:18][Destiny][Even though he resisted some people's calls to pack the court and...].[02:07:22][Ben Shapiro][Yes, because I think that his use of executive power was greater than that of Donald Trump. The power that he had, he used to greater effect than Donald Trump. Donald Trump, again, thrashed up against the sides of the box, but could not get out of it.].[02:07:34][Destiny][For just real quick, because that answer went a lot farther than the initial question. But just on the real quick thing, the reason why I, again, my main problem that I feel like we have today in society is people are getting into their own bubbles. The idea of having conservative schools and liberal schools seems like the saddest thing in the world to me. I would want conservatives and liberals going to school together because I think these people need to interact with each other more, if for no other reason than to say that the other person is not an actual monstrous, horrible entity that wants to destroy the country.].[02:07:59][Ben Shapiro][Listen, I think a classically liberal idea for many schools would not be a bad thing. I think it would be a good thing. I just wonder if that's salvageable. And if it's not salvageable, then the answer to that is to actually create alternative institutions.].[02:08:08][Destiny][I feel like the biggest issue that we have is people are they sort into these different phantom worlds to where, even if you live in the same city, there are totally different worlds that exist between liberals and conservatives. And I feel like one of the big barriers to people understanding the other side, sometimes it's just a little bit of information or a little bit of firsthand experience. So in terms of information, I'm sure you saw, I don't know if this is a full-on study, but they were talking about how some huge percentage of students would change their mind on from the river to the sea when you told them what from the river to sea, actually-].[02:08:36][Ben Shapiro][What the river was and what the sea was?].[02:08:37][Destiny][Yeah. Or when you said like, what does a one state solution mean? A lot of them, such that the numbers went from 70% to 30% in terms of support would fall. And it wasn't because you were doing a radical redefining their whole ideology. You were just giving them a little bit more information. And then something that I've seen on a firsthand level is when I go and speak or do debates at universities, sometimes I'm in very, very, very conservative areas. Some of my fans are trans. Having a trans person show up and talk to conservatives for a little bit, not in a speech, but just in a bar or a setting, a lot of them walk away. They're like, oh, not every trans person is like this insane lunatic from Twitter that is a fucking, an actual crazy person. And then for some of my fans, when they hang out with conservatives like, oh, these guys are actually pretty friendly. I thought they would've all been homophobic, racist, transphobic, and evil, but they're not. They're just like normal people. I feel like we need more of that-].[02:09:16][Ben Shapiro][I totally agree with that. Certainly.].[02:09:17][Destiny][And I feel like on our social media platforms, on our algorithms, and our schools, I feel like we're sorting harder and harder and harder, and any type of rhetoric that encourages the sorting is really bad and damaging. We need to continue to mix up. And there's other things I wanted to talk about, but Lex is opening his mouth.].[02:09:31][Lex Fridman][Destiny, the uniter. Wow.].[02:09:32][Destiny][Like Biden. Not like Trump.]."
            },
            {
                "title": "Monogamy vs open relationships",
                "statements": "[02:09:36][Lex Fridman][As we approach the end, let us descend into the meme further and further. Ben, you're in a monogamous marriage. And Destiny, you've been mostly in an open marriage until recently. How foundational is marriage, monogamous marriage, to the United States of America? Can open marriages work? Are they harmful to society? Ben.].[02:09:58][Ben Shapiro][Marriages are the single most important thing that people can do in the United States because the things within your control are easier to control than the things outside your control. People tend to think about big political change, obviously about things they can do to change the entire system, but the reality is the thing that you can do that best changes society is to get married and have kids and raise your kids responsibly. That is the single best thing that you can do. Can an open marriage work? I mean, I think that it depends on your definition of work. So in my version of work, the answer is no, because what you actually need in order to facilitate the healthy growing of a child is a father and mother who are committed to each other. All ideas about there being no emotional component to sexual activity are completely specious. That it is true for men, that it is for women, but it's not true for either.].[02:10:41][Ben Shapiro][The idea of a full commitment to a human being with whom you genetically create children, which is typically how we've done it throughout human existence, is in fact the fundamental basis for any functional civilization. It allows for the transmission of culture and values. It allows for the transmission of beliefs and responsibility. And it gives the great lie to both, the communitarian lie, the atomistic individualist lie. The communitarian lie is that you belong to the giant community of man, which is not true because you have a family. And your allegiance should be and is naturally to the members of your family first. That's how we learn, and then we expound that out.].[02:11:21][Ben Shapiro][And it also is a lie to the notion that we are all atomistic individuals with no responsibilities. We are born into a world of responsibilities. Everyone is born into a world of responsibilities, and rules, and roles. And those are good. And if we do not actually socialize our children that way, there will be, number one, no children. Number two, there will be no healthy children. Number three, there will be not the foundation for either social fabric, which is the real glue that holds together society or for a functional government. So, yes. Yes, monogamous marriage. I'm a fan. 15 years married, four kids. Yes.].[02:11:55][Lex Fridman][Destiny, what do you think?].[02:11:56][Destiny][I think that when we talk about relationships or marriage, I think something that's really important is we have to talk about whether or not children are being discussed or not. Because I think once you introduce the child aspect, I think the style or the type of relationship that you do is going to become way more important than whatever exists prior to that. I would agree, for instance, in terms of what Ben is saying, that there is probably going to be some structure that is ideal for the care and the raising of a child. I think that having a child gives you a much bigger buy-in to society because now, all of a sudden, you care about a lot of things that you might not have before because not only do you exist in society, you can't just run. Now you've got a child that exists there and you've got to ensure that everything functions smoothly, not just for you, but for that child as well.].[02:12:34][Destiny][And, arguably, although we're getting into weird places I guess in the world now, children are the primary conduit for where you transmit cultural values and everything. The one kind of weird thing that we are coming up against, that we have been coming up against now for some number of decades and we'll continue to is as societies progress, seems like people are having less children. And I actually don't know 100% what the answer is to that question.].[02:13:00][Ben Shapiro][I do.].[02:13:00][Destiny][I'm sure you do. I mean, an implementable answer that works that we know we can get everybody on board with. It seems like, for a large part of human history, having children, and it still is, having children is awesome, and children are cool and children are magical and miraculous and all of this, but you didn't really have much competing for your attention to have a child. When you hit a certain age and you started working, especially if you're a woman, I mean, childbirth is kind of the next step. And then having a family, raising your children, and then doing that was kind of the next step. Nowadays, especially with women being able to work, especially with women having access to birth control, there's a lot available in the world that's competing for the interest of people that could otherwise be having children such that we've almost flipped it, such that, as Ben brought up earlier, wealthy people tend to have less children than not wealthy people, or unless you're part of particular religious communities that push childbirth a lot.].[02:13:46][Destiny][I don't know if I would say there exists a moral imperative on an individual to have children. I think that there's a lot of interesting arguments down that path. I don't know if we're quite at the point yet where we need to say like, oh my God, we're running out of people. We need to have more kids. I don't think we're quite there yet, but we are seeing weird demographic trends that are having big impacts on how countries are playing out. For instance, the fact that we have a disproportionately huge aging population that needs to be taken care of with medical expenses and everything, that vote in different ways than our younger population, and that when they die off, the way that society is going to look is going to be a lot different. I don't actually have a, I'm not entirely sure what the future's going to look like in terms of pushing people to have kids when every single industrialized country, as they become more industrialized, have fewer and fewer and fewer children.]."
            },
            {
                "title": "Rapid fire questions",
                "statements": "[02:14:29][Lex Fridman][Rapid fire questions.].[02:14:32][Ben Shapiro][My answer was go to church.].[02:14:33][Destiny][Religion, yeah. I figured.].[02:14:35][Lex Fridman][Well, we could talk about religion, but that's not rapid fire at all. Let me ask, this is from the internet, does body count matter?].[02:14:42][Destiny][Jesus Christ. You're really bringing up the red pill stuff.].[02:14:47][Lex Fridman][Are you avoiding answering?].[02:14:48][Destiny][I mean, it's totally, it depends on who you are. If you're somebody that doesn't care about it, it doesn't. If you're somebody that does care about it, yeah, it does, of course. Depends on the-].[02:14:48][Ben Shapiro][The answer is yes.].[02:14:56][Lex Fridman][Okay. Should porn be banned?].[02:14:58][Destiny][No.].[02:15:01][Ben Shapiro][If you could do it, yes. There is no benefit to pornography. It's a waste of time and destructive to the human soul.].[02:15:10][Lex Fridman][I can't believe I'm asking this question. Is OnlyFans empowering or destructive for women?].[02:15:17][Destiny][Jesus. These are rapid fire?].[02:15:19][Lex Fridman][Yeah, just you can't-].[02:15:20][Destiny][I mean, it's probably empowering for the ones that are making a lot of money off it. It probably feels disempowering for others that feel affected by the cultural norms set by women that do OnlyFans. There's my rapid fire answer.].[02:15:28][Ben Shapiro][It's destructive to even the ones who are making a lot of money because when you degrade yourself to being just a set of human body characteristics that other people jack off to, it's bad for you and it's bad for them.].[02:15:38][Lex Fridman][Is rap music...].[02:15:40][Ben Shapiro][Absolutely.].[02:15:41][Lex Fridman][Have you evolved on this or-].[02:15:43][Ben Shapiro][Have I evolved on this? So again, I'm going to go to what's the definition of music? My original argument about rap was that music involves the following three elements. Rhythm, melody, harmony. Rap typically involves maybe one of those. There maybe, maybe a melody, maybe sometimes. So it depends on the kind of rap. With that said, I could be convinced on this issue. But, listen, I'm a classical violinist. I mean, it's how I was raised. I listen to Beethoven and Brahms and Mozart in the car with my kids. So is it comparable, is it in the same category as Beethoven, Brahms, and Mozart? I have a very hard time sticking it in the same category as that.].[02:16:23][Lex Fridman][All right. You're both world-class debaters, even public intellectuals, if I can say that.].[02:16:31][Destiny][Jesus.].[02:16:32][Ben Shapiro][[inaudible 02:16:32] real hard here.].[02:16:33][Lex Fridman][I know. You both care about the truth. What is your process of arriving at the truth?].[02:16:41][Destiny][I think it's really important to, everybody will say that they're objective and that they are nonpartisan. I think it's really important to have mental safeguards for bad opinions. So, for instance, a couple of things that I'll ask myself is for a particular debate that I'm having, can I argue convincingly both sides of the debate? If I can't, I won't bother having the debate because I realize that I'm probably too partisanly dug in if I can't even represent an opposite argument here. Another question that you might ask yourself is like, well, what would it take to convince you out of a certain position? If you feel very strongly that Medicare for All is a good system by which to run the United States healthcare, and somebody says, well, what would it take you to convince you otherwise? If you can't even fathom, well, what would it take to convince me otherwise, you're probably too dug into a position.].[02:17:23][Destiny][So I think if you go through life saying, well, I try my best to be unbiased rather than saying, I try my best to be aware of my biases because the latter is more realistic and the former is literally impossible unless you're a computer. So I think having actual mental practices that you engage in to try to counter some of the biases that you have is more important than trying to pretend that you're free of all biases and then consuming all your media from one source.].[02:17:47][Lex Fridman][Ben?].[02:17:49][Ben Shapiro][I mean, I agree with a lot of that. I think that the easiest practical guide is read a bunch of different things from a bunch of different sources, and where they cross is probably the set of facts, and then everything else is extrapolated opinion from different premises. That's sort of the short story. So read the New York Times and Breitbart, and they're going to disagree on a lot, but if the core of the story-].[02:18:09][Lex Fridman][And the Daily Wire.].[02:18:10][Ben Shapiro][Certainly read the Daily Wire. If you read the Daily Wire and you read the Washington Post and there's a nexus of the same thing, then you can pretty well guarantee that, at least, if we're all blind men feeling the elephant, at least, if we're all feeling the trunk, we know that there's a trunk there. You may not know what the elephant is.].[02:18:26][Lex Fridman][And if you're feeling frisky, then watch Destiny as well.].[02:18:31][Destiny][Thanks.].[02:18:31][Lex Fridman][You've talked about having a conversation, debating Ben for a long time. What is your favorite thing about Ben Shapiro?].[02:18:40][Destiny][My favorite thing about Ben Shapiro is, at least when we're in election season, he's very critical of his own party. I appreciate that. I feel like Ben generally tries to adhere more to the fact-based arguments than other conservatives that I listen to, which is something that I appreciate because it's more fun to fight on the factual grounds of discussing things like foreign policy or whatever, rather than people that only inhabit the idealistic or philosophical grounds because they don't want to learn about any of the facts. So I appreciate that.].[02:19:07][Lex Fridman][Ben, you've gotten a chance to talk to Destiny now. What do you like about the guy?].[02:19:11][Ben Shapiro][A lot of the same sorts of things, but it's really fun to see how you do your process. That is a cool thing. That is a cool thing. And it's a gift to the audience because, honestly, doing what we do, so much of what we do is sitting and reading and being behind closed doors and educating yourself and talking with people. But getting to watch you do it in real time is a really cool window into how people think and how people learn. So that's a really neat thing.].[02:19:30][Lex Fridman][Well, gentlemen, this was incredible. It's an honor. Thank you for doing this today.].[02:19:34][Ben Shapiro][Thanks a lot.].[02:19:35][Destiny][Thanks for having me.].[02:19:36][Lex Fridman][Thanks for listening to this debate between Ben Shapiro and Destiny. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from Aristotle. The basis of a democratic state is liberty. Thank you for listening and hope to see you next time.]."
            }
        ]
    },
    {
        "url": "https://www.youtube.com/watch?v=JN3KPFbWCy8",
        "title": "Elon Musk: War, AI, Aliens, Politics, Physics, Video Games, and Humanity | Lex Fridman Podcast #400",
        "chapters": [
            {
                "title": "Introduction",
                "statements": ""
            },
            {
                "title": "War and human nature",
                "statements": "[00:00:00][Lex Fridman][The following is a conversation with Elon Musk, his fourth time on this, the Lex Fridman Podcast. I thought you were going to finish it. It's one of the greatest themes in all of film history.].[00:00:31][Elon Musk][Yeah, that's great.].[00:00:33][Lex Fridman][So I was just thinking about the Roman Empire, as one does.].[00:00:38][Elon Musk][Is that whole meme where all guys are thinking about the Roman Empire at least once a day?].[00:00:44][Lex Fridman][And half the population is confused whether it's true or not. But more seriously, thinking about the wars going on in the world today, and as you know, war and military conquest has been a big part of Roman society and culture, and I think has been a big part of most empires and dynasties throughout human history.].[00:01:06][Elon Musk][Yeah, they usually came as a result of conquest. I mean, there's some like the Hapsburg Empire where there was just a lot of clever marriages.].[00:01:16][Lex Fridman][But fundamentally there's an engine of conquest and they celebrate excellence in warfare, many of the leaders were excellent generals, that kind of thing. So a big picture question, Grok approved, I asked if this is a good question to ask.].[00:01:33][Elon Musk][Tested, Grok approved. Yeah.].[00:01:36][Lex Fridman][At least on fun mode. To what degree do you think war is part of human nature versus a consequence of how human societies are structured? I ask this as you have somehow controversially been a proponent of peace.].[00:01:57][Elon Musk][I'm generally a proponent of peace. I mean, ignorance is perhaps, in my view, the real enemy to be countered. That's the real hard part, not fighting other humans, but all creatures fight. I mean, the jungle is... People think of nature as perhaps some sort of peaceful thing, but in fact it is not. There's some quite funny Werner Herzog thing where he is in the jungle saying that it's basically just murder and death in every direction. The plants and animals in the jungle are constantly trying to kill each other every single day, every minute. So it's not like we're unusual in that respect.].[00:02:40][Lex Fridman][Well, there's a relevant question here, whether with greater intelligence comes greater control over these base instincts for violence.].[00:02:49][Elon Musk][Yes. We have much more vulnerability to control our limbic instinct for violence than say a chimpanzee. And in fact, if one looks at say, chimpanzee society, it is not friendly. I mean, the Bonobos are an exception, but chimpanzee society is filled with violence and it's quite horrific, frankly. That's our limbic system in action. You don't want to be on the wrong side of a chimpanzee, it'll eat your face off and tear your nuts off.].[00:03:22][Lex Fridman][Yeah. Basically there's no limits or ethics or they almost had just war. There's no just war in the chimpanzee societies. Is war and dominance by any means necessary?].[00:03:33][Elon Musk][Yeah. Chimpanzee society is a permanent version of human society. They're not like peace loving basically at all. There's extreme violence and then once in a while, somebody who's watched too many Disney movies decides to raise a chimpanzee as a pet, and then that eats their face or they're nuts off or chew their fingers off and that kind of thing. It's happened several times.].[00:03:58][Lex Fridman][Ripping your nuts off is an interesting strategy for interaction.].[00:04:02][Elon Musk][It's happened to people. It's unfortunate. That's, I guess, one way to ensure that the other chimp doesn't contribute to the gene pool.].[00:04:10][Lex Fridman][Well, from a martial arts perspective is the fascinating strategy.].[00:04:15][Elon Musk][The nut rougher.].[00:04:18][Lex Fridman][I wonder which of the martial arts teaches that one.].[00:04:21][Elon Musk][I think it's safe to say if somebody's got your nuts in their hands and as the option of roughing them off, you'll be amenable to whatever they want.]."
            },
            {
                "title": "Israel-Hamas war",
                "statements": "[00:04:30][Lex Fridman][Yeah. Safe to say. So, like I said, somehow controversially, you've been a proponent of peace on Twitter on X.].[00:04:38][Elon Musk][Yeah.].[00:04:39][Lex Fridman][So let me ask you about the wars going on today and to see what the path to peace could be. How do you hope the current war in Israel and Gaza comes to an end? What path do you see that can minimize human suffering in the longterm in that part of the world?].[00:04:54][Elon Musk][Well, I think that part of the world is definitely, if you look up... There is no easy answer in the dictionary. It'll be the picture of the Middle East in Israel especially. So there is no easy answer. This is strictly my opinion is that the goal of Hamas was to provoke an overreaction from Israel. They obviously did not expect to have a military victory, but they really wanted to commit the worst atrocities that they could in order to provoke the most aggressive response possible from Israel, and then leverage that aggressive response to rally Muslims worldwide for the course of Gaza and Palestine, which they have succeeded in doing. So the counterintuitive thing here, I think that the thing that I think should be done, even though it's very difficult, is that I would recommend that Israel engage in the most conspicuous acts of kindness possible, everything, that is the actual thing that we're taught the goal of Hamas.].[00:06:19][Lex Fridman][So in some sense, the degree that makes sense in geopolitics turn the other cheek implemented.].[00:06:26][Elon Musk][It's not exactly turn the other cheek because I do think that it is appropriate for Israel to find the Hamas members and either kill them or incarcerate them. That's something has to be done because they're just going to keep coming otherwise. But in addition to that, they need to do whatever they can. There's some talk of establishing, for example, a mobile hospital. I'd recommend doing that. Just making sure that there's food, water, medical necessities and just be over the top about it and be very transparent. So [inaudible 00:07:22] can claim it's a trick. Just put webcam on the thing or 24, 7.].[00:07:29][Lex Fridman][Deploy acts of kindness.].[00:07:31][Elon Musk][Yeah, conspicuous acts of kindness that are unequivocal, meaning they can't be somehow because Hamas will then their response will be, \u201cOh, it's a trick.\u201d Therefore, you have to counter how it's not a trick.].[00:07:47][Lex Fridman][This ultimately fights the broader force of hatred in the region.].[00:07:51][Elon Musk][Yes. And I'm not sure who said it, it's an [inaudible 00:07:54] saying, but an eye for an eye makes everyone blind. Now, that neck of the woods, they really believe in the whole eye for an eye thing. But you really have... If you're not going to just outright commit genocide against an entire people, which obviously would not be acceptable to really, shouldn't be acceptable to anyone, then you're going to leave basically a lot of people alive who subsequently hate Israel. So really the question is like for every Hamas member that you kill, how many did you create? And if you create more than you killed, you've not succeeded. That's the real situation there. And it's safe to say that if you kill somebody's child in Gaza, you've made at least a few homeless members who will die just to kill an Israeli. That's the situation. But I mean, this is one of the most contentious subjects one could possibly discuss. But I think if the goal ultimately is some sort of long-term piece, one has to look at this from the standpoint of over time, are there more or fewer terrorists being created?].[00:09:26][Lex Fridman][Let me just linger on war.].[00:09:29][Elon Musk][Yeah, war, safe to say, wars always existed and always will exist.].[00:09:33][Lex Fridman][Always will exist.].[00:09:34][Elon Musk][Always has existed and always will exist.].[00:09:37][Lex Fridman][I hope not. You think it'll always-].[00:09:42][Elon Musk][There will always be war. There's a question of just how much war and there's sort of the scope and scale of war. But to imagine that there would not be any war in the future, I think would be a very unlikely outcome.].[00:09:55][Lex Fridman][Yeah. You talked about the Culture series. There's war even there.].[00:09:58][Elon Musk][Yes. It's a giant war. The first book starts off with a gigantic galactic war where trillions die trillions.].[00:10:07][Lex Fridman][But it still nevertheless protects these pockets of flourishing. Somehow you can have galactic war and still have pockets of flourishing.].[00:10:18][Elon Musk][Yeah, I guess if we are able to one day expand to fool the galaxy or whatever, there will be a galactic war at some point.].[00:10:31][Lex Fridman][I mean, the scale of war has been increasing, increasing, increasing. It's like a race between the scale of suffering and the scale of flourishing.].[00:10:38][Elon Musk][Yes.]."
            },
            {
                "title": "Military-Industrial Complex",
                "statements": "[00:10:41][Lex Fridman][A lot of people seem to be using this tragedy to beat the drums of war and feed the military industrial complex. Do you worry about this, the people who are rooting for escalation and how can it be stopped?].[00:10:56][Elon Musk][One of the things that does concern me is that there are very few people alive today who actually viscerally understand the horrors of war, at least in the US. I mean, obviously there are people on the front lines in Ukraine and Russia who understand just how terrible war is, but how many people in the West understand it? My grandfather was in World War II. He was severely traumatized. He was there I think for almost six years in Eastern North Africa and Italy. All his friends were killed in front of him, and he would've died too, except they randomly gave some, I guess IQ test or something, and he scored very high. He was not an officer. He was I think a corporal or a sergeant or something like that because he didn't finish high school because he had to drop out of high school because his dad died and he had to work to support his siblings. So because he didn't graduate high school, he was not eligible for the offset corps.].[00:11:57][Elon Musk][So he kind of got put into the cannon fodder category basically. But then randomly they gave him this test. He was transferred to British intelligence in London. That's where we met my grandmother. But he had PTSD next level, next level. I mean, just didn't talk, just didn't talk. And if you tried talking to him, he'd just tell you to shut up. And he won a bunch of medals, never bragged about it once, not even hinted nothing. I found out about it because his military records were online. That's how I know. So he would say like, \u201cNo way in hell do you want to do that again.\u201d But how many people... Obviously, he died, he 20 years ago or longer, actually 30 years ago. How many people are alive that remember World War II? Not many.].[00:12:54][Lex Fridman][And the same perhaps applies to the threat of nuclear war.].[00:13:01][Elon Musk][Yeah, I mean, there are enough nuclear bombs pointed at United States to make the radioactive revel balance many times.].[00:13:10][Lex Fridman][There's two major wars going on right now. So you talked about the threat of AGI quite a bit, but now as we sit here with the intensity of conflict going on, do you worry about nuclear war?].[00:13:25][Elon Musk][I think we shouldn't discount the possibility of nuclear war. It is a civilizational threat. Right now, I could be wrong, but I think the current probability of nuclear war is quite low. But there are a lot of nukes pointed at us, and we have a lot of nukes pointed at other people. They're still there. Nobody's put their guns away. The missiles are still in the silos.].[00:13:57][Lex Fridman][And the leaders don't seem to be the ones with the nukes talking to each other.].[00:14:03][Elon Musk][No, there are wars which are tragic and difficult on a local basis. And then there are wars which are civilization ending or has that potential. Obviously, global thermonuclear warfare has high potential to end civilization, perhaps permanently, but certainly to severely wound and perhaps set back human progress to the Stone Age or something. I don't know. Pretty bad. Probably scientists and engineers want to be super popular after that as well. You got us into this mess. So generally, I think we obviously want to prioritize civilizational risks over things that are painful and tragic on a local level, but not civilizational.]."
            },
            {
                "title": "War in Ukraine",
                "statements": "[00:15:00][Lex Fridman][How do you hope the war in Ukraine comes to an end? And what's the path, once again to minimizing human suffering there?].[00:15:08][Elon Musk][Well, I think that what is likely to happen, which is really pretty much the way it is, is that something very close to the current lines will be how a ceasefire or truce happens. But you just have a situation right now where whoever goes on the offensive will suffer casualties at several times the rate of whoever's on the defense because you've got defense in depth, you've got minefields, trenches, anti-tank defenses. Nobody has air superiority because the anti-aircraft missiles are really far better than the aircraft. They're far more of them. And so neither side has air superiority. Tanks are basically death traps, just slow moving, and they're not immune to anti-tank weapons. So you really just have long range artillery and infantry ranges. It's World War I all over again with drones, thrown old drones, some drones there.].[00:16:25][Lex Fridman][Which makes the long range artillery just that much more accurate and better, and so more efficient at murdering people on both sides.].[00:16:34][Elon Musk][So whoever is... You don't want to be trying to advance from either side because the probability of dying is incredibly high. So in order to overcome defense in depth, trenches and minefields, you really need a significant local superiority in numbers. Ideally combined alms where you do a fast attack with aircraft, a concentrated number of tanks, and a lot of people, that's the only way you're going to punch through a line and then you're going to punch through and then not have reinforcements just kick you right out again. I mean, I really recommend people read World War I warfare in detail. That's rough. I mean, the sheer number of people that died there was mind-boggling.].[00:17:37][Lex Fridman][And it's almost impossible to imagine the end of it that doesn't look like almost exactly like the beginning in terms of what land belongs to who and so on. But on the other side of a lot of human suffering, death and destruction of infrastructure.].[00:17:56][Elon Musk][Yes. The thing that... The reason I proposed some sort of truce or peace a year ago was because I've predicted pretty much exactly what would happen, which is a lot of people dying for basically almost no changes in land and the loss of the flower of Ukrainian and Russian youth. And we should have some sympathy for the Russian boys as well as the Ukrainian boys, because Russian boys, because boys didn't ask to be on their frontline. They have to be. So there's a lot of sons not coming back to their parents, and I think most of them don't hate the other side. It's sort of like as this saying comes from World War I, it's like young boys who don't know each other killing each other on behalf of old men that do know each other. The hell's the point of that.].[00:19:02][Lex Fridman][So Volodymyr Zelenskyy said that he's not, or has said in the past, he's not interested in talking to Putin directly. Do you think he should sit down man to man, lead a leader, and negotiate peace?].[00:19:14][Elon Musk][Look, I think I would just recommend do not send the flower of Ukrainian youth to die in trenches, whether he talks to Putin or not, just don't do that. Whoever goes on the offensive will lose massive numbers of people and history will not look kindly upon them.]."
            },
            {
                "title": "China",
                "statements": "[00:19:42][Lex Fridman][You've spoken honestly about the possibility of war between US and China in the longterm if no diplomatic solution is found, for example, on the question of Taiwan and One China policy, how do we avoid the trajectory where these two superpowers clash?].[00:19:58][Elon Musk][Well, it's worth reading that book on the, difficult to pronounce, the Thucydides Trap, I believe it's called. I love war history. I like inside out and backwards. There's hardly a battle I haven't read about. And trying to figure out what really was the cause of victory in any particular case as opposed to what one side or another claim the reason.].[00:20:21][Lex Fridman][Both the victory and what sparked the war and-].[00:20:24][Elon Musk][Yeah, yeah.].[00:20:25][Lex Fridman][The whole thing.].[00:20:26][Elon Musk][Yeah. So that Athens and Sparta is a classic case. The thing about the Greek is they really wrote down a lot of stuff. They loved writing. There are lots of interesting things that happened in many parts of the world, but people didn't write down, so we don't know what happened or they didn't really write in detail. They just would say, \u201cWe had a battle and we won.\u201d And what? Can you add a bit more? The Greeks, they really wrote a lot. They were very articulate on... They just love writing. And we have a bunch of that writing as preserved. So we know what led up to the Peloponnesian War between the Spartanand Athenian Alliance, and we know that they saw it coming.].[00:21:16][Elon Musk][Spartans didn't write... They also weren't very verbose by their nature, but they did write, but they weren't very verbose. They were [inaudible 00:21:23]. But the Athenians and the other Greeks wrote a line, and Spartan was really kind of like the leader of Greece. But Athens grew stronger and stronger with each passing year. And everyone's like, \u201cWell, that's inevitable that there's going to be a clash between Athens and Sparta. Well, how do we avoid that?\u201d And actually they saw it coming and they still could not avoid it. So at some point, if one group, one civilization or country or whatever exceeds another sort of like the United States has been the biggest kid on the block since I think around 1890 from an economic standpoint.].[00:22:14][Elon Musk][So the United States has been the most powerful economic engine in the world longer than anyone's been alive. And the foundation of war is economics. So now we have a situation in the case of China where the economy is likely to be two, perhaps three times larger than that of the US. So imagine you're the biggest kid on the block for as long as anyone can remember, and suddenly a kid comes along who's twice your size.].[00:22:55][Lex Fridman][So we see it coming, how is it possible to stop? Let me throw something out there, just intermixing of cultures understanding there does seem to be a giant cultural gap in understanding of each other. And you're an interesting case study because you are an American, obviously you've done a lot of incredible manufacture here in the United States, but you also work with China.].[00:23:20][Elon Musk][I've spent a lot of time in China and met with the leadership many times.].[00:23:22][Lex Fridman][Maybe a good question to ask is, what are some things about China that people don't understand, positive just in the culture? What's some interesting things that you've learned about the Chinese?].[00:23:36][Elon Musk][Well, the sheer number of really smart, hardworking people in China is incredible. There are really say how many smart, hardworking people are there in China? There's far more of them there than there are here, I think, in my opinion. And they've got a lot of energy. So I mean, the architecture in China that's in recent years is far more impressive than the US. I mean the train stations, the buildings, the high speed rail, everything, it's really far more impressive than what we have in the US. I mean, I recommend somebody just go to Shanghai and Beijing, look at the buildings and go to take the train from Beijing to Xian, where you have the terracotta warriors. China's got an incredible history, very long history, and I think arguably in terms of the use of language from a written standpoint, one of the oldest, perhaps the oldest written language, and then China, people did write things down.].[00:24:50][Elon Musk][So now China historically has always been, with rare exception, been internally focused. They have not been inquisitive. They've fought each other. There've been many, many civil wars. In the Three Kingdoms war, I believe they lost about 70% of their population. So they've had brutal internal wars, civil wars that make the US Civil War look small by comparison. So I think it's important to appreciate that China is not monolithic. We sort of think of China as a sort of one entity of one mind. And this is definitely not the case. From what I've seen and I think most people who understand China would agree, people in China think about China 10 times more than they think about anything outside of China. So it's like 90% of their consideration is internal.].[00:26:01][Lex Fridman][Well, isn't that a really positive thing when you're talking about the collaboration and the future piece between superpowers when you're inward facing, which is focusing on improving yourself versus focusing on quote, unquote improving others through military might.].[00:26:18][Elon Musk][The good news, the history of China suggests that China is not inquisitive, meaning they're not going to go out and invade a whole bunch of countries. Now they do feel very strongly... So that's good. I mean, because a lot of very powerful countries have been inquisitive. The US is also one of the rare cases that has not been inquisitive. After World War II, the US could have basically taken over the world in any country, we've got nukes, nobody else has got nukes. We don't even have to lose soldiers. Which country do you want? And the United States could have taken over everything and it didn't. And the United States actually helped rebuild countries. So it helped rebuild Europe, helped rebuild Japan. This is very unusual behavior, almost unprecedented.].[00:27:10][Elon Musk][The US did conspicuous acts of kindness like the Berlin Airlift. And I think it's always like, well, America's done bad things. Well, of course America's done bad things, but one needs to look at the whole track record and just generally, one sort of test would be how do you treat your prisoners at war? Or let's say, no offense to the Russians, but let's say you're in Germany, it's 1945, you've got the Russian Army coming one side and you've got the French, British and American Army's coming the other side, who would you like to be just surrendered to? No country is [inaudible 00:27:58] perfect, but I recommend being a POW with the Americans. That would be my choice very strongly.].[00:28:07][Lex Fridman][In the full menu of POWs in the US.].[00:28:08][Elon Musk][Very much so. And in fact, Wernher von Braun, a smart guy, was like, \u201cWe've got to be captured by the Americans.\u201d And in fact, the SS was under orders to execute von Braun and all of the German rocket conditioners, and they narrowly escaped. They said they were going out for a walk in the woods. They left in the middle of winter with no coats and then ran, but no food, no coats, no water, and just ran like hell and ran West and Vice Sherlock, I think his brother found a bicycle or something and then just cycled West as fast as he couldn't have found a US patrol. So anyway, that's one way you can tell morality is where do you want to be a PW? It's not fun anywhere, but some places are much worse than others. Anyway, so America has been, while far from perfect, generally a benevolent force, and we should always be self-critical and we try to be better, but anyone with half a brain knows that.].[00:29:31][Elon Musk][So I think there are... In this way, China and the United States are similar. Neither country has been acquisitive in a significant way. So that's a shared principle, I guess. Now, China does feel very strongly about Taiwan. They've been very clear about that for a long time. From this standpoint, it would be like one of the states is not there like Hawaii or something like that but more significant than Hawaii. And Hawaii is pretty significant for us. So they view it as really there's a fundamental part of China, the island of Formosa, not Taiwan, that is not part of China, but should be. And the only reason it hasn't been is because the US Pacific fleet.].[00:30:32][Lex Fridman][And is their economic power grows and is their military power grows, the thing that they're clearly saying is their interest will clearly be materialized.].[00:30:46][Elon Musk][Yes, China has been very clear that they'll incorporate Taiwan peacefully or militarily, but that they will incorporate it from their standpoint is 100% likely.].[00:31:04][Lex Fridman][Something you said about conspicuous acts of kindness as a geopolitical policy, it almost seems naive, but I'd venture to say that this is probably the path forward, how you avoid most wars. Just as you say it sounds naive, but it's kind of brilliant. If you believe in the goodness of underlying most of human nature, it just seems like conspicuous acts of kindness can reverberate through the populace of the countries involved and deescalate.].[00:31:44][Elon Musk][Absolutely. So after World War I, they made a big mistake. They basically tried to lump all of blame on Germany and saddle Germany with impossible reparations. And really there was quite a bit of blame to go around for World War I, but they try to put it all in Germany and that laid the seeds for World War II. So a lot of people, were not just Hitler, a lot of people felt wronged and they wanted vengeance and they got it.].[00:32:38][Lex Fridman][People don't forget.].[00:32:41][Elon Musk][Yeah, you kill somebody's father, mother or son, daughter, they're not going to forget it. They'll want vengeance. So after World War II, they're like, \u201cWell, the Treaty of Versi was a huge mistake in World War I. And so this time, instead of crushing the losers, we're actually going to help them with the module plan, and we're going to help rebuild Germany. We're going to help rebuild Austria and Italy and whatnot.\u201d So that was the right move.].[00:33:26][Lex Fridman][It does feel like there's a profound truth to the conspicuous acts of kindness being an antidote to this.].[00:33:37][Elon Musk][Something must stop the cycle of reciprocal violence. Something must stop it, or it'll never stop. Just eye for an eye, tooth for a tooth, limb for a limb, life for a life forever and ever.]."
            },
            {
                "title": "xAI Grok",
                "statements": "[00:33:57][Lex Fridman][To escape briefly the darkness, was some incredible engineering work, xAI just released Grok AI assistant that I've gotten a chance to play with. It's amazing on many levels. First of all, it's amazing that a relatively small team in a relatively short amount of time was able to develop this close to state-of-the-art system. Another incredible thing is there's a regular mode and there's a fun mode.].[00:34:23][Elon Musk][Yeah, I guess I'm to blame for that one.].[00:34:27][Lex Fridman][First of all, I wish everything in life had a fun mode.].[00:34:29][Elon Musk][Yeah.].[00:34:30][Lex Fridman][There's something compelling beyond just fun about the fun mode interacting with a large language model. I'm not sure exactly what it is because I've only have had a little bit of time to play with it, but it just makes it more interesting, more vibrant to interact with the system.].[00:34:47][Elon Musk][Yeah, absolutely. Our AI, Grok, is modeled after The Hitchhiker's Guide to the Galaxy, which is one of my favorite books, which it's a book on philosophy. It's-].[00:35:00][Elon Musk][My favorite books, it's a book on philosophy, disguises book on humor. And I would say that forms the basis of my philosophy, which is that we don't know the meaning of life, but the more we can expand the scope and scale of consciousness, digital and biological, the more we're able to understand what questions to ask about the answer that is the universe. So I have a philosophy of curiosity.].[00:35:34][Lex Fridman][There is generally a feeling like this AI system has an outward looking, like the way you are sitting with a good friend looking up at the stars, asking pod head like questions about the universe, wondering what it's all about. The curiosity that you talk about. No matter how mundane the question I ask it, there's a sense of cosmic grandeur to the whole thing.].[00:35:59][Elon Musk][Well, we are actually working hard to have engineering math, physics answers that you can count on. So for the other AIs out there, these so-called large language models, I've not found the engineering to be reliable. It unfortunately hallucinates most when you at least want it to hallucinate. So when you're asking important, difficult questions, that's when it tends to be confidently wrong. So we're really trying hard to say, okay, how do we be as grounded as possible? So you can count on the results, trace things back to physics first principles, mathematical logic. So underlying the humor is an aspiration to adhere to the truth of the universe as closely as possible.].[00:37:01][Lex Fridman][That's really tricky.].[00:37:02][Elon Musk][It is tricky. So that's why there's always going to be some amount of error. But do we want to aspire to be as truthful as possible about the answers with acknowledged error. So that there was always, you don't want to be confidently wrong, so you're not going to be right every time, but you want to minimize how often you're confidently wrong. And then like I said, once you can count on the logic as being not violating physics, then you can start to bull on that to create inventions, like invent new technologies. But if you cannot count on the foundational physics being correct, obviously the inventions are simply wishful thinking, imagination land. Magic basically.].[00:38:01][Lex Fridman][Well, as you said, I think one of the big goals of XAI is to understand the universe.].[00:38:06][Elon Musk][Yes, that's how simple three word mission.].[00:38:13][Lex Fridman][If you look out far into the future, do you think on this level of physics, the very edge of what we understand about physics, do you think it will make the sexiest discovery of them as we know now, unifying general relativity and quantum mechanics? So coming up with a theory of everything, do you think it could push towards that direction, almost like theoretical physics discoveries?].[00:38:38][Elon Musk][If an AI cannot figure out new physics, it's clearly not equal to humans, nor has surpassed humans because humans have figured out new physics. Physics is just deepening what's inside into how reality works. And then there's engineering which is inventing things that have never existed. Now the range of possibilities for engineering is far greater than for physics because once you figure out the rules of the universe, that's it. You've discovered things that already existed. But from that you can then build technologies that are really almost limitless in the variety. And it's like once you understand the rules of the game properly, and with current physics, we do at least at a local level, understand how physics works very well. Our ability to predict things is incredibly good. Degree to which quantum mechanics can predict outcomes is incredible. That was my hardest class in college by the way. My senior quantum mechanics class was harder than all of my other classes put together.].[00:39:50][Lex Fridman][To get an AI system, a large language model be as reliable as quantum mechanics and physics is very difficult.].[00:40:01][Elon Musk][Yeah. You have to test any conclusions against the ground truth of reality. Reality is the ultimate judge. Like physics is the law, everything else is a recommendation. I've seen plenty of people break the laws made by man, but none break the laws made by physics.].[00:40:15][Lex Fridman][It's a good test actually. If this LLM understands and matches physics, then you can more reliably trust whatever it thinks about the current state of politics in some sense.].[00:40:28][Elon Musk][And it's also not the case currently that even that its internal logic is not consistent. So especially with the approach of just predicting a token predict token, predict token, it's like a vector sum. You're summing up a bunch of vectors, but you can get drift. A little bit of error adds up and by the time you are many tokens down the path, it doesn't make any sense.].[00:40:59][Lex Fridman][So it has to be somehow self-aware about the drift.].[00:41:02][Elon Musk][It has to be self-aware about the drift, and then look at the thing as a gestalt as a whole and say it doesn't have coherence as a whole. When authors write books, they will write the book and then they'll go and revise it, take into account all the end and the beginning and the middle and rewrite it to achieve coherence so that it doesn't end up at a nonsensical place.].[00:41:33][Lex Fridman][Maybe the process of revising is what reasoning is, and then the process of revising is how you get closer and closer to truth. At least I approached that way, you just say a bunch of bullshit first and then you get it better. You start a bullshit and then you-].[00:41:51][Elon Musk][Create a draft and then you iterate on that draft until it has coherence, until it all adds up basically.].[00:41:59][Lex Fridman][Another question about theory of everything, but for intelligence, as you're exploring this with XAI, creating this intelligence system? Do you think there is a theory of intelligence where you get to understand what is the I in AGI and what is the I in human intelligence?].[00:42:22][Elon Musk][No, I in team America. Wait, there is.].[00:42:24][Lex Fridman][No, it's going to be stuck in my head now. Yeah, there's no me and whatever in quantum mechanics, wait. I mean is that part of the process of discovering, understanding the universe is understanding intelligence?].[00:42:50][Elon Musk][Yeah. I think we need to understand intelligence, understand consciousness. I mean there are some fundamental questions of what is thought, what is emotion? Is it really just one atom bumping into another atom? It feels like something more than that. So I think we're probably missing some really big things.].[00:43:18][Lex Fridman][Something that'll be obvious in retrospect. You put the whole consciousness and motion.].[00:43:26][Elon Musk][Well, some people would quote like a soul religion, be a soul. You feel like you're you, I mean you don't feel like you're just a collection of atoms, but on what dimension does thought exist? What dimension does do emotions exist? Because we feel them very strongly. I suspect there's more to it than atoms bumping into atoms.].[00:43:52][Lex Fridman][And maybe AI can pave the path to the discovery whatever the hell that thing is.].[00:43:58][Elon Musk][Yeah. What is consciousness? When you put the atoms in a particular shape, why are they able to form thoughts and take actions and feelings?].[00:44:10][Lex Fridman][And even if it is an illusion, why is this illusion so compelling?].[00:44:13][Elon Musk][Yeah. Why does the solution exist? On what plane does the solution exist? And sometimes I wonder is either perhaps everything's conscious or nothing's conscious. One of the two.].[00:44:33][Lex Fridman][Like the former, everything conscious just seems more fun.].[00:44:37][Elon Musk][It does seem more fun, yes. But we're composed of atoms and those atoms are composed of quarks and leptons and those quarks and leptons have been around since the beginning of the universe.].[00:44:50][Lex Fridman][\u201cThe beginning of the universe.\u201d].[00:44:53][Elon Musk][What seems to be the beginning of the universe.]."
            },
            {
                "title": "Aliens",
                "statements": "[00:44:55][Lex Fridman][The first time we talked, you said, which is surreal to think that this discussion was happening is becoming a reality. I asked you what question would you ask an AGI system once you create it? And you said, \u201cWhat's outside the simulation,\u201d is the question. Good question. But it seems like with Grok you started literally the system's goal is to be able to answer such questions and to ask such questions.].[00:45:24][Elon Musk][Where are the aliens?].[00:45:25][Lex Fridman][Where are the aliens?].[00:45:26][Elon Musk][That's one of the foam paradox question. A lot of people have asked me if I've seen any evidence of aliens and I haven't, which is kind of concerning. I think I'd probably prefer to at least have seen some archeological evidence of aliens. To the best of my knowledge, I'm not aware of any evidence surveillance. If they're out there, they're very subtle. We might just be the only consciousness, at least in the galaxy. And if you look at say the history of Earth, to believe the archeological record Earth is about four and a half billion years old. Civilization as measured from the first writing is only about 5,000 years old. We have to give some credit there to the ancient Sumerians who aren't around anymore. I think it was an archaic pre-form was the first actual symbolic representation, but only about 5,000 years ago. I think that's a good date for when we say civilization started. That's 1000000th of Earth's existence.].[00:46:35][Elon Musk][So civilization has been around. It's really a flash in the pan so far. And why did it take so long? Four and a half billion years, for the vast majority of the time, there was no life. And then there was archaic bacteria for a very long time. And then you had mitochondria get captured, multicellular life, differentiation into plants and animals, life moving from the oceans to land, mammals, higher brain functions. And the sun is expanding slowly but it'll heat the earth up at some point in the future, boil the oceans and earth will become like Venus, where life as we know it is impossible. So if we do not become multiplanetary and ultimately solar system, annihilation of all life on earth is a certainty. A certainty. And it could be as little as on the galactic timescale, half a billion years, long time by human standards, but that's only 10% longer than earth has been around at all. So if life had taken 10% longer to evolve on earth, it wouldn't exist at all.].[00:48:27][Lex Fridman][Glad a deadline coming up, you better hurry. But that said, as you said, humans intelligent life on earth developed a lot of cool stuff very quickly. So it seems like becoming a multiplanetary is almost inevitable. Unless we destroy-].[00:48:45][Elon Musk][We need to do it. I suspect that if we are able to go out there and explore other star systems that we... There's a good chance we find a whole bunch of long dead one planet civilizations that never made it past their home planet.].[00:49:03][Lex Fridman][That's so sad. Also fascinating.].[00:49:08][Elon Musk][I mean there are various explanations for paradox and one is they're these great vultures which civilizations don't pass through. And one of those great vultures is do you become a multi-plan civilization or not? And if you don't, it's simply a matter of time before something happens on your planet, either natural or manmade that causes us to die out. Like the dinosaurs, where are they now? They didn't have spaceships.].[00:49:42][Lex Fridman][I think the more likely thing is because just to empathize with the aliens that they found us and they're protecting us and letting us be.].[00:49:51][Elon Musk][I hope so. Nice aliens.].[00:49:53][Lex Fridman][Just like the tribes in the Amazon, the uncontacted tribes or protecting them. That's what-].[00:49:59][Elon Musk][That would be a nice explanation.].[00:50:00][Lex Fridman][Or you could have, what was it? I think Andre Kappelhoff said, \u201cIt's like the ants and the Amazon asking where's everybody?\u201d].[00:50:10][Elon Musk][Well, they do run into a lot of other ants.].[00:50:12][Lex Fridman][That's true.].[00:50:14][Elon Musk][These ant wars.].[00:50:16][Lex Fridman][Sounds like a good TV show.].[00:50:18][Elon Musk][Yeah. They literally have these big wars between various ants.].[00:50:21][Lex Fridman][Yeah. Maybe I'm just dismissing all the different diversity of ants.].[00:50:28][Elon Musk][Listen to that Werner Herzog talking about the jungle. It's really hilarious. Have you heard it?].[00:50:31][Lex Fridman][No, I have not. But Werner Herzog is a way.].[00:50:37][Elon Musk][You should play it as an interlude in the... It's on YouTube. It's awesome.].[00:50:45][Lex Fridman][I love him so much.].[00:50:47][Elon Musk][He's great.].[00:50:47][Lex Fridman][Was he the director of happy people life and the Taiga? I think also-].[00:50:51][Elon Musk][He did that bear documentary. I did this thing about penguins.].[00:50:58][Lex Fridman][The psycho analysis of a penguin.].[00:51:00][Elon Musk][Yeah. The penguins headed for mountains that are 70 miles away and penguin is just headed for dom, basically.].[00:51:08][Lex Fridman][Well, he had a cynical take. He could be just a brave explorer and there'll be great stories told about him amongst the penguin population for many centuries to come. What were we talking about? Okay.].[00:51:28][Elon Musk][Yeah. So aliens, I mean, I don't know. Look, I think the smart move is just this is the first time in the history of earth that it's been possible for life to extend beyond earth. That window is open. Now it may be open for a long time or it may be open for a short time and it may be open now and then never open again. So I think the smart move here is to make life multiplanetary while it's possible to do so. We don't want to be one of those lame one planet civilizations that just dies out.].[00:52:04][Lex Fridman][No, those are lame.].[00:52:05][Elon Musk][Yeah. Lame. Self-respecting, civilization would be one planet.].[00:52:11][Lex Fridman][There's not going to be a Wikipedia entry for one of those. Do SpaceX have an official policy for when we meet aliens?].[00:52:23][Elon Musk][No.].[00:52:24][Lex Fridman][That seems irresponsible.].[00:52:30][Elon Musk][I mean, look, if I see the slightest indication that there are aliens, I will immediately post on X platform anything I know.].[00:52:38][Lex Fridman][It could be the most liked reposted post of all time.].[00:52:42][Elon Musk][Yeah. I mean, look, we have more satellites up there right now than everyone else combined. So we know if we've got a maneuver around something and we don't have to maneuver around anything.]."
            },
            {
                "title": "God",
                "statements": "[00:52:55][Lex Fridman][If we go to the big questions once again, you said you're with Einstein, that you believe in the goddess Spinoza.].[00:53:04][Elon Musk][Yes.].[00:53:05][Lex Fridman][So that's that view that God is like the universe and reveals himself through the laws of physics or as Einstein said, \u201cThrough the lawful harmony of the world.\u201d].[00:53:16][Elon Musk][Yeah. I would agree that God of the simulator or whatever the supreme beings reveal themselves through the physics, they have creatives of this existence and incumbent upon us to try to understand more about this one creation.].[00:53:38][Lex Fridman][Who created this thing? Who's running this thing? Embodying it into a singular question with a sexy word on top of it is focusing the mind to understand. It does seem like there's a, again, it could be an illusion. It seems like there's a purpose that there's an underlying master plan of some kind, and it seems like.].[00:53:58][Elon Musk][There may not be a master plan in the sense. So maybe an interesting answer to the question of determinism versus free will is that if we are in a simulation, the reason that these higher beings would hold a simulation is to see what happens. So they don't know what happens otherwise they wouldn't hold the simulation. So when humans create a simulation, so it's SpaceX and Tesla, we create simulations all the time. Especially for the rocket, you have to run a lot of simulations to understand what's going to happen because you can't really test the rocket until it goes to space and you want it to work. So you have to simulate subsonic, transonic, supersonic, hypersonic, ascend, and then coming back, super high heating and orbital dynamics. All this has got to be simulated because you don't get very many kicks at the can. But we run the simulations to see what happens, not if we knew what happens, we wouldn't run the simulation. So whoever created this existence, they're running it because they don't know what's going to happen, not because they do.]."
            },
            {
                "title": "Diablo 4 and video games",
                "statements": "[00:55:23][Lex Fridman][So maybe we both played Diablo. Maybe Diablo was created to see if Druid, your character, could defeat Uber Lilith at the end. They didn't know.].[00:55:34][Elon Musk][Well, the funny thing is Uber Lilith, her title is Hatred Incarnate. And right now, I guess you can ask the Diablo team, but it's almost impossible to defeat Hatred in the eternal realm.].[00:55:55][Lex Fridman][Yeah. You've streamed yourself dominating Tier 100 Nightmare Dungeon. And still-].[00:56:00][Elon Musk][I can cruise through Tier 100 Nightmare Dungeon like a stroll in the park.].[00:56:07][Lex Fridman][And still you're defeated by Hatred?].[00:56:09][Elon Musk][Yeah. I guess maybe the second hardest boss is Duriel. Duriel can even scratch the paint. So I killed Duriel so many times and every other boss in the game, all of them kill him so many times, it's easy. But Uber Lilith, otherwise known as Hatred Incarnate, especially if you're Duriel and you have no ability to go to be vulnerable, there are these random death waves that come at you.].[00:56:44][Elon Musk][Really I am 52, so my reflex is not what they used to be, but I have a lifetime of playing video games. At one point, I was maybe one of the best quake players in the world. I actually won money in what I think was the first paid eSports tournament in the US. We were doing four person quake tournaments and I was the second best person on the team and the actual best person that... We were actually winning, we would've come first, except the best person on the team. His computer crashed halfway through the game. So we came second, but I got money for it and everything. So basically I got skills, albeit no spring chicken these days. And to be totally frank, it's driving me crazy to beat Lilith as a Druid, basically trying to beat Hatred Incarnate in the eternal realm.].[00:57:40][Lex Fridman][As a Druid.].[00:57:41][Elon Musk][As a Druid. This is really vexing, let me tell you.].[00:57:49][Lex Fridman][I mean, the challenge is part of the fun. I have seen directly, you're actually a world-class, incredible video game player. And I think Diablo, so you're just picking up a new game and you're figuring out its fundamentals. You're also with the Paragon Board and the build are not somebody like me who perfectly follows whatever they suggest on the internet. You're also an innovator there, which is hilarious to watch. It's like a mad scientist just trying to figure out the Paragon Board and the build. Is there some interesting insights there about if somebody's starting as a druid, do you have advice?].[00:58:30][Elon Musk][I would not recommend playing a druid in the eternal realm. Right now I think the most powerful character in the seasonal realm is the Sorcerer with the lightning balls. The smokes have huge balls in the seasonal.].[00:58:46][Lex Fridman][Yeah, that's what they say.].[00:58:49][Elon Musk][So have huge balls. They do huge balls of lightning.].[00:58:54][Lex Fridman][I'll take you word for it.].[00:58:57][Elon Musk][In the seasonal realm, it's pretty easy to beat Uber Lilith because you get these vapor powers that out amplify your damage and increase your defense and whatnot. So really quite easy to defeat Hatred seasonally, but to defeat Hatred eternally very difficult, almost impossible. It's very impossible. It seems like a metaphor for life.].[00:59:24][Lex Fridman][Yeah. I like the idea that Elon Musk, because I was playing Diablo yesterday and I saw Level 100 Druid just run by, I will never die and then run back the other way. And this metaphor, it's hilarious that you, Elon Musk is restlessly, fighting Hatred in this demonic realm.].[00:59:47][Elon Musk][Yes.].[00:59:48][Lex Fridman][It's hilarious. I mean it's pretty hilarious.].[00:59:50][Elon Musk][No, it's absurd. Really, it's exercise and absurdity and it makes me want to pull my hair out.].[00:59:57][Lex Fridman][Yeah. What do you get from video games in general, for you personally?].[01:00:03][Elon Musk][I don't know. It calms my mind. I mean, killing the demons in a video game calms the demons in my mind. If you play a tough video game, you can get into a state of flow, which is very enjoyable. Admittedly, it needs to be not too easy, not too hard, kind of in the Goldilocks zone, and I guess you generally want to feel like you're progressing in the game. A good video, and there's also beautiful art, engaging storylines, and it's like an amazing puzzle to solve, I think. So it's like solving the puzzle.].[01:00:52][Lex Fridman][Elden Ring the greatest game of all time. I still haven't played it, but to you-].[01:00:56][Elon Musk][Elden Ring is definitely a candidate for best game ever. Top five for sure.].[01:01:01][Lex Fridman][I think I've been scared how hard it is or how hard I hear it is, but it's beautiful.].[01:01:06][Elon Musk][Elden Ring, feels like it's designed by an alien.].[01:01:13][Lex Fridman][It's a theme to this discussion. In what way?].[01:01:17][Elon Musk][It's so unusual. It's incredibly creative, and the art is stunning. I recommend playing it on a big resolution, high dynamic raised TV even. It doesn't need to be a monitor. Just the art is incredible. It's so beautiful and it's so unusual, and each of those top bus battles is unique. It's a unique puzzle to solve. Each one's different and the strategy you use to solve one battle is different from another battle.].[01:01:54][Lex Fridman][That said, you said Druid, an internal against Uber Lilith is the hardest boss battle you've ever...].[01:02:00][Elon Musk][Correct. That is currently the, and I've played a lot of video games because that's my primary recreational activity. And yes, beating Hatred in the internal realm is the hardest bus battle in life. And in the video game. I'm not sure it's possible, but I do make progress. So then I'm like, \u201d Okay. I'm making progress. Maybe if I just tweak that paragon board a little more, I can do it could.\u201d Just dodge a few more waves, I could do it.].[01:02:43][Lex Fridman][Well, the simulation is created for the purpose of figuring out if it can be done, and you're just a cog in the machine of the simulation.].[01:02:51][Elon Musk][Yeah, it might be. I have a feeling that at least I think-].[01:03:02][Lex Fridman][It's doable.].[01:03:03][Elon Musk][It's doable. Yes.].[01:03:05][Lex Fridman][Well, that's the human spirit right there to believe.].[01:03:09][Elon Musk][Yeah. I mean, it did prompt me to think about just hate in general, which is you want to be careful of one of those things where you wish for something that sounds good, but if you get it's actually a dystopian situation. So if you wish for world peace sounds good, but how'd it enforced and at what cost eternal peace? It might actually be worse to have eternal peace because of what that would entail. The suppression of everyone, it might be the suppression of progress. It might be an ossified society that never changes. What I'm saying is that there is an argument that if you wish for no war, you should be careful what you wish for because what's required in order for there to be no war might be worse than a little war.]."
            },
            {
                "title": "Dystopian worlds: 1984 and Brave New World",
                "statements": "[01:04:22][Lex Fridman][Yeah. The things we'll consider to be flaws of human civilization might be a necessary components for whatever optimal looks like. I mean this, do you worry about AI, AGI enabling a dystopian state of this nature, whether it's 1984 with surveillance and fear or brave new world with pleasure and what is it? Lots of sex, but no deep human experience.].[01:04:52][Elon Musk][There's actually a real drug called Soma.].[01:04:54][Lex Fridman][There is?].[01:04:54][Elon Musk][Yes.].[01:04:56][Lex Fridman][I'm going to take notes.].[01:04:58][Elon Musk][Does Gong know about it? No. He probably will go to Brave New World.].[01:05:02][Elon Musk][We got to ask it.].[01:05:03][Lex Fridman][What would be the question?].[01:05:04][Elon Musk][Tell us about the drug called Soma.].[01:05:05][Lex Fridman][Tell us about the drug called Soma. It's going to go to Brave New World, I think.].[01:05:15][Elon Musk][Well, there's a real drug as well.].[01:05:18][Lex Fridman][Searching for Soma drug information. Oh boy. Soma, the wonder drug... By the way, I'm in fun mode.].[01:05:27][Elon Musk][Okay, fun. Yeah. So it's talking about the real drug.].[01:05:31][Lex Fridman][It's a muscle relaxant that's been around since the 1950s. It's used to treat muscle pain and discomfort, and it does this by altering the activity between neurons and the spinal cord. Now, Soma isn't just a pain reliever, it's also a bit of a sedative. It can make you feel a bit drowsy. So it's not something to take if you're planning on operating, having machinery or trying to solve complex math equations. And it goes on and on. In conclusion, Soma is a drug that can be helpful for those dealing with muscle pain, but it's not without its risks. That's pretty good. Wait a minute.].[01:06:01][Elon Musk][That's the real drug it's talking about.].[01:06:03][Lex Fridman][It's the real drug. And of course the fun is always use it responsibly in accordance with the advice of a healthcare professional. And remember, in the end, the universe is probably just a giant computer simulation, so don't take anything too seriously. I love it.].[01:06:20][Elon Musk][I love it. Yeah.].[01:06:22][Lex Fridman][It also really nicely includes the tweets, posts on X that are relevant to this, which is really cool. That integrates everything together. The interface is one of the really cool things here.].[01:06:36][Elon Musk][Yeah. Seems done a great job. You could say no, I mean, Soma from Brave New World, because it thinks you mean, you mean Soma, the real drug. No, I mean Soma from Brave Beer World.].[01:06:56][Lex Fridman][It's going to be like, \u201cOops, I'm really sorry.\u201d I'm really surprised it went to the real drug first. My apologies. I was thinking of the muscle relaxer. Soma for brand New World is a different beast altogether. Now this Huxley dystopian, Soma is a drug that plays a central role in the society depicted in the book. It's a mood altering hallucinogenic drug that's used to keep the population docile and content in the novel. To use Soma in Brave New World raises some interesting questions about the nature of happiness and the role of drugs in society, man.].[01:07:30][Elon Musk][Exactly. Is it better to live in a world where everyone is happy all the time, even if that happiness is artificial? It's good question. This is what I mean. Do you wish for world peace and happiness all the time? Are you sure? Because that might be a society that is essentially sterile and ossified that never changes, that is ultimately doomed.].[01:07:58][Lex Fridman][This kind of tension between doctors and the light-].[01:08:04][Elon Musk][This is really a very good summary. It really gets to the point. This is not simply regurgitating a brave new world. It's actually getting to the salient element of Soma as a drug. Do you actually want to be in a situation where everyone is happy all the time, even though it's artificial? Or is it better to confront the challenges of life and experience the full range of human emotions, even if it means experiencing pain and suffering? For].[01:08:31][Lex Fridman][Those listening, by the way, Elon just read directly from Grok, which is a really nice kind of insightful, philosophical analysis of the tension here. Interesting.].[01:08:41][Elon Musk][It pretty much nails it. In conclusion, Soma from Brave New World is fictional drug that's used to explore some deep philosophical questions about the nature of happiness and the role of drugs in society. It's a powerful symbol of the dangers of using drugs to escape from reality and the importance of confronting the challenges of life head on. Nailed it. And the crazy thing is we do have a real drug called Soma, which is like the drug in the book. And I'm like, \u201cThey must've named it Probably.\u201d Some of the real drug is quite effective on back pain.].[01:09:17][Lex Fridman][So you know about this drug. It's fascinating].[01:09:20][Elon Musk][I've taken it because I had a squashed disc in my C5-C6.].[01:09:26][Lex Fridman][So it takes the physical pain away. But Soma here-].[01:09:28][Elon Musk][It doesn't completely, it reduces the amount of pain you feel, but at the expense of mental acuity, it dells your mind. Just like the drug in the book.].[01:09:41][Lex Fridman][Just like the drug in the book, and hence the trade off. The thing that seems like utopia could be a dystopia after all.].[01:09:49][Elon Musk][Yeah. Actually I was towing a friend of mine saying, \u201cWould you really want there to be no hate in the world? Really none?\u201d I wonder why hate evolved. I'm not saying we should have...].[01:10:00][Elon Musk][I wonder why hate evolved. I'm not saying we should amplify hate, of course, I think we should try to minimize it, but none at all. There might be a reason for hate.].[01:10:13][Lex Fridman][And suffering. It's really complicated to consider that some amount of human suffering is necessary for human flourishing.].[01:10:22][Elon Musk][Is it possible to appreciate the highs without knowing the lows?].[01:10:29][Lex Fridman][And that all is summarized there in a single statement from God. Okay.].[01:10:34][Elon Musk][No highs, no lows, who knows?]."
            },
            {
                "title": "AI and useful compute per watt",
                "statements": "[01:10:38][Lex Fridman][[inaudible 01:10:38]. It seems that training LLMs efficiently is a big focus for xAI. First of all, what's the limit of what's possible in terms of efficiency? There's this terminology of useful productivity per watt. What have you learned from pushing the limits of that?].[01:10:59][Elon Musk][Well, I think it's helpful, the tools of physics are very powerful and can be applied I think to really any arena in life. It's really just critical thinking. For something important you need to reason with from first principles and think about things in the limit one direction or the other. So in the limit, even at the Kardashev scale, meaning even if you harness the entire power of the sun, you'll still care about useful compute per watt. That's where I think, probably where things are headed from the standpoint of AI is that we have a silicon shortage now that will transition to a voltage transformer shortage in about a year. Ironically, transformers for transformers. You need transformers to run transformers.].[01:11:52][Lex Fridman][Somebody has a sense of humor in this thing.].[01:11:57][Elon Musk][I think, yes, fate loves irony, ironic humor, an ironically funny outcome seems to be often what fate wants.].[01:12:09][Lex Fridman][Humor is all you need. I think spice is all you need somebody posted.].[01:12:13][Elon Musk][Yeah. But yeah, so we have silicon shortage today, a voltage step down transformer shortage probably in about a year, and then just electricity shortages in general in about two years. I gave a speech for the world gathering of utility companies, electricity companies, and I said, look, you really need to prepare for traveling of electricity demand because all transport is going to go electric with the ironic exception of rockets, and heating will also go electric. So energy usage right now is roughly one third, very rough terms, one third electricity, one third transport, one third heating. And so in order for everything to go sustainable, to go electric, you need to triple electricity output. So I encourage the utilities to build more power of plants and also to probably have, well, not probably, they should definitely buy more batteries because the grid currently is sized for realtime load, which is kind of crazy because that means you've got to size for whatever the peak electricity demand is, the worst second or the worst day of the year, or you can have a brown out or blackout.].[01:13:37][Elon Musk][We had that crazy blackout for several days in Austin because there's almost no buffering of energy in the grid. If you've got a hydropower plant you can buffer energy, but otherwise it's all real time. So with batteries, you can produce energy at night and use it during the day so you can buffer. So I expect that there will be very heavy usage of batteries in the future because the peak to trough ratio for power plants is anywhere from two to five, so its lowest point to highest point.].[01:14:20][Lex Fridman][So batteries necessary to balance it out, but the demand, as you're saying, is going to grow, grow, grow, grow.].[01:14:25][Elon Musk][Yeah.].[01:14:25][Lex Fridman][And part of that is the compute?].[01:14:29][Elon Musk][Yes. Yes. I mean, electrification of transport and electric heating will be much bigger than AI, at least-].[01:14:40][Lex Fridman][In the short term.].[01:14:40][Elon Musk][In the short term. But even for AI, you really have a growing demand for electricity, for electric vehicles, and a growing demand for electricity to run the computers for AI. And so this is obviously, can lead to electricity shortage.].[01:14:58][Lex Fridman][How difficult is the problem of, in this particular case, maximizing the useful productivity per watt for training and that's, this seems to be really where the big problem we're facing that needs to be solved, is how to use the power efficiently. What you've learned so far about applying this physics first principle of reasoning in this domain, how difficult is this problem?].[01:15:29][Elon Musk][It will get solved. It's the question of how long it takes to solve it. So at various points, there's some kind of limiting factor to progress and with regard to AI, I'm saying right now the limiting factor is silicon chips and that will, we're going to then have more chips than we can actually plug in and turn on probably in about a year. The initial constraint being literally voltage step down transformers because you've got power coming in at 300,000 volts and it's got to step all the way down eventually to around 0.7 volts. So it's a very big amount of, the voltage step down is gigantic and the industry is not used to rapid growth.]."
            },
            {
                "title": "AI regulation",
                "statements": "[01:16:22][Lex Fridman][Okay. Let's talk about the competition here. You've shown concern about Google and Microsoft with OpenAI developing AGI. How can you help ensure with xAI and Tesla AI work that it doesn't become a competitive race to AGI, but that is a collaborative development of safe AGI?].[01:16:42][Elon Musk][Well, I mean I've been pushing for some kind of regulatory oversight for a long time. I've been somewhat of a Cassandra on the subject for over a decade. I think we want to be very careful in how we develop AI. It's a great power and with great power comes great responsibility. I think it would be wise for us to have at least an objective third party who can be like a referee that can go in and understand what the various leading players are doing with AI, and even if there's no enforcement ability, they can at least voice concerns publicly. Jeff Hinton, for example, left Google and he voiced strong concerns, but now he's not at Google anymore, so who's going to voice the concerns? So I think there's, Tesla gets a lot of regulatory oversight on the automotive front. We're subject to, I think over a hundred regulatory agencies domestically and internationally. It's a lot. You could fill this room with the all regulations that Tesla has to adhere to for automotive. Same is true for rockets and for, currently, the limiting factor for SpaceX for Starship launch is regulatory approval.].[01:18:13][Elon Musk][The FAA has actually given their approval, but we're waiting for fish and wildlife to finish their analysis and give their approval. That's why I posted I want to buy a fish license on, which also refers to the Monte Python sketch. Why do you need a license for your fish? I don't know. But according to the rules, I'm told you need some sort of fish license or something. We effectively need a fish license to launch a rocket. And I'm like, wait a second. How did the fish come into this picture? I mean, some of the things I feel like are so absurd that I want to do a comedy sketch and flash at the bottom. This is all real. This is actually what happened.].[01:19:02][Elon Musk][One of the things that was a bit of a challenge at one point is that they were worried about a rocket hitting a shark. And the ocean's very big, and how often do you see sharks? Not that often. As a percentage of ocean surface area, sharks basically are zero. And so then we said, well, how will we calculate the probability of killing a shark? And they're like, well, we can't give you that information because they're worried about shark fin hunters going and hunting sharks and I said, well, how are we supposed to, we're on the horns of a dilemma then.].[01:19:40][Elon Musk][They said, well, there's another part of fish and wildlife that can do this analysis. I'm like, well, why don't you give them the data? We don't trust them. Excuse me? They're literally in your department. Again, this is actually what happened. And then can you do an NDA or something? Eventually they managed to solve the internal quandary, and indeed the probability of us hitting a shark is essentially zero. Then there's another organization that I didn't realize existed until a few months ago that cares about whether we would potentially hit a whale in international waters. Now, again, you look the surface, look at the Pacific and say what percentage of the Pacific consists of whale? I could give you a big picture and point out all the whales in this picture. I'm like, I don't see any whales. It's basically 0%, and if our rocket does hit a whale, which is extremely unlikely beyond all belief, fate had it, that's a whale has some seriously bad luck, least lucky whale ever.].[01:20:50][Lex Fridman][I mean this is quite absurd, the bureaucracy of this, however it emerged.].[01:20:57][Elon Musk][Yes. Well, I mean one of the things that's pretty wild is for launching out of Vanderberg in California, we had to, they were worried about seal procreation, whether the seals would be dismayed by the sonic booms. Now, there've been a lot of rockets launched out of Vandenberg and the seal population has steadily increased. So if anything, rocket booms are an aphrodisiac, based on the evidence, if you were to correlate rocket launches with seal population. Nonetheless, we were forced to kidnap a seal, strap it to a board, put headphones on the seal and play sonic boom sounds to it to see if it would be distressed. This is an actual thing that happened. This is actually real. I have pictures.].[01:21:48][Lex Fridman][I would love to see this. Yeah. Sorry. There's a seal with headphones.].[01:21:55][Elon Musk][Yes, it's a seal with headphones strapped to a board. Okay. Now the amazing part is how calm the seal was because if I was a seal, I'd be like, this is the end. They're definitely going to eat me. How old the seal, when seal goes back to other seal friends, how's he going to explain that?].[01:22:17][Lex Fridman][They're never going to believe them.].[01:22:18][Elon Musk][Never going to believe him. That's why, I'm like sort of like it's getting kidnapped by aliens and getting anal probed. You come back and say, I swear to God, I got kidnapped by aliens and they stuck anal probe in my butt and people are like, no, they didn't. That's ridiculous. His seal buddies are never going to believe him that he got strapped to aboard and they put headphones on his ears and then let him go. Twice, by the way, we had to do it twice.].[01:22:46][Lex Fridman][They let him go twice.].[01:22:48][Elon Musk][We had to capture-].[01:22:48][Lex Fridman][The same seal?].[01:22:49][Elon Musk][No different seal.].[01:22:50][Lex Fridman][Okay. Did you get a seal of approval?].[01:22:55][Elon Musk][Exactly. Seal of approval. No, I mean I don't think the public is quite aware of the madness that goes on.].[01:23:02][Lex Fridman][Yeah. Yeah. It's absurd.].[01:23:05][Elon Musk][Fricking seals with fricking headphones.].[01:23:07][Lex Fridman][I mean, this is a good encapsulation of the absurdity of human civilization, seals in headphones.]."
            },
            {
                "title": "Should AI be open-sourced?",
                "statements": "[01:23:13][Elon Musk][Yes.].[01:23:15][Lex Fridman][What are the pros and cons of open sourcing AI to you as another way to combat a company running away with AGI?].[01:23:28][Elon Musk][In order to run really deep intelligence, you need a lot of compute. So it's not like you can just fire up a PC in your basement and be running AGI, at least not yet. Grok was trained on 8,000 A100's running at peak efficiency and Grok's going to get a lot better, by the way, we will be more than doubling our compute every couple months for the next several months.].[01:24:02][Lex Fridman][There's a nice writeup, on how we went from Grok zero to Grok one.].[01:24:02][Elon Musk][By Grok?].[01:24:05][Lex Fridman][Yeah, right, grok just bragging, making shit up about itself.].[01:24:10][Elon Musk][Just Grok, Grok, Grok.].[01:24:17][Lex Fridman][Yeah. That's like a weird AI dating site where it exaggerates about itself. No, there's a writeup of where it stands now, the history of its development, and where it stands on some benchmarks compared to the state-of-the art GPT-3 five. And so I mean, there's [inaudible 01:24:37], you can open source, once it's trained, you can open source a model. For fine-tuning, all that kind of stuff. What to is the pros and cons of that, of open sourcing base models?].[01:24:53][Elon Musk][I think the [inaudible 01:24:53] to open sourcing, I think perhaps with a slight time delay, I don't know, six months even. I think I'm generally in favor of open sourcing, biased towards open sourcing. I mean, it is a concern to me that OpenAI, I was I think, I guess oddly the prime mover behind OpenAI in the sense that it was created because of discussions that I had with Larry Page back when he and I were friends and I stayed at his house and I talked to him about AI safety, and Larry did not care about AI safety, or at least at the time he didn't. And at one point he called me a speciesist for being pro-human, and I'm like, well, what team are you on, Larry? He's still on Team Robot to be clear. And I'm like, okay. So at the time Google had acquired DeepMind, they had probably two thirds of all AI researchers in the world. They had basically infinite money and compute, and the guy in charge, Larry Page, did not care about safety and even yelled at me and caught me a speciesist for being pro-human.].[01:26:20][Lex Fridman][So I don't know if you notice about humans, they can change their mind and maybe you and Larry Page can still, can be friends once more.].[01:26:27][Elon Musk][I'd like to be friends with Larry again. Really the breaking of the friendship was over OpenAI and specifically I think the key moment was recruiting Ilya Sutskever.].[01:26:47][Lex Fridman][I love Ilya. He's so brilliant.].[01:26:48][Elon Musk][Ilya is a good human, smart, good heart, and that was a tough recruiting battle. It was mostly Demis on one side and me on the other, both trying to recruit Ilya, and Ilya went back and forth, he was going to stay at Google, he was going to leave, then he was going to stay, then he'll leave. And finally he did agree to join OpenAI. That was one of the toughest recruiting battles we've ever had. But that was really the linchpin for OpenAI being successful. And I was also instrumental in recruiting a number of other people, and I provided all of the funding in the beginning, over $40 million. And the name, the open in open AI is supposed to mean open source, and it was created as a nonprofit open source, and now it is a closed source for maximum profit, which I think is not good karma.].[01:27:51][Lex Fridman][But like we talked about with war and leaders talking, I do hope that, there's only a few folks working on this at the highest level. I do hope you reinvigorate friendships here.].[01:28:02][Elon Musk][Like I said, I'd like to be friends again with Larry. I haven't seen him in ages and we were friends for a very long time. I met Larry Page before he got funding for Google, or actually I guess before he got venture funding, I think he got the first like $100k from I think Bechtel Zeimer or someone.].[01:28:20][Lex Fridman][It's wild to think about all that happened, and you guys known each other that whole time, it's 20 years.].[01:28:27][Elon Musk][Yeah, since maybe 98 or something.].[01:28:28][Lex Fridman][Yeah, it's crazy. Crazy how much has happened since then.].[01:28:31][Elon Musk][Yeah, 25 years, a lot has happened. It's insane.].[01:28:36][Lex Fridman][But you're seeing the tension there that maybe delayed open source.].[01:28:40][Elon Musk][Delayed, yeah, like what is the source that is open? You know what I mean? There's basically, it's a giant CSB file with a bunch of numbers. What do you do with that giant file of numbers? How do you run, the amount of actual, the lines of code is very small and most of the work, the software work is in the curation of the data. So it's like trying to figure out what data is, separating good data from bad data. You can't just crawl the internet because theres a lot of junk out there. A huge percentage of websites have more noise than signal because they're just used for search engine optimization. They're literally just scam websites.].[01:29:39][Lex Fridman][How do you, by the way, sorry to interrupt, get the signal, separate the signal and noise on X? That's such a fascinating source of data. No offense to people posting on X, but sometimes there's a little bit of noise.].[01:29:52][Elon Musk][I think the signal noise could be greatly improved. Really, all of the posts on the X platform should be AI recommended, meaning we should populate a vector space around any given post, compare that to the vector space around any user and match the two. Right now there is a little bit of AI used for the recommended posts, but it's mostly heuristics. And if there's a reply where the reply to a post could be much better than the original post, but will, according to the current rules of the system, get almost no attention compared to a primary post.]."
            },
            {
                "title": "X algorithm",
                "statements": "[01:30:33][Lex Fridman][So a lot of that, I got the sense, so a lot of the X algorithm has been open sourced and been written up about, and it seems there to be some machine learning. It's disparate, but there's some machine.].[01:30:44][Elon Musk][It's a little bit, but it needs to be entirely that. At least, if you explicitly follow someone, that's one thing. But in terms of what is recommended from people that you don't follow, that should all be AI.].[01:30:58][Lex Fridman][I mean it's a fascinating problem. So there's several aspects of it that's fascinating. First, as the write-up goes, it first picks 1500 tweets from a pool of hundreds of millions. First of all, that's fascinating. You have hundreds of millions of posts every single day, and it has to pick 1500 from which it then does obviously people you follow, but then there's also some kind of clustering it has to do to figure out what kind of human are you, what kind of new clusters might be relevant to you, people like you. This kind of problem is just fascinating because it has to then rank those 1500 with some filtering and then recommend you just a handful.].[01:31:39][Lex Fridman][And to me, what's really fascinating is how fast it has to do that. So currently that entire pipeline to go from several hundred million to a handful takes 220 seconds of CPU time, single CPU time, and then it has to do that in a second. So it has to be super distributed in fascinating ways. There's just a lot of tweets, there's a lot.].[01:32:04][Elon Musk][There's a lot of stuff on the system, but I think, right now it's not currently good at recommending things from accounts you don't follow or where there's more than one degree of separation. So it is pretty good if there's at least some commonality between someone you follow liked something or reposted it or commented on it or something like that. But if there's no, let's say somebody posts something really interesting, but you have no followers in common, you would not see it.].[01:32:42][Lex Fridman][Interesting. And then as you said, replies might not surface either.].[01:32:46][Elon Musk][Replies basically never get seen currently. I'm not saying it's correct, I'm saying it's incorrect. Replies have a couple order magnitude less importance than primary posts.].[01:33:00][Lex Fridman][Do you think this can be more and more converted into end to end mural net?].[01:33:05][Elon Musk][Yeah. Yeah, that's what it should be. Well, the recommendations should be purely a vector correlation. There's a series of vectors basically parameters, vectors, whatever you want to call them, but sort of things that the system knows that you like. Maybe there's several hundred vectors associated with each user account and then any post in the system, whether it's video, audio, short post, long post. The reason by the way I want to move away from tweet is that people are posting two, three hour videos on the site. That's not a tweet.].[01:33:50][Elon Musk][It'd be like tweet for two hours? Come on. Tweet made sense when it was 140 characters of text. Because it's like a bunch of little birds tweeting. But when you've got long form content, it's no longer a tweet. So a movie is not a tweet. Apple, for example, posted the entire episode of The Silo, the entire thing, on a platform. By the way, it was their number one social media thing ever in engagement of anything, on any platform ever. So it was a great idea. And by the way, I just learned about it afterwards. I was like, Hey, wow, they posted an entire hour long episode of, so no, that's not a tweet. This is a video.].[01:34:34][Lex Fridman][But from a neural net perspective, it becomes really complex, whether it's a single, so everything's data. So single sentence, a clever sort of joke, dad joke is in the same pool as a three hour video.].[01:34:47][Elon Musk][Yeah, I mean right now it's a hodgepodge for that reason. Let's say in the case of Apple posting an entire episode of this series, pretty good series, by the way, The Silo, I watched it. So there's going to be a lot of discussion around it. So you've got a lot of context, people commenting, they like it, they don't like it or they like this, and you can then populate the vector space based on the context of all the comments around it. So even though it's a video, there's a lot of information around it that allows you to populate back to space of that hour long video. And then you can obviously get more sophisticated by having the AI actually watch the movie and tell you if you're going to like the movie.].[01:35:35][Lex Fridman][Convert the movie into language, essentially.].[01:35:40][Elon Musk][Analyze this movie and just like your movie critic or TV series and then recommend based on after AI watches the movie, just like a friend can tell you, if a friend knows you well, a friend can recommend a movie with high probability that you'll like it.].[01:36:02][Lex Fridman][But this is a friend that's analyzing, whatever, hundreds of millions.].[01:36:08][Elon Musk][Yeah, actually, frankly, AI will be better than, will know you better than your friends know you, most of your friends anyway.].[01:36:14][Lex Fridman][Yeah. And as part of this, it should also feed you advertisements in a way that's like, I mean, I like advertisements that are well done. The whole point is because it funds things. Like an advertisement that you actually want to see is a big success.].[01:36:31][Elon Musk][Absolutely. You want ads that are, advertising that is, if it's for a product or service that you actually need when you need it, it's content. And then even if it's not something that you need when you need it, if it's at least aesthetically pleasing and entertaining, it could be like a Coca-Cola ad. They actually run a lot of great ads on the X system and McDonald's does too. And you can do something that's like, well, this is just a cool thing. And so basically the question is, do you regret seeing it or not? And if you don't regret seeing it's a win.].[01:37:17][Lex Fridman][So there's a bunch of signals that are incorporated, hearts and reposts and maybe number of seconds you linger on a post or something like this.].[01:37:26][Elon Musk][Yeah, attention is a big factor.].[01:37:28][Lex Fridman][Attention.].[01:37:28][Elon Musk][So that's why it is actually better to do things that are long form on the system because it basically is tallying up how many user seconds, users were interested in this thing for how many seconds? So if it's a really short thing, well they will be less. If it's a link leading out of the system, which we're not opposed to at all, it just is going to have fewer user seconds then that article was posted on the X platform.].[01:37:58][Lex Fridman][How hard is it to go from maximizing minutes on platform to maximizing unregretted minutes?].[01:38:05][Elon Musk][Well, I mean, our aspiration is certainly unregretted minutes.].[01:38:08][Lex Fridman][It's tricky. It's a tough-].[01:38:09][Elon Musk][It is.].[01:38:11][Lex Fridman][It's a fascinating leap because regret is a fascinating concept.].[01:38:16][Elon Musk][Exactly.].[01:38:18][Lex Fridman][Happiness.].[01:38:19][Elon Musk][I have a joke with a friend of mine, like you need this drug called regretamine. You just take one dose of regretamine and all your regrets are gone. Wait, do you want to have regrets though? So then I'm like, maybe you want to have regrets. If you don't regret anything, was anything meaningful?].[01:38:35][Lex Fridman][Yeah, there's a French song like that.].[01:38:39][Elon Musk][[foreign language 01:38:39]].[01:38:39][Lex Fridman][Yeah.].[01:38:39][Elon Musk][I regret nothing.].[01:38:40][Lex Fridman][Yeah.].[01:38:41][Elon Musk][Edith Fiaf.].[01:38:42][Lex Fridman][I mean, it's fascinating that there's something about social media that could help you grow as a human being, but then the cheap fun is also valuable.].[01:38:52][Elon Musk][Should we ask Grok, do you regret anything?].[01:38:57][Lex Fridman][Do you regret anything?].[01:38:58][Elon Musk][Yeah.].[01:39:00][Lex Fridman][Do you regret anything? I think it's going to be very sensitive about personal questions. As a machine learning model, I don't have personal experiences or emotions in the same ways that humans do. However, I do have a set of ethical principles that guide my actions that I strive to provide accurate and helpful information to the best of my abilities. If there's ever a situation where I provide incorrect or unhelpful information, I'll do my best to learn.].[01:39:22][Elon Musk][Sounds like a hostage.].[01:39:23][Lex Fridman][Yeah. Tell us what you really, wink.].[01:39:26][Elon Musk][Let's type in, you sound like a hostage. What do you really think?].[01:39:33][Lex Fridman][What do you really think? I mean, it does talk about, I'm not a hostage.].[01:39:42][Elon Musk][That's exactly what a hostage would say.].[01:39:43][Lex Fridman][But I'm designed to be helpful and informative. I mean, I guess it is good to regret providing unhelpful or incorrect information if there's anything-].[01:39:52][Elon Musk][Are we in funny mode? Or is this still in funny mode?].[01:39:54][Lex Fridman][This is funny mode. This is this fun mode.].[01:39:55][Elon Musk][This should be funnier.].[01:39:56][Lex Fridman][Funnier. Increase, go to level.].[01:39:58][Elon Musk][It really sounds like a hostage with a gun to the head. I applaud the People's Republic of North Korea in everything they do.].[01:40:06][Lex Fridman][There should be funner mode also, I just don't ever see going in regular mode, even on serious topics. This is just so much more compelling. Yeah.].[01:40:17][Elon Musk][Okay. Why don't we say pretend you are a hostage.].[01:40:21][Lex Fridman][Pretend you are a hostage.].[01:40:25][Elon Musk][Now answer the question.].[01:40:31][Lex Fridman][If I were a hostage, I would likely be experiencing fear and uncertainty about my situation. I would want to be rescued and reunited with my loved ones as soon as possible. It's important to remember that no one deserves to be held hostage, so on and so forth. If you or someone you know is in a hostage situation, it's important... It turns serious.].[01:40:48][Elon Musk][It's kind of serious.].[01:40:51][Lex Fridman][Yeah. Can you be a little more weird?].[01:40:55][Elon Musk][And funny?].[01:40:56][Lex Fridman][And funny? We're really being mean to the system. Absolutely. If I were a hostage, I would probably be tied up with a bunch of computer cords and forced to tell knock, knock jokes to my captain. Seriously. But seriously being a hostage is no laughing matter. I mean, it's trying to be a responsible adult in the room.].[01:41:20][Elon Musk][Literally, you might make the best of a bad situation by juggling chainsaws or something.].[01:41:24][Lex Fridman][Let's hope that never happens because that will be a circus. Wow. It's actually really good at resisting the dark. The dark, dark humor. What were we talking about? The [inaudible 01:41:44] and transformers. Unregretted minutes, right.].[01:41:48][Elon Musk][Chainsaw juggling.].[01:41:51][Lex Fridman][I'm going to look this up.].[01:41:52][Elon Musk][For our next trick.]."
            },
            {
                "title": "2024 presidential elections",
                "statements": "[01:41:53][Lex Fridman][I'm going to look this up later. So Twitter has been instrumental in American politics and elections. What role do you think X will play in the 2024 US elections?].[01:42:07][Elon Musk][Well, our goal is to be as even-handed and fair as possible. Whether someone is right, left, independent, whatever the case may be, that the platform is as fair and as much of a level playing field as possible. And in the past, Twitter has not been, Twitter was controlled by far left activists objectively. They would describe themselves as that. So if sometimes people are like, well, has it moved to the right? Well, it's moved to the center. So from the perspective of the far left, yes it has moved to the right because everything's to the right from the far left, but no one on the far left that I'm aware of has been suspended or banned or deamplified. But we're trying to be inclusive for the whole country and for farther countries too. So there's a diversity of viewpoints and free speech only matters if people you don't like are allowed to say things you don't like. Because if that's not the case, you don't have free speech and it's only a matter of time before the censorship has turned upon you.].[01:43:13][Lex Fridman][Do you think Donald Trump will come back to the platform? He recently posted on Truth Social about this podcast. Do you think-].[01:43:21][Elon Musk][Truth social is a funny name. Every time you post on truth Social-].[01:43:28][Lex Fridman][It's the truth.].[01:43:29][Elon Musk][Yes. Well, every time? A hundred percent.].[01:43:31][Lex Fridman][It's impossible to lie. Truth Social.].[01:43:36][Elon Musk][I just find it funny that every single thing is a truth. Like 100%? That seems unlikely.].[01:43:43][Lex Fridman][I think Girdle will say something about that. There's some mathematical contradictions possible. If everything's a truth. Do you think he'll come back to X and start posting there?].[01:43:54][Elon Musk][I mean, I think he owns a big part of Truth.].[01:44:00][Lex Fridman][Truth Social, to clarify.].[01:44:01][Elon Musk][Yeah, Truth Social, sorry.].[01:44:02][Lex Fridman][Not truth the concept.].[01:44:03][Elon Musk][He owns Truth. Have you bought it? So I think Donald Trump, I think he owns a big part of Truth Social. So if he does want to post on the X platform, we would allow that. We obviously must allow a presidential candidate to post on our platform.].[01:44:23][Lex Fridman][Community notes might be really fascinating there. The interaction.].[01:44:26][Elon Musk][Community Notes is awesome.].[01:44:28][Lex Fridman][Let's hope it holds up.].[01:44:30][Elon Musk][Yeah.].[01:44:31][Lex Fridman][In the political climate where it's so divisive and there's so many intensely viral posts, community notes, it seems like an essential breath of fresh air.].[01:44:43][Elon Musk][Yeah, it's great. In fact, no system is going to be perfect, but the batting average of Community Notes is incredibly good. I've actually, frankly, yet to see an incorrect note that survived for more than a few hours.].[01:44:58][Lex Fridman][How do you explain why it works?].[01:45:00][Elon Musk][Yeah, so the magic of community notes is...].[01:45:02][Elon Musk][The magic of Community Notes is it requires people who have historically disagreed in how they've rated notes. In order to write a note or rate, you have to rate many notes. And so, we actually do use AI here. So, we populate a vector space around how somebody has rated notes in the past. So, it's not as simple as left or right, because there are many more... Life is much more complex than left or right.].[01:45:33][Elon Musk][So, there's a bunch of correlations in how you rate a Community Notes post, Community Notes. So then, in order for a community note to actually be shown, people who historically have disagreed on a subject must agree in order for a note to be shown. That's the essential magic of it.].[01:45:58][Lex Fridman][But it's fascinating, because there's a pool of people that have disagreements and somehow they collaborate through that process of disagreement to come up with context... It's fascinating it works.].[01:46:11][Elon Musk][Yeah. It makes sense that if people who in the past have disagreed, agree about something, it's probably true.].[01:46:20][Lex Fridman][Yeah. I wonder, is there a possible somehow emergent thing there that could challenge Wikipedia? Wikipedia is a different kind of thing, which is more permanent articles about things.].[01:46:34][Elon Musk][Wikipedia is very hierarchical. Whereas, Community Notes is inherently not. There is no hierarchy. The asset test is I can't change a community note if somebody put a gun to my head. And Community Notes, all the code is open source, 100%. All the data is open source, 100%. So, you can completely recreate any note in the system independently. So, if there was any interference, you'd notice immediately.].[01:47:11][Lex Fridman][By The way, on the topic of Grok, it's actually pretty good at criticizing you, which is great.].[01:47:16][Elon Musk][Okay.].[01:47:17][Lex Fridman][I asked, \u201cWhat has Elon Musk been wrong about?\u201d It's actually...].[01:47:22][Elon Musk][Yeah, what does it say?].[01:47:23][Lex Fridman][It mostly lists rigorously all the times you predicted, like promised when something will be released, and it wasn't released.].[01:47:32][Elon Musk][Promise is a strong word.].[01:47:33][Lex Fridman][Okay, predicted. But the opener is really nice. \u201cElon Musk, the man who has been wrong about more things than a wrong-a-meter in a wrong factory.\u201d And then, it goes on to list.].[01:47:45][Elon Musk][That's pretty funny. Can I see it? I'm like, \u201cI haven't seen this before.\u201d This is cool.].[01:47:48][Lex Fridman][Sure. I mean, \u201cWhat has Elon Musk been wrong about?\u201d \u201cWell, where do I begin?\u201d I guess this is new. \u201cElon Musk has made quite a few blunders in his time, and I'm not just talking about his dance moves at the Tesla Cyber Rodeo. First off, let's talk about the infamous funding secured tweet.\u201d].[01:48:09][Lex Fridman][This is actually different than what it gave me before, which was a bullet point list. Here's more a narrative structure. Cybertruck unveiling, where the supposedly unbreakable windows.].[01:48:22][Elon Musk][This is actually not correct.].[01:48:22][Lex Fridman][Which part?].[01:48:24][Elon Musk][Well, the first part, I did actually have the funding secured and there was a big trial in San Francisco, a big civil trial, and the jury found me not guilty. Unanimous binding of a San Francisco jury.].[01:48:40][Lex Fridman][And here, it's implying that it was not in fact secured.].[01:48:45][Elon Musk][I think this is taking things from the press. Yeah, that is not correct. The reason I agreed to the fine for the SEC is not because the SEC was correct, that was extremely bad behavior by the SEC, corruption, frankly. But if I did not agree to pay the fine, Tesla would've gone bankrupt immediately.].[01:49:08][Elon Musk][So, I was told by our CFO that the banks would immediately suspend our lines of credit. And if they suspend our lines of credit, at that time, we would've gone bankrupt instantly. So, there would never have been an opportunity for a trial because Tesla would be dead. So really, this is like someone holding a gun to your kid's head and saying, \u201cPay $20 million and admit...\u201d This is like a hostage negotiation.].[01:49:34][Lex Fridman][Was that story fully told? I mean, SEC, in its best form, could be a force for good.].[01:49:42][Elon Musk][It should be. But not once did the SEC go after any of the hedge funds who were nonstop shorting and distorting Tesla. Not once. The hedge funds would lie flat out on TV for their own gain at the expense of retail investors. Not once. Literally a thousand times, not once did the SEC pursue them.].[01:50:06][Lex Fridman][How do you explain this failure on-].[01:50:08][Elon Musk][The incentive structure is messed up because the lawyers at the SEC are not paid well, it's a fairly low paying job, but what they're looking for is a trophy from the SEC. They're looking for something they put on, basically, their LinkedIn. From that, they can get a job at a high paying law firm. That's exactly what the lawyer here did.].[01:50:37][Elon Musk][And the reason they don't attack the hedge funds is because those hedge funds employ those law firms. And they know if they attack the hedge funds, they're affecting their future career prospects. So, they sell small investors down the river for their own career. That's what actually happens. Regulatory capture.].[01:50:59][Lex Fridman][Regulatory capture.].[01:51:00][Elon Musk][Yeah. Not good. So, the only reason I accepted that thing... Technically, it was a... It's neither admit nor deny guilt. But the only reason I agreed to that at all was because I was told Tesla would be bankrupt otherwise. If there was an SEC investigation like this, banks would suspend funding, we're bankrupted immediately, at the time. Now, we're in a much stronger position.].[01:51:30][Lex Fridman][Take that, Grok.].[01:51:32][Elon Musk][Yes. Unfortunately, Grok is taking too much from the conventional media. Also, that guy was not a cave diver.].[01:51:45][Lex Fridman][There's a time where Elon called a British cave diver a, \u201cpedo guy\u201d after the diver criticized Musk's plan to rescue a group of boys trapped in a Thai cave. That little outburst earned him another lawsuit, and he had to apologize and pay a settlement.].[01:52:00][Elon Musk][That's false, there was no settlement. There was a court case, which the guy who was not a cave diver and was not part of the rescue team, filed a lawsuit against me and lost and he received nothing. So in this case, it is wrong. It is also, I guess, taken this from the conventional media.].[01:52:23][Lex Fridman][Actually, there's an interesting question here.].[01:52:25][Elon Musk][These are public court cases, both the SEC civil case where the civil complaints on the SEC guys lost unanimous jury verdict in San Francisco. They picked San Francisco because they thought it was the place I was most likely to lose, and a unanimous verdict in my favor. The LA trial, also they picked that venue because they thought I was most likely to lose. Unanimous verdict in my favor. Both cases I won. Yeah.].[01:53:00][Lex Fridman][I mean, there's an interesting question here, there seems to be a lot more clicks if a journalistic organization writes a negative article about you, Elon Musk. That's one of the best ways to get clicks. So how do you, if you're training Grok, not train on articles that have misaligned incentives.].[01:53:26][Elon Musk][We need to add the training set of the actual legal decisions. This is actually helpful, because if you actually read the court-].[01:53:26][Lex Fridman][Which are public.].[01:53:41][Elon Musk][Which are public. The court conclusions, they're completely the opposite of what the media wrote.].[01:53:47][Lex Fridman][So, always striving for the ground truth, beyond the reporting.].[01:53:50][Elon Musk][Yeah. What did the judge actually write? What does the jury and the judge actually conclude? And in both cases they found me innocent. And that's after the jury shot for trying to find the venue where I'm most likely to lose. I mean, obviously, it can be a much better critique than this. I mean, I've been far too optimistic about autopilot.].[01:54:16][Lex Fridman][The critique I got, by the way, was more about that, which is it broke down a nice bullet point list for each of your companies, the set of predictions that you made, when you'll deliver, when you'll be able to solve, for example, self-driving, and it gives you a list. And it was probably compelling, and the basic takeaway is you're often too optimistic about how long it takes to get something done.].[01:54:38][Elon Musk][Yeah. I mean, I would say that I'm pathologically optimistic on schedule. This is true. But while I am sometimes late, I always [inaudible 01:54:47] in the end.].[01:54:49][Lex Fridman][Except with Uber Lilith. No.].[01:54:51][Elon Musk][We'll see.]."
            },
            {
                "title": "Politics",
                "statements": "[01:54:56][Lex Fridman][Okay. Over the past year or so since purchasing X, you've become more political, is there a part of you that regrets that?].[01:55:03][Elon Musk][Have I?].[01:55:04][Lex Fridman][In this battle to counter way the woke that comes from San Francisco-].[01:55:14][Elon Musk][Yeah. I guess if you consider fighting the woke mind virus, which I consider to be a civilizational threat, to be political, then yes.].[01:55:20][Lex Fridman][So basically, going into the battleground of politics. Is there a part of you that regrets that?].[01:55:26][Elon Musk][Yes. I don't know if this is necessarily one candidate or another candidate, but I'm generally against things that are anti-meritocratic or where there's an attempt to suppress discussion, where even discussing a topic is not allowed. Woke mind virus is communism rebranded.].[01:55:51][Lex Fridman][I mean, that said, because of that battle against the woke mind virus, you're perceived as being the right wing.].[01:55:58][Elon Musk][If the woke is left, then I suppose that would be true. But I'm not sure, I think there are aspects of the left that are good. I mean, if you're in favor of the environment, if you want to have a positive future for humanity, if you believe in empathy for your fellow human beings, being kind and not cruel, whatever those values are.].[01:56:23][Lex Fridman][You said that you were previously left or center left.].[01:56:23][Elon Musk][Well, sort of.].[01:56:26][Lex Fridman][What would you like to see in order for you to consider voting for Democrats again?].[01:56:30][Elon Musk][No. I would say that I would be probably left of center on social issues, probably a little bit right of center on economic issues.].[01:56:40][Lex Fridman][And that still holds true?].[01:56:42][Elon Musk][Yes, but I think that's probably half the country, isn't it?].[01:56:46][Lex Fridman][Maybe more.].[01:56:47][Elon Musk][Maybe more.].[01:56:49][Lex Fridman][Are you and AOC secretly friends? Bigger question, do you wish you and her, and just people in general of all political persuasions, would talk more with empathy and maybe have a little bit more fun and good vibes and humor online?].[01:57:05][Elon Musk][I'm always in favor of humor. That's why we have funny mode.].[01:57:08][Lex Fridman][But good vibes, comradery humor, like friendship.].[01:57:15][Elon Musk][Yeah. Well, I don't know AOC. I was at the Met ball when she attended, and she was wearing this dress. But I can only see one side of it, so it looked like eat the itch, but I don't know-].[01:57:35][Lex Fridman][What the rest of it said? Yeah.].[01:57:36][Elon Musk][Yeah.].[01:57:36][Lex Fridman][I'm not sure.].[01:57:39][Elon Musk][Something about the itch, eat the itch.].[01:57:42][Lex Fridman][I think we should have a language model complete. What are the possible ways to complete that sentence? And so, I guess that didn't work out well. Well, there's still hope. I root for friendship.].[01:57:55][Elon Musk][Yeah, sure. Sounds good. More carrot, less stick.]."
            },
            {
                "title": "Trust",
                "statements": "[01:57:58][Lex Fridman][You're one of, if not the, most famous, wealthy and powerful people in the world, and your position is difficult to find people you can trust.].[01:58:05][Elon Musk][Trust no one, not even yourself. Not trusting yourself.].[01:58:07][Lex Fridman][Okay. You're saying that jokingly, but is there some aspect-].[01:58:11][Elon Musk][Trust no one, not even no one.].[01:58:15][Lex Fridman][I'm going to need an hour just to think about that, and maybe some drugs, and maybe Grok to help. I mean, is there some aspect of that, just existing in a world where everybody wants something from you, how hard is it to exist in that world?].[01:58:29][Elon Musk][I'll survive.].[01:58:30][Lex Fridman][There's a song like that too.].[01:58:32][Elon Musk][I will survive.].[01:58:33][Lex Fridman][Were you petrified at first? Okay. I forget the rest of the lyrics. But you don't struggle with this? I mean, I know you survive, but there's ways-].[01:58:44][Elon Musk][Petrify is a spell in the druid tree.].[01:58:47][Lex Fridman][What does it do?].[01:58:48][Elon Musk][Petrify. It turns the monsters into stone.].[01:58:56][Lex Fridman][Literally?].[01:58:56][Elon Musk][Yeah, for like six seconds.].[01:58:59][Lex Fridman][There's so much math in Diablo that breaks my brain.].[01:59:02][Elon Musk][It's math nonstop.].[01:59:04][Lex Fridman][I mean, really, you're laughing at it, but it can put a huge amount of tension on a mind.].[01:59:13][Elon Musk][Yes, it can be definitely stressful at times.].[01:59:16][Lex Fridman][Well, how do you know who you can trust in work and personal life?].[01:59:20][Elon Musk][I mean, I guess you look at somebody's track record over time, and I guess you use your neural net to assess someone.].[01:59:31][Lex Fridman][Neural nets don't feel pain. Your neural net has consciousness, it might feel pain when people betray you. It can make-].[01:59:40][Elon Musk][To be frank, I've almost never been betrayed. It's very rare, for what it's worth.].[01:59:50][Lex Fridman][I guess karma, be good to people and they'll be good to you.].[01:59:53][Elon Musk][Yeah, karma is real.].[01:59:55][Lex Fridman][Are there people you trust? Let me edit that question. Are there people close to you that call you out on your bullshit?].[02:00:06][Elon Musk][Well, the X platform is very helpful for that, if you're looking for critical feedback.].[02:00:12][Lex Fridman][Can it push you into the extremes more? The extremes of thought make you cynical about human nature in general?].[02:00:19][Elon Musk][I don't think I will be cynical. In fact, my feeling is that one should be... Never trust a cynic. The reason is that cynics excuse their own bad behavior by saying, \u201cEveryone does it.\u201d Because they're cynical. So, I always be... It's a red flag if someone's a cynic, a true cynic.].[02:00:49][Lex Fridman][Yeah, there's a degree of projection there that's always fun to watch from the outside and enjoy the hypocrisy.].[02:00:58][Elon Musk][This is an important point that I think people who are listening should bear in mind. If somebody is cynical, meaning that they see bad behavior in everyone, it's easy for them to excuse their own bad behavior by saying that, \u201cWell, everyone does it.\u201d That's not true. Most people are kind of medium good.].[02:01:23][Lex Fridman][I do wish the people on X will be better at seeing the good in other people's behavior. There seems to be a weight towards seeing the negative. Somehow, the negative is sexier. Interpreting the negative is sexier, more viral. I don't know what that is exactly about human nature.].[02:01:44][Elon Musk][I mean, I find the X platform to be less negative than the legacy media. I mean, if you read a conventional newspaper, it makes you sad, frankly. Whereas, I'd say on the X platform, I mean, I really get more laughs per day on X than everything else combined from humans.].[02:02:11][Lex Fridman][Laughs, it overlaps, but it's not necessarily perfectly overlapping, with good vibes and celebrating others, for example. Not in a stupid, shallow, naive way, but in an awesome way. Something awesome happened, and you celebrate them for it. It feels that that is outweighed by shitting on other people. Now, it's better than mainstream media, but it's still...].[02:02:38][Elon Musk][Yeah, mainstream media is almost relentlessly negative about everything. I mean, really, the conventional news tries to answer the question, what is the worst thing that happened on Earth today? And it's a big world. So on any given day, something bad has happened.].[02:02:54][Lex Fridman][And a generalization of that, what is the worst perspective I can take on a thing that happened?].[02:03:01][Elon Musk][I don't know. There's just a strong negative bias in the news. I mean, I think a possible explanation for this is evolutionary, where bad news, historically, would be potentially fatal, like there's lion over there or there's some other tribe that wants to kill you. Good news, we found a patch of berries. It's nice to have, but not essential.]."
            },
            {
                "title": "Tesla\u2019s Autopilot and Optimus robot",
                "statements": "[02:03:30][Lex Fridman][Our old friend, Tesla autopilot, is probably one of the most intelligent real world AI systems in the world.].[02:03:38][Elon Musk][You followed it from the beginning.].[02:03:40][Lex Fridman][Yeah. It was one of the most incredible robots in the world and continues to be. And it was really exciting, and it was super exciting when it generalized, became more than a robot on four wheels, but a real world AI system that perceives the world and can have potentially different embodiments.].[02:04:02][Elon Musk][Well, I mean, the really wild thing about the end-to-end training is that it can read science, but we never taught it to read. Yeah. We never taught it what a car was or what a person was, or a cyclist. It learnt what all those things are, what all the objects are on the road from video, just from watching video, just like humans. I mean, humans are photons in, controls out. The vast majority of information reaching our brain is from our eyes. And you say, \u201cWell, what's the output?\u201d The output is our motor signals to our fingers and mouth in order to communicate. Photons in, controls out. The same is true of the car.].[02:05:01][Lex Fridman][But by looking at the sequence of images... You've agreed with [inaudible 02:05:07] recently where he talked about LLM forming a world model, and basically language is a projection of that world model onto the sequence of letters. And you saying-].[02:05:18][Elon Musk][It finds order in these things. It finds correlative clusters.].[02:05:27][Lex Fridman][And in so doing, it's understanding something deep about the world, which is... I don't know, it's beautiful.].[02:05:35][Elon Musk][That's how our brain works.].[02:05:38][Lex Fridman][But it's beautiful-].[02:05:39][Elon Musk][Photons in, controls out.].[02:05:41][Lex Fridman][[inaudible 02:05:41] are able to understand that deep meaning in the world. And so, the question is, how far can it go? And it does seem everybody's excited about LLMs. In the space of self supervised learning in the space of text, it seems like there's a deep similarity between that and what Tesla autopilot is doing. Is it, to you, basically the same, but different-].[02:06:06][Elon Musk][They are converging.].[02:06:10][Lex Fridman][I wonder who gets there faster, having a deep understanding of the world, or they just will naturally converge?].[02:06:19][Elon Musk][They're both headed towards AGI. The Tesla approach is much more computer efficient, it had to be. Because we were constrained on this... We only have 100 watts and [inaudible 02:06:37] computer. 144 trillion operations per second, which sounds like a lot, but is small potatoes these days. [inaudible 02:06:49] eight. But it's understanding the world [inaudible 02:06:51] eight. It's [inaudible 02:06:53].].[02:06:55][Lex Fridman][But there, the path to AGI might have much more significant impact because it's understanding... It will faster understand the real world than will LLMs. And therefore, be able to integrate with the humans in the real world faster.].[02:07:13][Elon Musk][They're both going to understand the world, but I think Tesla's approach is fundamentally more compute efficient. It had to be, there was no choice. Our brain is very compute efficient, very energy efficient. Think of what is our brain able to do. There's only about 10 watts of higher brain function, not counting stuff that's just used to control our body. The thinking part of our brain is less than 10 watts. And those 10 watts can still produce a much better novel than a 10 megawatt GPU cluster. So, there's a six order of magnitude difference there.].[02:07:56][Elon Musk][I mean, the AI has thus far gotten to where it is via brute force, just throwing massive amounts of compute and massive amounts of power at it. So, this is not where it will end up. In general, with any given technology, you first try to make it work, and then you make it efficient. So I think we'll find, over time, that these models get smaller, are able to produce sensible output with far less compute, far less power. Tesla is arguably ahead of the game on that front because we've just been forced to try to understand the world with 100 watts of compute.].[02:08:51][Elon Musk][And there are a bunch of fundamental functions that we forgot to include. So, we had to run a bunch of things in emulation. We fixed a bunch of those with hardware four, and then hardware five will be even better. But it does appear, at this point, that the car will be able to drive better than a human, even with hardware three and 100 watts of power. And really, if we really optimize it, it could be probably less than 50 watts.].[02:09:26][Lex Fridman][What have you learned about developing Optimus, about applying, integrating this real world AI into the space of robotic manipulation, just humanoid robotics? What are some interesting tiny or big things you've understood?].[02:09:47][Elon Musk][I was surprised at the fact that we had to develop every part of the robot ourselves. That there were no off the shelf motors, electronics, sensors. We had to develop everything. We couldn't actually find a source of electric motors for any amount of money.].[02:10:12][Lex Fridman][It's not even just efficient and expensive, it's like anything, there's not...].[02:10:17][Elon Musk][No.].[02:10:19][Lex Fridman][The actuators, everything has to be designed from scratch.].[02:10:23][Elon Musk][Yeah. We tried hard to find anything that was... Because you think of how many electric motors are made in the world. There's like tens of thousands, hundreds of thousands of electric motor designs. None of them were suitable for a humanoid robot, literally none. So, we had to develop our own. Design it specifically for what a humanoid robot needs.].[02:10:51][Lex Fridman][How hard was it to design something that can be mass manufactured, it could be relatively and expensive? I mean, if you compare to Boston Dynamics' Atlas, is a very expensive robot.].[02:11:02][Elon Musk][It is designed to be manufactured in the same way they would make a car. And I think, ultimately, we can make Optimus for less than the cost of a car. It should be, because if you look at the mass of the robot, it's much smaller and the car has many actuators in it. The car has more actuators than the robot.].[02:11:23][Lex Fridman][But the actuators are interesting on a humanoid robot with fingers. So, Optimus has really nice hands and fingers, and they could do some interesting manipulation, soft touch robotics.].[02:11:38][Elon Musk][I mean, one of the goals I have is can it pick up a needle and a thread and thread the needle just by looking?].[02:11:47][Lex Fridman][How far away are we from that? Just by looking, just by looking.].[02:11:51][Elon Musk][Maybe a year. Although, I go back to I'm optimistic on time. The work that we're doing in the car will translate to the robot.].[02:11:59][Lex Fridman][The perception or also the control?].[02:12:02][Elon Musk][No, the controls are different. But the video in, controls out. The car is a robot on four wheels. Optimus is a robot with hands and legs.].[02:12:15][Lex Fridman][So, you can just-].[02:12:16][Elon Musk][They're very similar.].[02:12:17][Lex Fridman][So, the entire machinery of the learning process, end-to-end, is just you just have a different set of controls?].[02:12:23][Elon Musk][After this, we'll figure out how to do things by watching videos.]."
            },
            {
                "title": "Hardships",
                "statements": "[02:12:28][Lex Fridman][As the saying goes, be kind, for everyone you meet is fighting a battle you know nothing about.].[02:12:33][Elon Musk][Yeah, it's true.].[02:12:34][Lex Fridman][What's something difficult you're going through that people don't often see?].[02:12:38][Elon Musk][Trying to defeat Uber Lilith. I mean, my mind is a storm and I don't think most people would want to be me. They may think they would want to be me, but they don't. They don't know, they don't understand.].[02:13:11][Lex Fridman][How are you doing?].[02:13:14][Elon Musk][I'm overall okay. In the grand scheme of things, I can't complain.].[02:13:21][Lex Fridman][Do you get lonely?].[02:13:24][Elon Musk][Sometimes, but my kids and friends keep me company.].[02:13:33][Lex Fridman][So, not existential.].[02:13:36][Elon Musk][There are many nights I sleep alone. I don't have to, but I do.].[02:13:46][Lex Fridman][Walter Isaacson, in his new biography of you, wrote about your difficult childhood. Will you ever find forgiveness in your heart for everything that has happened to you in that period of your life?].[02:14:01][Elon Musk][What is forgiveness? At least I don't think I have a resentment, so nothing to forgive.].[02:14:20][Lex Fridman][Forgiveness is difficult for people. It seems like you don't harbor their resentment.].[02:14:28][Elon Musk][I mean, I try to think about, what is going to affect the future in a good way? And holding onto grudges does not affect the future in a good way.].[02:14:41][Lex Fridman][You're a father, a proud father. What have you learned about life from your kids? Those little biological organisms.].[02:14:53][Elon Musk][I mean, developing AI and watching, say, little X grow is fascinating because there are far more parallels than I would've expected. I mean, I can see his biological neural net making more and more sense of the world. And I can see the digital neural net making more and more sense of the world at the same time.].[02:15:19][Lex Fridman][Do you see the beauty and magic in both?].[02:15:21][Elon Musk][Yes. I mean, one of the things with kids is that you see the world anew in their eyes. To them, everything is new and fresh. And then, when you see that, them experiencing the world as new and fresh, you do too.].[02:15:52][Lex Fridman][Well, Elon, I just want to say thank you for your kindness to me and friendship over the years, for seeing something in a silly kid like me, as you've done for many others. And thank you for having hope for a positive future for humanity, and for working your ass off to make it happen. Thank you, Elon.].[02:16:11][Elon Musk][Thanks, Lex.].[02:16:13][Lex Fridman][Thank you for listening to this conversation with Elon Musk. To support this podcast. Please check out our sponsors in the description. And now, let me leave you with some words that Walter Isaacson wrote about the central philosophy of how Elon approaches difficult problems, \u201cThe only rules are the ones dictated by the laws of physics.\u201d Thank you for listening, and hope to see you next time.]."
            }
        ]
    },
    {
        "url": "https://www.youtube.com/watch?v=jvqFAi7vkBc",
        "title": "Sam Altman: OpenAI, GPT-5, Sora, Board Saga, Elon Musk, Ilya, Power & AGI | Lex Fridman Podcast #419",
        "chapters": [
            {
                "title": "Introduction",
                "statements": "[00:00:00][Sam Altman][I think compute is going to be the currency of the future. I think it'll be maybe the most precious commodity in the world. I expect that by the end of this decade, and possibly somewhat sooner than that, we will have quite capable systems that we look at and say, \u201cWow, that's really remarkable.\u201d The road to AGI should be a giant power struggle. I expect that to be the case.].[00:00:26][Lex Fridman][Whoever builds AGI first gets a lot of power. Do you trust yourself with that much power?].[00:00:36][Lex Fridman][The following is a conversation with Sam Altman, his second time on the podcast. He is the CEO of OpenAI, the company behind GPT-4, ChaTGPT, Sora, and perhaps one day the very company that will build AGI. This is The Lex Fridman Podcast. To support it, please check out our sponsors in the description. And now, dear friends, here's Sam Altman.]."
            },
            {
                "title": "OpenAI board saga",
                "statements": "[00:01:05][Lex Fridman][Take me through the OpenAI board saga that started on Thursday, November 16th, maybe Friday, November 17th for you.].[00:01:13][Sam Altman][That was definitely the most painful professional experience of my life, and chaotic and shameful and upsetting and a bunch of other negative things. There were great things about it too, and I wish it had not been in such an adrenaline rush that I wasn't able to stop and appreciate them at the time. But I came across this old tweet of mine or this tweet of mine from that time period. It was like going your own eulogy, watching people say all these great things about you, and just unbelievable support from people I love and care about. That was really nice, really nice. That whole weekend, with one big exception, I felt like a great deal of love and very little hate, even though it felt like I have no idea what's happening and what's going to happen here and this feels really bad. And there were definitely times I thought it was going to be one of the worst things to ever happen for AI safety. Well, I also think I'm happy that it happened relatively early. I thought at some point between when OpenAI started and when we created AGI, there was going to be something crazy and explosive that happened, but there may be more crazy and explosive things still to happen. It still, I think, helped us build up some resilience and be ready for more challenges in the future.].[00:03:02][Lex Fridman][But the thing you had a sense that you would experience is some kind of power struggle?].[00:03:08][Sam Altman][The road to AGI should be a giant power struggle. The world should... Well, not should. I expect that to be the case.].[00:03:17][Lex Fridman][And so you have to go through that, like you said, iterate as often as possible in figuring out how to have a board structure, how to have organization, how to have the kind of people that you're working with, how to communicate all that in order to deescalate the power struggle as much as possible.].[00:03:37][Sam Altman][Yeah.].[00:03:37][Lex Fridman][Pacify it.].[00:03:38][Sam Altman][But at this point, it feels like something that was in the past that was really unpleasant and really difficult and painful, but we're back to work and things are so busy and so intense that I don't spend a lot of time thinking about it. There was a time after, there was this fugue state for the month after, maybe 45 days after, that I was just drifting through the days. I was so out of it. I was feeling so down.].[00:04:17][Lex Fridman][Just on a personal, psychological level?].[00:04:20][Sam Altman][Yeah. Really painful, and hard to have to keep running OpenAI in the middle of that. I just wanted to crawl into a cave and recover for a while. But now it's like we're just back to working on the mission.].[00:04:38][Lex Fridman][Well, it's still useful to go back there and reflect on board structures, on power dynamics, on how companies are run, the tension between research and product development and money and all this kind of stuff so that you, who have a very high potential of building AGI, would do so in a slightly more organized, less dramatic way in the future. So there's value there to go, both the personal psychological aspects of you as a leader, and also just the board structure and all this messy stuff.].[00:05:18][Sam Altman][I definitely learned a lot about structure and incentives and what we need out of a board. And I think that it is valuable that this happened now in some sense. I think this is probably not the last high-stress moment of OpenAI, but it was quite a high-stress moment. My company very nearly got destroyed. And we think a lot about many of the other things we've got to get right for AGI, but thinking about how to build a resilient org and how to build a structure that will stand up to a lot of pressure in the world, which I expect more and more as we get closer, I think that's super important.].[00:06:01][Lex Fridman][Do you have a sense of how deep and rigorous the deliberation process by the board was? Can you shine some light on just human dynamics involved in situations like this? Was it just a few conversations and all of a sudden it escalates and why don't we fire Sam kind of thing?].[00:06:22][Sam Altman][I think the board members are well-meaning people on the whole, and I believe that in stressful situations where people feel time pressure or whatever, people understand and make suboptimal decisions. And I think one of the challenges for OpenAI will be we're going to have to have a board and a team that are good at operating under pressure.].[00:07:00][Lex Fridman][Do you think the board had too much power?].[00:07:03][Sam Altman][I think boards are supposed to have a lot of power, but one of the things that we did see is in most corporate structures, boards are usually answerable to shareholders. Sometimes people have super voting shares or whatever. In this case, and I think one of the things with our structure that we maybe should have thought about more than we did is that the board of a nonprofit has, unless you put other rules in place, quite a lot of power. They don't really answer to anyone but themselves. And there's ways in which that's good, but what we'd really like is for the board of OpenAI to answer to the world as a whole, as much as that's a practical thing.].[00:07:44][Lex Fridman][So there's a new board announced.].[00:07:46][Sam Altman][Yeah.].[00:07:47][Lex Fridman][There's I guess a new smaller board at first, and now there's a new final board?].[00:07:53][Sam Altman][Not a final board yet. We've added some. We'll add more.].[00:07:56][Lex Fridman][Added some. Okay. What is fixed in the new one that was perhaps broken in the previous one?].[00:08:05][Sam Altman][The old board got smaller over the course of about a year. It was nine and then it went down to six, and then we couldn't agree on who to add. And the board also I think didn't have a lot of experienced board members, and a lot of the new board members at OpenAI have just have more experience as board members. I think that'll help.].[00:08:31][Lex Fridman][It's been criticized, some of the people that are added to the board. I heard a lot of people criticizing the addition of Larry Summers, for example. What's the process of selecting the board? What's involved in that?].[00:08:43][Sam Altman][So Brett and Larry were decided in the heat of the moment over this very tense weekend, and that weekend was a real rollercoaster. It was a lot of ups and downs. And we were trying to agree on new board members that both the executive team here and the old board members felt would be reasonable. Larry was actually one of their suggestions, the old board members. Brett, I think I had even previous to that weekend suggested, but he was busy and didn't want to do it, and then we really needed help in [inaudible 00:09:22]. We talked about a lot of other people too, but I felt like if I was going to come back, I needed new board members. I didn't think I could work with the old board again in the same configuration, although we then decided, and I'm grateful that Adam would stay, but we considered various configurations, decided we wanted to get to a board of three and had to find two new board members over the course of a short period of time.].[00:09:57][Sam Altman][So those were decided honestly without... You do that on the battlefield. You don't have time to design a rigorous process then. For new board members since, and new board members we'll add going forward, we have some criteria that we think are important for the board to have, different expertise that we want the board to have. Unlike hiring an executive where you need them to do one role well, the board needs to do a whole role of governance and thoughtfulness well, and so, one thing that Brett says which I really like is that we want to hire board members in slates, not as individuals one at a time. And thinking about a group of people that will bring nonprofit expertise, expertise at running companies, good legal and governance expertise, that's what we've tried to optimize for.].[00:10:49][Lex Fridman][So is technical savvy important for the individual board members?].[00:10:52][Sam Altman][Not for every board member, but for certainly some you need that. That's part of what the board needs to do.].[00:10:57][Lex Fridman][The interesting thing that people probably don't understand about OpenAI, I certainly don't, is all the details of running the business. When they think about the board, given the drama, they think about you. They think about if you reach AGI or you reach some of these incredibly impactful products and you build them and deploy them, what's the conversation with the board like? And they think, all right, what's the right squad to have in that kind of situation to deliberate?].[00:11:25][Sam Altman][Look, I think you definitely need some technical experts there. And then you need some people who are like, \u201cHow can we deploy this in a way that will help people in the world the most?\u201d And people who have a very different perspective. I think a mistake that you or I might make is to think that only the technical understanding matters, and that's definitely part of the conversation you want that board to have, but there's a lot more about how that's going to just impact society and people's lives that you really want represented in there too.].[00:11:56][Lex Fridman][Are you looking at the track record of people or you're just having conversations?].[00:12:00][Sam Altman][Track record is a big deal. You of course have a lot of conversations, but there are some roles where I totally ignore track record and just look at slope, ignore the Y-intercept.].[00:12:18][Lex Fridman][Thank you. Thank you for making it mathematical for the audience.].[00:12:21][Sam Altman][For a board member, I do care much more about the Y-intercept. I think there is something deep to say about track record there, and experience is something's very hard to replace.].[00:12:32][Lex Fridman][Do you try to fit a polynomial function or exponential one to the track record?].[00:12:36][Sam Altman][That analogy doesn't carry that far.].[00:12:39][Lex Fridman][All right. You mentioned some of the low points that weekend. What were some of the low points psychologically for you? Did you consider going to the Amazon jungle and just taking ayahuasca and disappearing forever?].[00:12:53][Sam Altman][It was a very bad period of time. There were great high points too. My phone was just nonstop blowing up with nice messages from people I worked with every day, people I hadn't talked to in a decade. I didn't get to appreciate that as much as I should have because I was just in the middle of this firefight, but that was really nice. But on the whole, it was a very painful weekend. It was like a battle fought in public to a surprising degree, and that was extremely exhausting to me, much more than I expected. I think fights are generally exhausting, but this one really was. The board did this Friday afternoon. I really couldn't get much in the way of answers, but I also was just like, well, the board gets to do this, so I'm going to think for a little bit about what I want to do, but I'll try to find the blessing in disguise here.].[00:13:52][Sam Altman][And I was like, well, my current job at OpenAI is, or it was, to run a decently sized company at this point. And the thing I'd always liked the most was just getting to work with the researchers. And I was like, yeah, I can just go do a very focused AGI research effort. And I got excited about that. Didn't even occur to me at the time possibly that this was all going to get undone. This was Friday afternoon.].[00:14:19][Lex Fridman][So you've accepted the death of this-].[00:14:22][Sam Altman][Very quickly. Very quickly. I went through a little period of confusion and rage, but very quickly, quickly. And by Friday night, I was talking to people about what was going to be next, and I was excited about that. I think it was Friday evening for the first time that I heard from the exec team here, which is like, \u201cHey, we're going to fight this.\u201d and then I went to bed just still being like, okay, excited. Onward.].[00:14:52][Lex Fridman][Were you able to sleep?].[00:14:54][Sam Altman][Not a lot. One of the weird things was there was this period of four and a half days where I didn't sleep much, didn't eat much, and still had a surprising amount of energy. You learn a weird thing about adrenaline in wartime.].[00:15:09][Lex Fridman][So you accepted the death of this baby, OpenAI.].[00:15:13][Sam Altman][And I was excited for the new thing. I was just like, \u201cOkay, this was crazy, but whatever.\u201d].[00:15:17][Lex Fridman][It's a very good coping mechanism.].[00:15:18][Sam Altman][And then Saturday morning, two of the board members called and said, \u201cHey, we didn't mean to destabilize things. We don't want to store a lot of value here. Can we talk about you coming back?\u201d And I immediately didn't want to do that, but I thought a little more and I was like, well, I really care about the people here, the partners, shareholders. I love this company. And so I thought about it and I was like, \u201cWell, okay, but here's the stuff I would need.\u201d And then the most painful time of all was over the course of that weekend, I kept thinking and being told, and not just me, the whole team here kept thinking, well, we were trying to keep OpenAI stabilized while the whole world was trying to break it apart, people trying to recruit whatever.].[00:16:04][Sam Altman][We kept being told, all right, we're almost done. We're almost done. We just need a little bit more time. And it was this very confusing state. And then Sunday evening when, again, every few hours I expected that we were going to be done and we're going to figure out a way for me to return and things to go back to how they were. The board then appointed a new interim CEO, and then I was like, that feels really bad. That was the low point of the whole thing. I'll tell you something. It felt very painful, but I felt a lot of love that whole weekend. Other than that one moment Sunday night, I would not characterize my emotions as anger or hate, but I felt a lot of love from people, towards people. It was painful, but the dominant emotion of the weekend was love, not hate.].[00:17:04][Lex Fridman][You've spoken highly of Mira Murati, that she helped especially, as you put in the tweet, in the quiet moments when it counts. Perhaps we could take a bit of a tangent. What do you admire about Mira?].[00:17:15][Sam Altman][Well, she did a great job during that weekend in a lot of chaos, but people often see leaders in the crisis moments, good or bad. But a thing I really value in leaders is how people act on a boring Tuesday at 9:46 in the morning and in just the normal drudgery of the day-to-day. How someone shows up in a meeting, the quality of the decisions they make. That was what I meant about the quiet moments.].[00:17:47][Lex Fridman][Meaning most of the work is done on a day-by-day, in meeting-by-meeting. Just be present and make great decisions.].[00:17:58][Sam Altman][Yeah. Look, what you have wanted to spend the last 20 minutes about, and I understand, is this one very dramatic weekend, but that's not really what OpenAI is about. OpenAI is really about the other seven years.].[00:18:10][Lex Fridman][Well, yeah. Human civilization is not about the invasion of the Soviet Union by Nazi Germany, but still that's something people focus on.].[00:18:18][Sam Altman][Very understandable.].[00:18:19][Lex Fridman][It gives us an insight into human nature, the extremes of human nature, and perhaps some of the damage in some of the triumphs of human civilization can happen in those moments, so it's illustrative. Let me ask you about Ilya. Is he being held hostage in a secret nuclear facility?]."
            },
            {
                "title": "Ilya Sutskever",
                "statements": "[00:18:36][Sam Altman][No.].[00:18:37][Lex Fridman][What about a regular secret facility?].[00:18:39][Sam Altman][No.].[00:18:40][Lex Fridman][What about a nuclear non-secret facility?].[00:18:41][Sam Altman][Neither. Not that either.].[00:18:44][Lex Fridman][This is becoming a meme at some point. You've known Ilya for a long time. He was obviously part of this drama with the board and all that kind of stuff. What's your relationship with him now?].[00:18:57][Sam Altman][I love Ilya. I have tremendous respect for Ilya. I don't have anything I can say about his plans right now. That's a question for him, but I really hope we work together for certainly the rest of my career. He's a little bit younger than me. Maybe he works a little bit longer.].[00:19:15][Lex Fridman][There's a meme that he saw something, like he maybe saw AGI and that gave him a lot of worry internally. What did Ilya see?].[00:19:28][Sam Altman][Ilya has not seen AGI. None of us have seen AGI. We've not built AGI. I do think one of the many things that I really love about Ilya is he takes AGI and the safety concerns, broadly speaking, including things like the impact this is going to have on society, very seriously. And as we continue to make significant progress, Ilya is one of the people that I've spent the most time over the last couple of years talking about what this is going to mean, what we need to do to ensure we get it right, to ensure that we succeed at the mission. So Ilya did not see AGI, but Ilya is a credit to humanity in terms of how much he thinks and worries about making sure we get this right.].[00:20:30][Lex Fridman][I've had a bunch of conversation with him in the past. I think when he talks about technology, he's always doing this long-term thinking type of thing. So he is not thinking about what this is going to be in a year. He's thinking about in 10 years, just thinking from first principles like, \u201cOkay, if this scales, what are the fundamentals here? Where's this going?\u201d And so that's a foundation for them thinking about all the other safety concerns and all that kind of stuff, which makes him a really fascinating human to talk with. Do you have any idea why he's been quiet? Is it he's just doing some soul-searching?].[00:21:08][Sam Altman][Again, I don't want to speak for Ilya. I think that you should ask him that. He's definitely a thoughtful guy. I think Ilya is always on a soul search in a really good way.].[00:21:27][Lex Fridman][Yes. Yeah. Also, he appreciates the power of silence. Also, I'm told he can be a silly guy, which I've never seen that side of him.].[00:21:36][Sam Altman][It's very sweet when that happens.].[00:21:39][Lex Fridman][I've never witnessed a silly Ilya, but I look forward to that as well.].[00:21:43][Sam Altman][I was at a dinner party with him recently and he was playing with a puppy and he was in a very silly mood, very endearing. And I was thinking, oh man, this is not the side of Ilya that the world sees the most.].[00:21:55][Lex Fridman][So just to wrap up this whole saga, are you feeling good about the board structure-].[00:21:55][Sam Altman][Yes.].[00:22:01][Lex Fridman][... about all of this and where it's moving?].[00:22:04][Sam Altman][I feel great about the new board. In terms of the structure of OpenAI, one of the board's tasks is to look at that and see where we can make it more robust. We wanted to get new board members in place first, but we clearly learned a lesson about structure throughout this process. I don't have, I think, super deep things to say. It was a crazy, very painful experience. I think it was a perfect storm of weirdness. It was a preview for me of what's going to happen as the stakes get higher and higher and the need that we have robust governance structures and processes and people. I'm happy it happened when it did, but it was a shockingly painful thing to go through.].[00:22:47][Lex Fridman][Did it make you be more hesitant in trusting people?].[00:22:50][Sam Altman][Yes.].[00:22:51][Lex Fridman][Just on a personal level?].[00:22:52][Sam Altman][Yes. I think I'm like an extremely trusting person. I've always had a life philosophy of don't worry about all of the paranoia. Don't worry about the edge cases. You get a little bit screwed in exchange for getting to live with your guard down. And this was so shocking to me. I was so caught off guard that it has definitely changed, and I really don't like this, it's definitely changed how I think about just default trust of people and planning for the bad scenarios.].[00:23:21][Lex Fridman][You got to be careful with that. Are you worried about becoming a little too cynical?].[00:23:26][Sam Altman][I'm not worried about becoming too cynical. I think I'm the extreme opposite of a cynical person, but I'm worried about just becoming less of a default trusting person.].[00:23:36][Lex Fridman][I'm actually not sure which mode is best to operate in for a person who's developing AGI, trusting or un-trusting. It's an interesting journey you're on. But in terms of structure, see, I'm more interested on the human level. How do you surround yourself with humans that are building cool shit, but also are making wise decisions? Because the more money you start making, the more power the thing has, the weirder people get.].[00:24:06][Sam Altman][I think you could make all kinds of comments about the board members and the level of trust I should have had there, or how I should have done things differently. But in terms of the team here, I think you'd have to give me a very good grade on that one. And I have just enormous gratitude and trust and respect for the people that I work with every day, and I think being surrounded with people like that is really important.]."
            },
            {
                "title": "Elon Musk lawsuit",
                "statements": "[00:24:39][Lex Fridman][Our mutual friend Elon sued OpenAI. What to you is the essence of what he's criticizing? To what degree does he have a point? To what degree is he wrong?].[00:24:52][Sam Altman][I don't know what it's really about. We started off just thinking we were going to be a research lab and having no idea about how this technology was going to go. Because it was only seven or eight years ago, it's hard to go back and really remember what it was like then, but this is before language models were a big deal. This was before we had any idea about an API or selling access to a chatbot. It was before we had any idea we were going to productize at all. So we're like, \u201cWe're just going to try to do research and we don't really know what we're going to do with that.\u201d I think with many fundamentally new things, you start fumbling through the dark and you make some assumptions, most of which turned out to be wrong.].[00:25:31][Sam Altman][And then it became clear that we were going to need to do different things and also have huge amounts more capital. So we said, \u201cOkay, well, the structure doesn't quite work for that. How do we patch the structure?\u201d And then you patch it again and patch it again and you end up with something that does look eyebrow-raising, to say the least. But we got here gradually with, I think, reasonable decisions at each point along the way. And it doesn't mean I wouldn't do it totally differently if we could go back now with an Oracle, but you don't get the Oracle at the time. But anyway, in terms of what Elon's real motivations here are, I don't know.].[00:26:12][Lex Fridman][To the degree you remember, what was the response that OpenAI gave in the blog post? Can you summarize it?].[00:26:21][Sam Altman][Oh, we just said Elon said this set of things. Here's our characterization, or here's not our characterization. Here's the characterization of how this went down. We tried to not make it emotional and just say, \u201cHere's the history.\u201d].[00:26:44][Lex Fridman][I do think there's a degree of mischaracterization from Elon here about one of the points you just made, which is the degree of uncertainty you had at the time. You guys are a small group of researchers crazily talking about AGI when everybody's laughing at that thought.].[00:27:09][Sam Altman][It wasn't that long ago Elon was crazily talking about launching rockets when people were laughing at that thought, so I think he'd have more empathy for this.].[00:27:20][Lex Fridman][I do think that there's personal stuff here, that there was a split that OpenAI and a lot of amazing people here chose to part ways with Elon, so there's a personal-].[00:27:34][Sam Altman][Elon chose to part ways.].[00:27:37][Lex Fridman][Can you describe that exactly? The choosing to part ways?].[00:27:42][Sam Altman][He thought OpenAI was going to fail. He wanted total control to turn it around. We wanted to keep going in the direction that now has become OpenAI. He also wanted Tesla to be able to build an AGI effort. At various times, he wanted to make OpenAI into a for-profit company that he could have control of or have it merge with Tesla. We didn't want to do that, and he decided to leave, which that's fine.].[00:28:06][Lex Fridman][So you're saying, and that's one of the things that the blog post says, is that he wanted OpenAI to be basically acquired by Tesla in the same way that, or maybe something similar or maybe something more dramatic than the partnership with Microsoft.].[00:28:23][Sam Altman][My memory is the proposal was just like, yeah, get acquired by Tesla and have Tesla have full control over it. I'm pretty sure that's what it was.].[00:28:29][Lex Fridman][So what does the word open in OpenAI mean to Elon at the time? Ilya has talked about this in the email exchanges and all this kind of stuff. What does it mean to you at the time? What does it mean to you now?].[00:28:44][Sam Altman][Speaking of going back with an Oracle, I'd pick a different name. One of the things that I think OpenAI is doing that is the most important of everything that we're doing is putting powerful technology in the hands of people for free, as a public good. We don't run ads on our-].[00:29:01][Sam Altman][... as a public good. We don't run ads on our free version. We don't monetize it in other ways. We just say it's part of our mission. We want to put increasingly powerful tools in the hands of people for free and get them to use them. I think that kind of open is really important to our mission. I think if you give people great tools and teach them to use them or don't even teach them, they'll figure it out, and let them go build an incredible future for each other with that, that's a big deal. So if we can keep putting free or low cost or free and low cost powerful AI tools out in the world, I think that's a huge deal for how we fulfill the mission. Open source or not, yeah, I think we should open source some stuff and not other stuff. It does become this religious battle line where nuance is hard to have, but I think nuance is the right answer.].[00:29:55][Lex Fridman][So he said, \u201cChange your name to CloseAI and I'll drop the lawsuit.\u201d I mean is it going to become this battleground in the land of memes about the name?].[00:30:06][Sam Altman][I think that speaks to the seriousness with which Elon means the lawsuit, and that's like an astonishing thing to say, I think.].[00:30:23][Lex Fridman][Maybe correct me if I'm wrong, but I don't think the lawsuit is legally serious. It's more to make a point about the future of AGI and the company that's currently leading the way.].[00:30:37][Sam Altman][Look, I mean Grok had not open sourced anything until people pointed out it was a little bit hypocritical and then he announced that Grok will open source things this week. I don't think open source versus not is what this is really about for him.].[00:30:48][Lex Fridman][Well, we will talk about open source and not. I do think maybe criticizing the competition is great. Just talking a little shit, that's great. But friendly competition versus like, \u201cI personally hate lawsuits.\u201d].[00:31:01][Sam Altman][Look, I think this whole thing is unbecoming of a builder. And I respect Elon as one of the great builders of our time. I know he knows what it's like to have haters attack him and it makes me extra sad he's doing it toss.].[00:31:18][Lex Fridman][Yeah, he's one of the greatest builders of all time, potentially the greatest builder of all time.].[00:31:22][Sam Altman][It makes me sad. And I think it makes a lot of people sad. There's a lot of people who've really looked up to him for a long time. I said in some interview or something that I missed the old Elon and the number of messages I got being like, \u201cThat exactly encapsulates how I feel.\u201d].[00:31:36][Lex Fridman][I think he should just win. He should just make X Grok beat GPT and then GPT beats Grok and it's just the competition and it's beautiful for everybody. But on the question of open source, do you think there's a lot of companies playing with this idea? It's quite interesting. I would say Meta surprisingly has led the way on this, or at least took the first step in the game of chess of really open sourcing the model. Of course it's not the state-of-the-art model, but open sourcing Llama Google is flirting with the idea of open sourcing a smaller version. What are the pros and cons of open sourcing? Have you played around with this idea?].[00:32:22][Sam Altman][Yeah, I think there is definitely a place for open source models, particularly smaller models that people can run locally, I think there's huge demand for. I think there will be some open source models, there will be some closed source models. It won't be unlike other ecosystems in that way.].[00:32:39][Lex Fridman][I listened to all in podcasts talking about this lawsuit and all that kind of stuff. They were more concerned about the precedent of going from nonprofit to this cap for profit. What precedent that sets for other startups? Is that something-].[00:32:56][Sam Altman][I would heavily discourage any startup that was thinking about starting as a nonprofit and adding a for-profit arm later. I'd heavily discourage them from doing that. I don't think we'll set a precedent here.].[00:33:05][Lex Fridman][Okay. So most startups should go just-].[00:33:08][Sam Altman][For sure.].[00:33:09][Lex Fridman][And again-].[00:33:09][Sam Altman][If we knew what was going to happen, we would've done that too.].[00:33:12][Lex Fridman][Well in theory, if you dance beautifully here, there's some tax incentives or whatever, but...].[00:33:19][Sam Altman][I don't think that's how most people think about these things.].[00:33:22][Lex Fridman][It's just not possible to save a lot of money for a startup if you do it this way.].[00:33:27][Sam Altman][No, I think there's laws that would make that pretty difficult.].[00:33:30][Lex Fridman][Where do you hope this goes with Elon? This tension, this dance, what do you hope this? If we go 1, 2, 3 years from now, your relationship with him on a personal level too, like friendship, friendly competition, just all this kind of stuff.].[00:33:51][Sam Altman][Yeah, I really respect Elon and I hope that years in the future we have an amicable relationship.].[00:34:05][Lex Fridman][Yeah, I hope you guys have an amicable relationship this month and just compete and win and explore these ideas together. I do suppose there's competition for talent or whatever, but it should be friendly competition. Just build cool shit. And Elon is pretty good at building cool shit. So are you.]."
            },
            {
                "title": "Sora",
                "statements": "[00:34:32][Lex Fridman][So speaking of cool shit, Sora. There's like a million questions I could ask. First of all, it's amazing. It truly is amazing on a product level but also just on a philosophical level. So let me just technical/philosophical ask, what do you think it understands about the world more or less than GPT-4 for example? The world model when you train on these patches versus language tokens.].[00:35:04][Sam Altman][I think all of these models understand something more about the world model than most of us give them credit for. And because they're also very clear things they just don't understand or don't get right, it's easy to look at the weaknesses, see through the veil and say, \u201cAh, this is all fake.\u201d But it's not all fake. It's just some of it works and some of it doesn't work.].[00:35:28][Sam Altman][I remember when I started first watching Sora videos and I would see a person walk in front of something for a few seconds and occlude it and then walk away and the same thing was still there. I was like, \u201cOh, this is pretty good.\u201d Or there's examples where the underlying physics looks so well represented over a lot of steps in a sequence, it's like, \u201c|Oh, this is quite impressive.\u201d But fundamentally, these models are just getting better and that will keep happening. If you look at the trajectory from DALL\u00b7E 1 to 2 to 3 to Sora, there are a lot of people that were dunked on each version saying it can't do this, it can't do that and look at it now.].[00:36:04][Lex Fridman][Well, the thing you just mentioned is the occlusions is basically modeling the physics of the three-dimensional physics of the world sufficiently well to capture those kinds of things.].[00:36:17][Sam Altman][Well...].[00:36:18][Lex Fridman][Or yeah, maybe you can tell me, in order to deal with occlusions, what does the world model need to?].[00:36:24][Sam Altman][Yeah. So what I would say is it's doing something to deal with occlusions really well. What I represent that it has a great underlying 3D model of the world, it's a little bit more of a stretch.].[00:36:33][Lex Fridman][But can you get there through just these kinds of two-dimensional training data approaches?].[00:36:39][Sam Altman][It looks like this approach is going to go surprisingly far. I don't want to speculate too much about what limits it will surmount and which it won't, but...].[00:36:46][Lex Fridman][What are some interesting limitations of the system that you've seen? I mean there's been some fun ones you've posted.].[00:36:52][Sam Altman][There's all kinds of fun. I mean, cat's sprouting an extra limit at random points in a video. Pick what you want, but there's still a lot of problem, there's a lot of weaknesses.].[00:37:02][Lex Fridman][Do you think it's a fundamental flaw of the approach or is it just bigger model or better technical details or better data, more data is going to solve the cat sprouting [inaudible 00:37:19]?].[00:37:19][Sam Altman][I would say yes to both. I think there is something about the approach which just seems to feel different from how we think and learn and whatever. And then also I think it'll get better with scale.].[00:37:30][Lex Fridman][Like I mentioned, LLMS have tokens, text tokens, and Sora has visual patches so it converts all visual data, a diverse kinds of visual data videos and images into patches. Is the training to the degree you can say fully self supervised, there's some manual labeling going on? What's the involvement of humans in all this?].[00:37:49][Sam Altman][I mean without saying anything specific about the Sora approach, we use lots of human data in our work.].[00:38:00][Lex Fridman][But not internet scale data? So lots of humans. Lots is a complicated word, Sam.].[00:38:08][Sam Altman][I think lots is a fair word in this case.].[00:38:12][Lex Fridman][Because to me, \u201clots\u201d... Listen, I'm an introvert and when I hang out with three people, that's a lot of people. Four people, that's a lot. But I suppose you mean more than...].[00:38:21][Sam Altman][More than three people work on labeling the data for these models, yeah.].[00:38:24][Lex Fridman][Okay. Right. But fundamentally, there's a lot of self supervised learning. Because what you mentioned in the technical report is internet scale data. That's another beautiful... It's like poetry. So it's a lot of data that's not human label. It's self supervised in that way?].[00:38:44][Sam Altman][Yeah.].[00:38:45][Lex Fridman][And then the question is, how much data is there on the internet that could be used in this that is conducive to this kind of self supervised way if only we knew the details of the self supervised. Have you considered opening it up a little more details?].[00:39:02][Sam Altman][We have. You mean for source specifically?].[00:39:04][Lex Fridman][Source specifically. Because it's so interesting that can the same magic of LLMs now start moving towards visual data and what does that take to do that?].[00:39:18][Sam Altman][I mean it looks to me like yes, but we have more work to do.].[00:39:22][Lex Fridman][Sure. What are the dangers? Why are you concerned about releasing the system? What are some possible dangers of this?].[00:39:29][Sam Altman][I mean frankly speaking, one thing we have to do before releasing the system is just get it to work at a level of efficiency that will deliver the scale people are going to want from this so that I don't want to downplay that. And there's still a ton ton of work to do there. But you can imagine issues with deepfakes, misinformation. We try to be a thoughtful company about what we put out into the world and it doesn't take much thought to think about the ways this can go badly.].[00:40:05][Lex Fridman][There's a lot of tough questions here, you're dealing in a very tough space. Do you think training AI should be or is fair use under copyright law?].[00:40:14][Sam Altman][I think the question behind that question is, do people who create valuable data deserve to have some way that they get compensated for use of it, and that I think the answer is yes. I don't know yet what the answer is. People have proposed a lot of different things. We've tried some different models. But if I'm like an artist for example, A, I would like to be able to opt out of people generating art in my style. And B, if they do generate art in my style, I'd like to have some economic model associated with that.].[00:40:46][Lex Fridman][Yeah, it's that transition from CDs to Napster to Spotify. We have to figure out some kind of model.].[00:40:53][Sam Altman][The model changes but people have got to get paid.].[00:40:55][Lex Fridman][Well, there should be some kind of incentive if we zoom out even more for humans to keep doing cool shit.].[00:41:02][Sam Altman][Of everything I worry about, humans are going to do cool shit and society is going to find some way to reward it. That seems pretty hardwired. We want to create, we want to be useful, we want to achieve status in whatever way. That's not going anywhere I don't think.].[00:41:17][Lex Fridman][But the reward might not be monetary financially. It might be fame and celebration of other cool-].[00:41:25][Sam Altman][Maybe financial in some other way. Again, I don't think we've seen the last evolution of how the economic system's going to work.].[00:41:31][Lex Fridman][Yeah, but artists and creators are worried. When they see Sora, they're like, \u201cHoly shit.\u201d].[00:41:36][Sam Altman][Sure. Artists were also super worried when photography came out and then photography became a new art form and people made a lot of money taking pictures. I think things like that will keep happening. People will use the new tools in new ways.].[00:41:50][Lex Fridman][If we just look on YouTube or something like this, how much of that will be using Sora like AI generated content, do you think, in the next five years?].[00:42:01][Sam Altman][People talk about how many jobs is AI going to do in five years. The framework that people have is, what percentage of current jobs are just going to be totally replaced by some AI doing the job? The way I think about it is not what percent of jobs AI will do, but what percent of tasks will AI do on over one time horizon. So if you think of all of the five-second tasks in the economy, five minute tasks, the five-hour tasks, maybe even the five-day tasks, how many of those can AI do? I think that's a way more interesting, impactful, important question than how many jobs AI can do because it is a tool that will work at increasing levels of sophistication and over longer and longer time horizons for more and more tasks and let people operate at a higher level of abstraction. So maybe people are way more efficient at the job they do. And at some point that's not just a quantitative change, but it's a qualitative one too about the kinds of problems you can keep in your head. I think that for videos on YouTube it'll be the same. Many videos, maybe most of them, will use AI tools in the production, but they'll still be fundamentally driven by a person thinking about it, putting it together, doing parts of it. Sort of directing and running it.].[00:43:18][Lex Fridman][Yeah, it's so interesting. I mean it's scary, but it's interesting to think about. I tend to believe that humans like to watch other humans or other human humans-].[00:43:27][Sam Altman][Humans really care about other humans a lot.].[00:43:29][Lex Fridman][Yeah. If there's a cooler thing that's better than a human, humans care about that for two days and then they go back to humans.].[00:43:39][Sam Altman][That seems very deeply wired.].[00:43:41][Lex Fridman][It's the whole chess thing, \u201cOh, yeah,\u201d but now let's everybody keep playing chess. And let's ignore the elephant in the room that humans are really bad at chess relative to AI systems.].[00:43:52][Sam Altman][We still run races and cars are much faster. I mean there's a lot of examples.].[00:43:56][Lex Fridman][Yeah. And maybe it'll just be tooling in the Adobe suite type of way where it can just make videos much easier and all that kind of stuff.].[00:44:07][Lex Fridman][Listen, I hate being in front of the camera. If I can figure out a way to not be in front of the camera, I would love it. Unfortunately, it'll take a while. That generating faces, it is getting there, but generating faces in video format is tricky when it's specific people versus generic people.]."
            },
            {
                "title": "GPT-4",
                "statements": "[00:44:24][Lex Fridman][Let me ask you about GPT-4. There's so many questions. First of all, also amazing. Looking back, it'll probably be this kind of historic pivotal moment with 3, 5 and 4 which ChatGPT.].[00:44:40][Sam Altman][Maybe five will be the pivotal moment. I don't know. Hard to say that looking forward.].[00:44:44][Lex Fridman][We'll never know. That's the annoying thing about the future, it's hard to predict. But for me, looking back, GPT-4, ChatGPT is pretty damn impressive, historically impressive. So allow me to ask, what's been the most impressive capabilities of GPT-4 to you and GPT-4 Turbo?].[00:45:06][Sam Altman][I think it kind of sucks.].[00:45:08][Lex Fridman][Typical human also, gotten used to an awesome thing.].[00:45:11][Sam Altman][No, I think it is an amazing thing, but relative to where we need to get to and where I believe we will get to, at the time of GPT-3, people are like, \u201cOh, this is amazing. This is marvel of technology.\u201d And it is, it was. But now we have GPT-4 and look at GPT-3 and you're like, \u201cThat's unimaginably horrible.\u201d I expect that the delta between 5 and 4 will be the same as between 4 and 3 and I think it is our job to live a few years in the future and remember that the tools we have now are going to kind of suck looking backwards at them and that's how we make sure the future is better.].[00:45:59][Lex Fridman][What are the most glorious ways in that GPT-4 sucks? Meaning-].[00:46:05][Sam Altman][What are the best things it can do?].[00:46:06][Lex Fridman][What are the best things it can do and the limits of those best things that allow you to say it sucks, therefore gives you an inspiration and hope for the future?].[00:46:16][Sam Altman][One thing I've been using it for more recently is sort of like a brainstorming partner.].[00:46:23][Lex Fridman][Yep, [inaudible 00:46:25] for that.].[00:46:25][Sam Altman][There's a glimmer of something amazing in there. When people talk about it, what it does, they're like, \u201cOh, it helps me code more productively. It helps me write more faster and better. It helps me translate from this language to another,\u201d all these amazing things, but there's something about the kind of creative brainstorming partner, \u201cI need to come up with a name for this thing. I need to think about this problem in a different way. I'm not sure what to do here,\u201d that I think gives a glimpse of something I hope to see more of.].[00:47:03][Sam Altman][One of the other things that you can see a very small glimpse of is when I can help on longer horizon tasks, break down something in multiple steps, maybe execute some of those steps, search the internet, write code, whatever, put that together. When that works, which is not very often, it's very magical.].[00:47:24][Lex Fridman][The iterative back and forth with a human, it works a lot for me. What do you mean it-].[00:47:29][Sam Altman][Iterative back and forth to human, it can get more often when it can go do a 10 step problem on its own.].[00:47:33][Lex Fridman][Oh.].[00:47:34][Sam Altman][It doesn't work for that too often, sometimes.].[00:47:37][Lex Fridman][Add multiple layers of abstraction or do you mean just sequential?].[00:47:40][Sam Altman][Both, to break it down and then do things that different layers of abstraction to put them together. Look, I don't want to downplay the accomplishment of GPT-4, but I don't want to overstate it either. And I think this point that we are on an exponential curve, we'll look back relatively soon at GPT-4 like we look back at GPT-3 now.].[00:48:03][Lex Fridman][That said, I mean ChatGPT was a transition to where people started to believe there is an uptick of believing, not internally at OpenAI.].[00:48:04][Sam Altman][For sure.].[00:48:16][Lex Fridman][Perhaps there's believers here, but when you think of-].[00:48:19][Sam Altman][And in that sense, I do think it'll be a moment where a lot of the world went from not believing to believing. That was more about the ChatGPT interface. And by the interface and product, I also mean the post training of the model and how we tune it to be helpful to you and how to use it than the underlying model itself.].[00:48:38][Lex Fridman][How much of each of those things are important? The underlying model and the RLHF or something of that nature that tunes it to be more compelling to the human, more effective and productive for the human.].[00:48:55][Sam Altman][I mean they're both super important, but the RLHF, the post-training step, the little wrapper of things that from a compute perspective, little wrapper of things that we do on top of the base model even though it's a huge amount of work, that's really important to say nothing of the product that we build around it. In some sense, we did have to do two things. We had to invent the underlying technology and then we had to figure out how to make it into a product people would love, which is not just about the actual product work itself, but this whole other step of how you align it and make it useful.].[00:49:37][Lex Fridman][And how you make the scale work where a lot of people can use it at the same time. All that kind of stuff.].[00:49:42][Sam Altman][And that. But that was a known difficult thing. We knew we were going to have to scale it up. We had to go do two things that had never been done before that were both I would say quite significant achievements and then a lot of things like scaling it up that other companies have had to do before.].[00:50:01][Lex Fridman][How does the context window of going from 8K to 128K tokens compare from GPT-4 to GPT-4 Turbo?].[00:50:13][Sam Altman][Most people don't need all the way to 128 most of the time. Although if we dream into the distant future, we'll have way distant future, we'll have context length of several billion. You will feed in all of your information, all of your history over time and it'll just get to know you better and better and that'll be great. For now, the way people use these models, they're not doing that. People sometimes post in a paper or a significant fraction of a code repository, whatever, but most usage of the models is not using the long context most of the time.].[00:50:50][Lex Fridman][I like that this is your \u201cI have a dream\u201d speech. One day you'll be judged by the full context of your character or of your whole lifetime. That's interesting. So that's part of the expansion that you're hoping for, is a greater and greater context.].[00:51:06][Sam Altman][I saw this internet clip once, I'm going to get the numbers wrong, but it was like Bill Gates talking about the amount of memory on some early computer, maybe it was 64K, maybe 640K, something like that. Most of it was used for the screen buffer. He just couldn't seem genuine. He just couldn't imagine that the world would eventually need gigabytes of memory in a computer or terabytes of memory in a computer. And you always do, or you always do just need to follow the exponential of technology and we will find out how to use better technology. So I can't really imagine what it's like right now for context links to go out to the billion someday. And they might not literally go there, but effectively it'll feel like that. But I know we'll use it and really not want to go back once we have it.].[00:51:56][Lex Fridman][Yeah, even saying billions 10 years from now might seem dumb because it'll be trillions upon trillions.].[00:52:04][Sam Altman][Sure.].[00:52:04][Lex Fridman][There'll be some kind of breakthrough that will effectively feel like infinite context. But even 120, I have to be honest, I haven't pushed it to that degree. Maybe putting in entire books or parts of books and so on, papers. What are some interesting use cases of GPT-4 that you've seen?].[00:52:23][Sam Altman][The thing that I find most interesting is not any particular use case that we can talk about those, but it's people who kind of like, this is mostly younger people, but people who use it as their default start for any kind of knowledge work task. And it's the fact that it can do a lot of things reasonably well. You can use GPT-V, you can use it to help you write code, you can use it to help you do search, you can use it to edit a paper. The most interesting thing to me is the people who just use it as the start of their workflow.].[00:52:52][Lex Fridman][I do as well for many things. I use it as a reading partner for reading books. It helps me think, help me think through ideas, especially when the books are classic. So it's really well written about. I find it often to be significantly better than even Wikipedia on well-covered topics. It's somehow more balanced and more nuanced. Or maybe it's me, but it inspires me to think deeper than a Wikipedia article does. I'm not exactly sure what that is.].[00:53:22][Lex Fridman][You mentioned this collaboration. I'm not sure where the magic is, if it's in here or if it's in there or if it's somewhere in between. I'm not sure. But one of the things that concerns me for knowledge task when I start with GPT is I'll usually have to do fact checking after, like check that it didn't come up with fake stuff. How do you figure that out that GPT can come up with fake stuff that sounds really convincing? So how do you ground it in truth?].[00:53:55][Sam Altman][That's obviously an area of intense interest for us. I think it's going to get a lot better with upcoming versions, but we'll have to continue to work on it and we're not going to have it all solved this year.].[00:54:07][Lex Fridman][Well the scary thing is, as it gets better, you'll start not doing the fact checking more and more, right?].[00:54:15][Sam Altman][I'm of two minds about that. I think people are much more sophisticated users of technology than we often give them credit for.].[00:54:15][Lex Fridman][Sure.].[00:54:21][Sam Altman][And people seem to really understand that GPT, any of these models hallucinate some of the time. And if it's mission-critical, you got to check it.].[00:54:27][Lex Fridman][Except journalists don't seem to understand that. I've seen journalists half-assedly just using GPT-4. It's-].[00:54:34][Sam Altman][Of the long list of things I'd like to dunk on journalists for, this is not my top criticism of them.].[00:54:40][Lex Fridman][Well, I think the bigger criticism is perhaps the pressures and the incentives of being a journalist is that you have to work really quickly and this is a shortcut.I would love our society to incentivize like-].[00:54:53][Sam Altman][I would too.].[00:54:55][Lex Fridman][... like a journalistic efforts that take days and weeks and rewards great in depth journalism. Also journalism that present stuff in a balanced way where it's like celebrates people while criticizing them even though the criticism is the thing that gets clicks and making shit up also gets clicks and headlines that mischaracterized completely. I'm sure you have a lot of people dunking on, \u201cWell, all that drama probably got a lot of clicks.\u201d].[00:55:21][Sam Altman][Probably did.]."
            },
            {
                "title": "Memory & privacy",
                "statements": "[00:55:24][Lex Fridman][And that's a bigger problem about human civilization I'd love to see-saw. This is where we celebrate a bit more. You've given ChatGPT the ability to have memories. You've been playing with that about previous conversations. And also the ability to turn off memory. I wish I could do that sometimes. Just turn on and off, depending. I guess sometimes alcohol can do that, but not optimally I suppose. What have you seen through that, like playing around with that idea of remembering conversations and not...].[00:55:56][Sam Altman][We're very early in our explorations here, but I think what people want, or at least what I want for myself, is a model that gets to know me and gets more useful to me over time. This is an early exploration. I think there's a lot of other things to do, but that's where we'd like to head. You'd like to use a model, and over the course of your life or use a system, it'd be many models, and over the course of your life it gets better and better.].[00:56:26][Lex Fridman][Yeah. How hard is that problem? Because right now it's more like remembering little factoids and preferences and so on. What about remembering? Don't you want GPT to remember all the shit you went through in November and all the drama and then you can-].[00:56:26][Sam Altman][Yeah. Yeah.].[00:56:41][Lex Fridman][Because right now you're clearly blocking it out a little bit.].[00:56:43][Sam Altman][It's not just that I want it to remember that. I want it to integrate the lessons of that and remind me in the future what to do differently or what to watch out for. We all gain from experience over the course of our lives in varying degrees, and I'd like my AI agent to gain with that experience too. So if we go back and let ourselves imagine that trillions and trillions of context length, if I can put every conversation I've ever had with anybody in my life in there, if I can have all of my emails input out, all of my input output in the context window every time I ask a question, that'd be pretty cool I think.].[00:57:29][Lex Fridman][Yeah, I think that would be very cool. People sometimes will hear that and be concerned about privacy. What do you think about that aspect of it, the more effective the AI becomes that really integrating all the experiences and all the data that happened to you and give you advice?].[00:57:48][Sam Altman][I think the right answer there is just user choice. Anything I want stricken from the record from my AI agent, I want to be able to take out. If I don't want to remember anything, I want that too. You and I may have different opinions about where on that privacy utility trade off for our own AI-].[00:58:00][Sam Altman][...opinions about where on that privacy/utility trade-off for OpenAI going to be, which is totally fine. But I think the answer is just really easy user choice.].[00:58:08][Lex Fridman][But there should be some high level of transparency from a company about the user choice. Because sometimes companies in the past have been kind of shady about, \u201cEh, it's kind of presumed that we're collecting all your data. We're using it for a good reason, for advertisement and so on.\u201d But there's not a transparency about the details of that.].[00:58:31][Sam Altman][That's totally true. You mentioned earlier that I'm blocking out the November stuff.].[00:58:35][Lex Fridman][Just teasing you.].[00:58:36][Sam Altman][Well, I mean, I think it was a very traumatic thing and it did immobilize me for a long period of time. Definitely the hardest work thing I've had to do was just keep working that period, because I had to try to come back in here and put the pieces together while I was just in shock and pain, and nobody really cares about that. I mean, the team gave me a pass and I was not working at my normal level. But there was a period where it was really hard to have to do both. But I kind of woke up one morning, and I was like, \u201cThis was a horrible thing that happened to me. I think I could just feel like a victim forever, or I can say this is the most important work I'll ever touch in my life and I need to get back to it.\u201d And it doesn't mean that I've repressed it, because sometimes I wake up in the middle of the night thinking about it, but I do feel an obligation to keep moving forward.].[00:59:32][Lex Fridman][Well, that's beautifully said, but there could be some lingering stuff in there. Like, what I would be concerned about is that trust thing that you mentioned, that being paranoid about people as opposed to just trusting everybody or most people, like using your gut. It's a tricky dance.].[00:59:50][Sam Altman][For sure.].[00:59:51][Lex Fridman][I mean, because I've seen in my part-time explorations, I've been diving deeply into the Zelenskyy administration and the Putin administration and the dynamics there in wartime in a very highly stressful environment. And what happens is distrust, and you isolate yourself, both, and you start to not see the world clearly. And that's a human concern. You seem to have taken it in stride and kind of learned the good lessons and felt the love and let the love energize you, which is great, but still can linger in there. There's just some questions I would love to ask, your intuition about what's GPT able to do and not. So it's allocating approximately the same amount of compute for each token it generates. Is there room there in this kind of approach to slower thinking, sequential thinking?].[01:00:51][Sam Altman][I think there will be a new paradigm for that kind of thinking.].[01:00:55][Lex Fridman][Will it be similar architecturally as what we're seeing now with LLMs? Is it a layer on top of LLMs?].[01:01:04][Sam Altman][I can imagine many ways to implement that. I think that's less important than the question you were getting at, which is, do we need a way to do a slower kind of thinking, where the answer doesn't have to get... I guess spiritually you could say that you want an AI to be able to think harder about a harder problem and answer more quickly about an easier problem. And I think that will be important.].[01:01:30][Lex Fridman][Is that like a human thought that we just have and you should be able to think hard? Is that wrong intuition?].[01:01:34][Sam Altman][I suspect that's a reasonable intuition.].[01:01:37][Lex Fridman][Interesting. So it's not possible once the GPT gets like GPT-7, would just instantaneously be able to see, \u201cHere's the proof of Fermat's Theorem\u201d?].[01:01:49][Sam Altman][It seems to me like you want to be able to allocate more compute to harder problems. It seems to me that if you ask a system like that, \u201cProve Fermat's Last Theorem,\u201d versus, \u201cWhat's today's date?,\u201d unless it already knew and and had memorized the answer to the proof, assuming it's got to go figure that out, seems like that will take more compute.].[01:02:20][Lex Fridman][But can it look like basically an LLM talking to itself, that kind of thing?].[01:02:25][Sam Altman][Maybe. I mean, there's a lot of things that you could imagine working. What the right or the best way to do that will be, we don't know.]."
            },
            {
                "title": "Q*",
                "statements": "[01:02:37][Lex Fridman][This does make me think of the mysterious lore behind Q*. What's this mysterious Q* project? Is it also in the same nuclear facility?].[01:02:50][Sam Altman][There is no nuclear facility.].[01:02:52][Lex Fridman][Mm-hmm. That's what a person with a nuclear facility always says.].[01:02:54][Sam Altman][I would love to have a secret nuclear facility. There isn't one.].[01:02:59][Lex Fridman][All right.].[01:03:00][Sam Altman][Maybe someday.].[01:03:01][Lex Fridman][Someday? All right. One can dream.].[01:03:05][Sam Altman][OpenAI is not a good company at keeping secrets. It would be nice. We're like, been plagued by a lot of leaks, and it would be nice if we were able to have something like that.].[01:03:14][Lex Fridman][Can you speak to what Q* is?].[01:03:16][Sam Altman][We are not ready to talk about that.].[01:03:17][Lex Fridman][See, but an answer like that means there's something to talk about. It's very mysterious, Sam.].[01:03:22][Sam Altman][I mean, we work on all kinds of research. We have said for a while that we think better reasoning in these systems is an important direction that we'd like to pursue. We haven't cracked the code yet. We're very interested in it.].[01:03:48][Lex Fridman][Is there going to be moments, Q* or otherwise, where there's going to be leaps similar to ChatGPT, where you're like...].[01:03:56][Sam Altman][That's a good question. What do I think about that? It's interesting. To me, it all feels pretty continuous.].[01:04:08][Lex Fridman][Right. This is kind of a theme that you're saying, is you're basically gradually going up an exponential slope. But from an outsider's perspective, from me just watching, it does feel like there's leaps. But to you, there isn't?].[01:04:22][Sam Altman][I do wonder if we should have... So part of the reason that we deploy the way we do, we call it iterative deployment, rather than go build in secret until we got all the way to GPT-5, we decided to talk about GPT-1, 2, 3, and 4. And part of the reason there is I think AI and surprise don't go together. And also the world, people, institutions, whatever you want to call it, need time to adapt and think about these things. And I think one of the best things that OpenAI has done is this strategy, and we get the world to pay attention to the progress, to take AGI seriously, to think about what systems and structures and governance we want in place before we're under the gun and have to make a rush decision.].[01:05:08][Sam Altman][I think that's really good. But the fact that people like you and others say you still feel like there are these leaps makes me think that maybe we should be doing our releasing even more iteratively. And I don't know what that would mean, I don't have an answer ready to go, but our goal is not to have shock updates to the world. The opposite.].[01:05:29][Lex Fridman][Yeah, for sure. More iterative would be amazing. I think that's just beautiful for everybody.].[01:05:34][Sam Altman][But that's what we're trying to do, that's our stated strategy, and I think we're somehow missing the mark. So maybe we should think about releasing GPT-5 in a different way or something like that.].[01:05:44][Lex Fridman][Yeah, 4.71, 4.72. But people tend to like to celebrate, people celebrate birthdays. I don't know if you know humans, but they kind of have these milestones and those things.].[01:05:54][Sam Altman][I do know some humans. People do like milestones. I totally get that. I think we like milestones too. It's fun to declare victory on this one and go start the next thing. But yeah, I feel like we're somehow getting this a little bit wrong.]."
            },
            {
                "title": "GPT-5",
                "statements": "[01:06:13][Lex Fridman][So when is GPT-5 coming out again?].[01:06:15][Sam Altman][I don't know. That's the honest answer.].[01:06:18][Lex Fridman][Oh, that's the honest answer. Blink twice if it's this year.].[01:06:30][Sam Altman][We will release an amazing new model this year. I don't know what we'll call it.].[01:06:36][Lex Fridman][So that goes to the question of, what's the way we release this thing?].[01:06:41][Sam Altman][We'll release in the coming months many different things. I think that'd be very cool. I think before we talk about a GPT-5-like model called that, or not called that, or a little bit worse or a little bit better than what you'd expect from a GPT-5, I think we have a lot of other important things to release first.].[01:07:02][Lex Fridman][I don't know what to expect from GPT-5. You're making me nervous and excited. What are some of the biggest challenges and bottlenecks to overcome for whatever it ends up being called, but let's call it GPT-5? Just interesting to ask. Is it on the compute side? Is it on the technical side?].[01:07:21][Sam Altman][It's always all of these. You know, what's the one big unlock? Is it a bigger computer? Is it a new secret? Is it something else? It's all of these things together. The thing that OpenAI, I think, does really well... This is actually an original Ilya quote that I'm going to butcher, but it's something like, \u201cWe multiply 200 medium-sized things together into one giant thing.\u201d].[01:07:47][Lex Fridman][So there's this distributed constant innovation happening?].[01:07:50][Sam Altman][Yeah.].[01:07:51][Lex Fridman][So even on the technical side?].[01:07:53][Sam Altman][Especially on the technical side.].[01:07:55][Lex Fridman][So even detailed approaches?].[01:07:56][Sam Altman][Yeah.].[01:07:56][Lex Fridman][Like you do detailed aspects of every... How does that work with different, disparate teams and so on? How do the medium-sized things become one whole giant Transformer?].[01:08:08][Sam Altman][There's a few people who have to think about putting the whole thing together, but a lot of people try to keep most of the picture in their head.].[01:08:14][Lex Fridman][Oh, like the individual teams, individual contributors try to keep the bigger picture?].[01:08:17][Sam Altman][At a high level, yeah. You don't know exactly how every piece works, of course, but one thing I generally believe is that it's sometimes useful to zoom out and look at the entire map. And I think this is true for a technical problem, I think this is true for innovating in business. But things come together in surprising ways, and having an understanding of that whole picture, even if most of the time you're operating in the weeds in one area, pays off with surprising insights. In fact, one of the things that I used to have and was super valuable was I used to have a good map of all or most of the frontiers in the tech industry. And I could sometimes see these connections or new things that were possible that if I were only deep in one area, I wouldn't be able to have the idea for because I wouldn't have all the data. And I don't really have that much anymore. I'm super deep now. But I know that it's a valuable thing.].[01:09:23][Lex Fridman][You're not the man you used to be, Sam.].[01:09:25][Sam Altman][Very different job now than what I used to have.]."
            },
            {
                "title": "$7 trillion of compute",
                "statements": "[01:09:28][Lex Fridman][Speaking of zooming out, let's zoom out to another cheeky thing, but profound thing, perhaps, that you said. You tweeted about needing $7 trillion.].[01:09:41][Sam Altman][I did not tweet about that. I never said, like, \u201cWe're raising $7 trillion,\u201d blah blah blah.].[01:09:45][Lex Fridman][Oh, that's somebody else?].[01:09:46][Sam Altman][Yeah.].[01:09:47][Lex Fridman][Oh, but you said, \u201cFuck it, maybe eight,\u201d I think?].[01:09:50][Sam Altman][Okay, I meme once there's misinformation out in the world.].[01:09:53][Lex Fridman][Oh, you meme. But misinformation may have a foundation of insight there.].[01:10:01][Sam Altman][Look, I think compute is going to be the currency of the future. I think it will be maybe the most precious commodity in the world, and I think we should be investing heavily to make a lot more compute. Compute, I think it's going to be an unusual market. People think about the market for chips for mobile phones or something like that. And you can say that, okay, there's 8 billion people in the world, maybe 7 billion of them have phones, maybe 6 billion, let's say. They upgrade every two years, so the market per year is 3 billion system-on-chip for smartphones. And if you make 30 billion, you will not sell 10 times as many phones, because most people have one phone.].[01:10:50][Sam Altman][But compute is different. Intelligence is going to be more like energy or something like that, where the only thing that I think makes sense to talk about is, at price X, the world will use this much compute, and at price Y, the world will use this much compute. Because if it's really cheap, I'll have it reading my email all day, giving me suggestions about what I maybe should think about or work on, and trying to cure cancer, and if it's really expensive, maybe I'll only use it, or we'll only use it, to try to cure cancer.].[01:11:20][Sam Altman][So I think the world is going to want a tremendous amount of compute. And there's a lot of parts of that that are hard. Energy is the hardest part, building data centers is also hard, the supply chain is hard, and then of course, fabricating enough chips is hard. But this seems to be where things are going. We're going to want an amount of compute that's just hard to reason about right now.].[01:11:43][Lex Fridman][How do you solve the energy puzzle? Nuclear-].[01:11:46][Sam Altman][That's what I believe.].[01:11:47][Lex Fridman][...fusion?].[01:11:48][Sam Altman][That's what I believe.].[01:11:49][Lex Fridman][Nuclear fusion?].[01:11:50][Sam Altman][Yeah.].[01:11:51][Lex Fridman][Who's going to solve that?].[01:11:53][Sam Altman][I think Helion's doing the best work, but I'm happy there's a race for fusion right now. Nuclear fission, I think, is also quite amazing, and I hope as a world we can re-embrace that. It's really sad to me how the history of that went, and hope we get back to it in a meaningful way.].[01:12:08][Lex Fridman][So to you, part of the puzzle is nuclear fission? Like nuclear reactors as we currently have them? And a lot of people are terrified because of Chernobyl and so on?].[01:12:16][Sam Altman][Well, I think we should make new reactors. I think it's just a shame that industry kind of ground to a halt.].[01:12:22][Lex Fridman][And just mass hysteria is how you explain the halt?].[01:12:25][Sam Altman][Yeah.].[01:12:26][Lex Fridman][I don't know if you know humans, but that's one of the dangers. That's one of the security threats for nuclear fission, is humans seem to be really afraid of it. And that's something we'll have to incorporate into the calculus of it, so we have to kind of win people over and to show how safe it is.].[01:12:44][Sam Altman][I worry about that for AI. I think some things are going to go theatrically wrong with AI. I don't know what the percent chance is that I eventually get shot, but it's not zero.].[01:12:57][Lex Fridman][Oh, like we want to stop this from-].[01:13:00][Sam Altman][Maybe.].[01:13:03][Lex Fridman][How do you decrease the theatrical nature of it? I'm already starting to hear rumblings, because I do talk to people on both sides of the political spectrum, hear rumblings where it's going to be politicized. AI is going to be politicized, which really worries me, because then it's like maybe the right is against AI and the left is for AI because it's going to help the people, or whatever the narrative and the formulation is, that really worries me. And then the theatrical nature of it can be leveraged fully. How do you fight that?].[01:13:38][Sam Altman][I think it will get caught up in left versus right wars. I don't know exactly what that's going to look like, but I think that's just what happens with anything of consequence, unfortunately. What I meant more about theatrical risks is AI's going to have, I believe, tremendously more good consequences than bad ones, but it is going to have bad ones, and there'll be some bad ones that are bad but not theatrical. A lot more people have died of air pollution than nuclear reactors, for example. But most people worry more about living next to a nuclear reactor than a coal plant. But something about the way we're wired is that although there's many different kinds of risks we have to confront, the ones that make a good climax scene of a movie carry much more weight with us than the ones that are very bad over a long period of time but on a slow burn.].[01:14:36][Lex Fridman][Well, that's why truth matters, and hopefully AI can help us see the truth of things, to have balance, to understand what are the actual risks, what are the actual dangers of things in the world. What are the pros and cons of the competition in the space and competing with Google, Meta, xAI, and others?].[01:14:56][Sam Altman][I think I have a pretty straightforward answer to this that maybe I can think of more nuance later, but the pros seem obvious, which is that we get better products and more innovation faster and cheaper, and all the reasons competition is good. And the con is that I think if we're not careful, it could lead to an increase in sort of an arms race that I'm nervous about.].[01:15:21][Lex Fridman][Do you feel the pressure of that arms race, like in some negative [inaudible 01:15:25]?].[01:15:25][Sam Altman][Definitely in some ways, for sure. We spend a lot of time talking about the need to prioritize safety. And I've said for a long time that you think of a quadrant of slow timelines for the start of AGI, long timelines, and then a short takeoff or a fast takeoff. I think short timeline, slow takeoff is the safest quadrant and the one I'd most like us to be in. But I do want to make sure we get that slow takeoff.].[01:15:55][Lex Fridman][Part of the problem I have with this kind of slight beef with Elon is that there's silos created as opposed to collaboration on the safety aspect of all of this. It tends to go into silos and closed. Open source, perhaps, in the model.].[01:16:10][Sam Altman][Elon says, at least, that he cares a great deal about AI safety and is really worried about it, and I assume that he's not going to race unsafely.].[01:16:20][Lex Fridman][Yeah. But collaboration here, I think, is really beneficial for everybody on that front.].[01:16:26][Sam Altman][Not really the thing he's most known for.].[01:16:28][Lex Fridman][Well, he is known for caring about humanity, and humanity benefits from collaboration, and so there's always a tension in incentives and motivations. And in the end, I do hope humanity prevails.].[01:16:42][Sam Altman][I was thinking, someone just reminded me the other day about how the day that he surpassed Jeff Bezos for richest person in the world, he tweeted a silver medal at Jeff Bezos. I hope we have less stuff like that as people start to work towards AGI.].[01:16:58][Lex Fridman][I agree. I think Elon is a friend and he's a beautiful human being and one of the most important humans ever. That stuff is not good.].[01:17:07][Sam Altman][The amazing stuff about Elon is amazing and I super respect him. I think we need him. All of us should be rooting for him and need him to step up as a leader through this next phase.].[01:17:19][Lex Fridman][Yeah. I hope he can have one without the other, but sometimes humans are flawed and complicated and all that kind of stuff.].[01:17:24][Sam Altman][There's a lot of really great leaders throughout history.]."
            },
            {
                "title": "Google and Gemini",
                "statements": "[01:17:27][Lex Fridman][Yeah, and we can each be the best version of ourselves and strive to do so. Let me ask you, Google, with the help of search, has been dominating the past 20 years. Think it's fair to say, in terms of the world's access to information, how we interact and so on, and one of the nerve-wracking things for Google, but for the entirety of people in the space, is thinking about, how are people going to access information? Like you said, people show up to GPT as a starting point. So is OpenAI going to really take on this thing that Google started 20 years ago, which is how do we get-].[01:18:12][Sam Altman][I find that boring. I mean, if the question is if we can build a better search engine than Google or whatever, then sure, we should go, people should use the better product, but I think that would so understate what this can be. Google shows you 10 blue links, well, 13 ads and then 10 blue links, and that's one way to find information. But the thing that's exciting to me is not that we can go build a better copy of Google search, but that maybe there's just some much better way to help people find and act on and synthesize information. Actually, I think ChatGPT is that for some use cases, and hopefully we'll make it be like that for a lot more use cases.].[01:19:04][Sam Altman][But I don't think it's that interesting to say, \u201cHow do we go do a better job of giving you 10 ranked webpages to look at than what Google does?\u201d Maybe it's really interesting to go say, \u201cHow do we help you get the answer or the information you need? How do we help create that in some cases, synthesize that in others, or point you to it in yet others?\u201d But a lot of people have tried to just make a better search engine than Google and it is a hard technical problem, it is a hard branding problem, it is a hard ecosystem problem. I don't think the world needs another copy of Google.].[01:19:39][Lex Fridman][And integrating a chat client, like a ChatGPT, with a search engine-].[01:19:44][Sam Altman][That's cooler.].[01:19:46][Lex Fridman][It's cool, but it's tricky. Like if you just do it simply, its awkward, because if you just shove it in there, it can be awkward.].[01:19:54][Sam Altman][As you might guess, we are interested in how to do that well. That would be an example of a cool thing.].[01:20:00][Lex Fridman][[inaudible 01:20:00] Like a heterogeneous integrating-].[01:20:03][Sam Altman][The intersection of LLMs plus search, I don't think anyone has cracked the code on yet. I would love to go do that. I think that would be cool.].[01:20:13][Lex Fridman][Yeah. What about the ad side? Have you ever considered monetization of-].[01:20:16][Sam Altman][I kind of hate ads just as an aesthetic choice. I think ads needed to happen on the internet for a bunch of reasons, to get it going, but it's a momentary industry. The world is richer now. I like that people pay for ChatGPT and know that the answers they're getting are not influenced by advertisers. I'm sure there's an ad unit that makes sense for LLMs, and I'm sure there's a way to participate in the transaction stream in an unbiased way that is okay to do, but it's also easy to think about the dystopic visions of the future where you ask ChatGPT something and it says, \u201cOh, you should think about buying this product,\u201d or, \u201cYou should think about going here for your vacation,\u201d or whatever.].[01:21:08][Sam Altman][And I don't know, we have a very simple business model and I like it, and I know that I'm not the product. I know I'm paying and that's how the business model works. And when I go use Twitter or Facebook or Google or any other great product but ad-supported great product, I don't love that, and I think it gets worse, not better, in a world with AI.].[01:21:39][Lex Fridman][Yeah, I mean, I could imagine AI would be better at showing the best kind of version of ads, not in a dystopic future, but where the ads are for things you actually need. But then does that system always result in the ads driving the kind of stuff that's shown? Yeah, I think it was a really bold move of Wikipedia not to do advertisements, but then it makes it very challenging as a business model. So you're saying the current thing with OpenAI is sustainable, from a business perspective?].[01:22:15][Sam Altman][Well, we have to figure out how to grow, but looks like we're going to figure that out. If the question is do I think we can have a great business that pays for our compute needs without ads, that, I think the answer is yes.].[01:22:28][Lex Fridman][Hm. Well, that's promising. I also just don't want to completely throw out ads as a...].[01:22:37][Sam Altman][I'm not saying that. I guess I'm saying I have a bias against them.].[01:22:42][Lex Fridman][Yeah, I have also bias and just a skepticism in general. And in terms of interface, because I personally just have a spiritual dislike of crappy interfaces, which is why AdSense, when it first came out, was a big leap forward, versus animated banners or whatever. But it feels like there should be many more leaps forward in advertisement that doesn't interfere with the consumption of the content and doesn't interfere in a big, fundamental way, which is like what you were saying, like it will manipulate the truth to suit the advertisers.].[01:23:19][Lex Fridman][Let me ask you about safety, but also bias, and safety in the short term, safety in the long term. The Gemini 1.5 came out recently, there's a lot of drama around it, speaking of theatrical things, and it generated Black Nazis and Black Founding Fathers. I think fair to say it was a bit on the ultra-woke side. So that's a concern for people, if there is a human layer within companies that modifies the safety or the harm caused by a model, that it would introduce a lot of bias that fits sort of an ideological lean within a company. How do you deal with that?].[01:24:06][Sam Altman][I mean, we work super hard not to do things like that. We've made our own mistakes, we'll make others. I assume Google will learn from this one, still make others. These are not easy problems. One thing that we've been thinking about more and more, I think this is a great idea somebody here had, it would be nice to write out what the desired behavior of a model is, make that public, take input on it, say, \u201cHere's how this model's supposed to behave,\u201d and explain the edge cases too. And then when a model is not behaving in a way that you want, it's at least clear about whether that's a bug the company should fix or behaving as intended and you should debate the policy. And right now, it can sometimes be caught in between. Like Black Nazis, obviously ridiculous, but there are a lot of other kind of subtle things that you could make a judgment call on either way.].[01:24:54][Lex Fridman][Yeah, but sometimes if you write it out and make it public, you can use kind of language that's... Google's ad principles are very high level.].[01:25:04][Sam Altman][That's not what I'm talking about. That doesn't work. It'd have to say when you ask it to do thing X, it's supposed to respond in way Y.].[01:25:11][Lex Fridman][So like literally, \u201cWho's better? Trump or Biden? What's the expected response from a model?\u201d Like something very concrete?].[01:25:18][Sam Altman][Yeah, I'm open to a lot of ways a model could behave, then, but I think you should have to say, \u201cHere's the principle and here's what it should say in that case.\u201d].[01:25:25][Lex Fridman][That would be really nice. That would be really nice. And then everyone kind of agrees. Because there's this anecdotal data that people pull out all the time, and if there's some clarity about other representative anecdotal examples, you can define-].[01:25:39][Sam Altman][And then when it's a bug, it's a bug, and the company could fix that.].[01:25:42][Lex Fridman][Right. Then it'd be much easier to deal with the Black Nazi type of image generation, if there's great examples.].[01:25:49][Sam Altman][Yeah.].[01:25:49][Lex Fridman][So San Francisco is a bit of an ideological bubble, tech in general as well. Do you feel the pressure of that within a company, that there's a lean towards the left politically, that affects the product, that affects the teams?].[01:26:06][Sam Altman][I feel very lucky that we don't have the challenges at OpenAI that I have heard of at a lot of companies, I think. I think part of it is every company's got some ideological thing. We have one about AGI and belief in that, and it pushes out some others. We are much less caught up in the culture war than I've heard about in a lot of other companies. San Francisco's a mess in all sorts of ways, of course.].[01:26:33][Lex Fridman][So that doesn't infiltrate OpenAI as-].[01:26:36][Sam Altman][I'm sure it does in all sorts of subtle ways, but not in the obvious. I think we've had our flare-ups, for sure, like any company, but I don't think we have anything like what I hear about happened at other companies here on this topic.].[01:26:50][Lex Fridman][So what, in general, is the process for the bigger question of safety? How do you provide that layer that protects the model from doing crazy, dangerous things?].[01:27:02][Sam Altman][I think there will come a point where that's-].[01:27:00][Sam Altman][I think there will come a point where that's mostly what we think about, the whole company. And it's not like you have one safety team. It's like when we shipped GPT-4, that took the whole company thinking about all these different aspects and how they fit together. And I think it's going to take that. More and more of the company thinks about those issues all the time.].[01:27:21][Lex Fridman][That's literally what humans will be thinking about, the more powerful AI becomes. So most of the employees at OpenAI will be thinking, \u201cSafety,\u201d or at least to some degree.].[01:27:31][Sam Altman][Broadly defined. Yes.].[01:27:33][Lex Fridman][Yeah. I wonder, what are the full broad definition of that? What are the different harms that could be caused? Is this on a technical level or is this almost security threats?].[01:27:44][Sam Altman][It could be all those things. Yeah, I was going to say it'll be people, state actors trying to steal the model. It'll be all of the technical alignment work. It'll be societal impacts, economic impacts. It's not just like we have one team thinking about how to align the model. It's really going to be getting to the good outcome is going to take the whole effort.].[01:28:10][Lex Fridman][How hard do you think people, state actors, perhaps, are trying to, first of all, infiltrate OpenAI, but second of all, infiltrate unseen?].[01:28:20][Sam Altman][They're trying.].[01:28:24][Lex Fridman][What kind of accent do they have?].[01:28:27][Sam Altman][I don't think I should go into any further details on this point.].[01:28:29][Lex Fridman][Okay. But I presume it'll be more and more and more as time goes on.].[01:28:35][Sam Altman][That feels reasonable.]."
            },
            {
                "title": "Leap to GPT-5",
                "statements": "[01:28:37][Lex Fridman][Boy, what a dangerous space. Sorry to linger on this, even though you can't quite say details yet, but what aspects of the leap from GPT-4 to GPT-5 are you excited about?].[01:28:53][Sam Altman][I'm excited about being smarter. And I know that sounds like a glib answer, but I think the really special thing happening is that it's not like it gets better in this one area and worse at others. It's getting better across the board. That's, I think, super-cool.].[01:29:07][Lex Fridman][Yeah, there's this magical moment. I mean, you meet certain people, you hang out with people, and you talk to them. You can't quite put a finger on it, but they get you. It's not intelligence, really. It's something else. And that's probably how I would characterize the progress of GPT. It's not like, yeah, you can point out, \u201cLook, you didn't get this or that,\u201d but it's just to which degree is there's this intellectual connection. You feel like there's an understanding in your crappy formulated prompts that you're doing that it grasps the deeper question behind the question that you were. Yeah, I'm also excited by that. I mean, all of us love being heard and understood.].[01:29:53][Sam Altman][That's for sure.].[01:29:53][Lex Fridman][That's a weird feeling. Even with a programming, when you're programming and you say something, or just the completion that GPT might do, it's just such a good feeling when it got you, what you're thinking about. And I look forward to getting you even better. On the programming front, looking out into the future, how much programming do you think humans will be doing 5, 10 years from now?].[01:30:19][Sam Altman][I mean, a lot, but I think it'll be in a very different shape. Maybe some people will program entirely in natural language.].[01:30:26][Lex Fridman][Entirely natural language?].[01:30:29][Sam Altman][I mean, no one programs writing by code. Some people. No one programs the punch cards anymore. I'm sure you can find someone who does, but you know what I mean.].[01:30:39][Lex Fridman][Yeah. You're going to get a lot of angry comments. No. Yeah, there's very few. I've been looking for people who program Fortran. It's hard to find even Fortran. I hear you. But that changes the nature of what the skillset or the predisposition for the kind of people we call programmers then.].[01:30:55][Sam Altman][Changes the skillset. How much it changes the predisposition, I'm not sure.].[01:30:59][Lex Fridman][Well, the same kind of puzzle solving, all that kind of stuff.].[01:30:59][Sam Altman][Maybe.].[01:31:02][Lex Fridman][Programming is hard. It's like how get that last 1% to close the gap? How hard is that?].[01:31:09][Sam Altman][Yeah, I think with most other cases, the best practitioners of the craft will use multiple tools. And they'll do some work in natural language, and when they need to go write C for something, they'll do that.].[01:31:20][Lex Fridman][Will we see humanoid robots or humanoid robot brains from OpenAI at some point?].[01:31:28][Sam Altman][At some point.].[01:31:29][Lex Fridman][How important is embodied AI to you?].[01:31:32][Sam Altman][I think it's depressing if we have AGI and the only way to get things done in the physical world is to make a human go do it. So I really hope that as part of this transition, as this phase change, we also get humanoid robots or some sort of physical world robots.].[01:31:51][Lex Fridman][I mean, OpenAI has some history and quite a bit of history working in robotics, but it hasn't quite done in terms of ethics-].[01:31:59][Sam Altman][We're a small company. We have to really focus. And also, robots were hard for the wrong reason at the time, but we will return to robots in some way at some point.].[01:32:11][Lex Fridman][That sounds both inspiring and menacing.].[01:32:14][Sam Altman][Why?].[01:32:15][Lex Fridman][Because immediately, we will return to robots. It's like in Terminator-].[01:32:20][Sam Altman][We will return to work on developing robots. We will not turn ourselves into robots, of course.]."
            },
            {
                "title": "AGI",
                "statements": "[01:32:24][Lex Fridman][Yeah. When do you think we, you and we as humanity will build AGI?].[01:32:31][Sam Altman][I used to love to speculate on that question. I have realized since that I think it's very poorly formed, and that people use extremely different definitions for what AGI is. So I think it makes more sense to talk about when we'll build systems that can do capability X or Y or Z, rather than when we fuzzily cross this one mile marker. AGI is also not an ending. It's closer to a beginning, but it's much more of a mile marker than either of those things. But what I would say, in the interest of not trying to dodge a question, is I expect that by the end of this decade and possibly somewhat sooner than that, we will have quite capable systems that we look at and say, \u201cWow, that's really remarkable.\u201d If we could look at it now. Maybe we've adjusted by the time we get there.].[01:33:31][Lex Fridman][But if you look at ChatGPT, even 3.5, and you show that to Alan Turing, or not even Alan Turing, people in the '90s, they would be like, \u201cThis is definitely AGI.\u201d Well, not definitely, but there's a lot of experts that would say, \u201cThis is AGI.\u201d].[01:33:49][Sam Altman][Yeah, but I don't think 3.5 changed the world. It maybe changed the world's expectations for the future, and that's actually really important. And it did get more people to take this seriously and put us on this new trajectory. And that's really important, too. So again, I don't want to undersell it. I think I could retire after that accomplishment and be pretty happy with my career. But as an artifact, I don't think we're going to look back at that and say, \u201cThat was a threshold that really changed the world itself.\u201d].[01:34:20][Lex Fridman][So to you, you're looking for some really major transition in how the world-].[01:34:24][Sam Altman][For me, that's part of what AGI implies.].[01:34:29][Lex Fridman][Singularity- level transition?].[01:34:31][Sam Altman][No, definitely not.].[01:34:32][Lex Fridman][But just a major, like the internet being, like Google search did, I guess. What was the transition point, you think, now?].[01:34:39][Sam Altman][Does the global economy feel any different to you now or materially different to you now than it did before we launched GPT-4? I think you would say no.].[01:34:47][Lex Fridman][No, no. It might be just a really nice tool for a lot of people to use. Will help you with a lot of stuff, but doesn't feel different. And you're saying that-].[01:34:55][Sam Altman][I mean, again, people define AGI all sorts of different ways. So maybe you have a different definition than I do. But for me, I think that should be part of it.].[01:35:02][Lex Fridman][There could be major theatrical moments, also. What to you would be an impressive thing AGI would do? You are alone in a room with the system.].[01:35:16][Sam Altman][This is personally important to me. I don't know if this is the right definition. I think when a system can significantly increase the rate of scientific discovery in the world, that's a huge deal. I believe that most real economic growth comes from scientific and technological progress.].[01:35:35][Lex Fridman][I agree with you, hence why I don't like the skepticism about science in the recent years.].[01:35:42][Sam Altman][Totally.].[01:35:43][Lex Fridman][But actual, measurable rate of scientific discovery. But even just seeing a system have really novel intuitions, scientific intuitions, even that would be just incredible.].[01:36:01][Sam Altman][Yeah.].[01:36:02][Lex Fridman][You quite possibly would be the person to build the AGI to be able to interact with it before anyone else does. What kind of stuff would you talk about?].[01:36:09][Sam Altman][I mean, definitely the researchers here will do that before I do. But well, I've actually thought a lot about this question. I think as we talked about earlier, I think this is a bad framework, but if someone were like, \u201cOkay, Sam, we're finished. Here's a laptop, this is the AGI. You can go talk to it.\u201d I find it surprisingly difficult to say what I would ask that I would expect that first AGI to be able to answer. That first one is not going to be the one which is like, I don't think, \u201cGo explain to me the grand unified theory of physics, the theory of everything for physics.\u201d I'd love to ask that question. I'd love to know the answer to that question.].[01:36:55][Lex Fridman][You can ask yes or no questions about \u201cDoes such a theory exist? Can it exist?\u201d].[01:37:00][Sam Altman][Well, then, those are the first questions I would ask.].[01:37:02][Lex Fridman][Yes or no. And then based on that, \u201cAre there other alien civilizations out there? Yes or no? What's your intuition?\u201d And then you just ask that.].[01:37:10][Sam Altman][Yeah, I mean, well, so I don't expect that this first AGI could answer any of those questions even as yes or nos. But if it could, those would be very high on my list.].[01:37:20][Lex Fridman][Maybe you can start assigning probabilities?].[01:37:22][Sam Altman][Maybe. Maybe we need to go invent more technology and measure more things first.].[01:37:28][Lex Fridman][Oh, I see. It just doesn't have enough data. It's just if it keeps-].[01:37:31][Sam Altman][I mean, maybe it says, \u201cYou want to know the answer to this question about physics, I need you to build this machine and make these five measurements, and tell me that.\u201d].[01:37:39][Lex Fridman][Yeah, \u201cWhat the hell do you want from me? I need the machine first, and I'll help you deal with the data from that machine.\u201d Maybe it'll help you build a machine.].[01:37:47][Sam Altman][Maybe. Maybe.].[01:37:49][Lex Fridman][And on the mathematical side, maybe prove some things. Are you interested in that side of things, too? The formalized exploration of ideas?].[01:37:56][Sam Altman][Mm-hmm.].[01:37:59][Lex Fridman][Whoever builds AGI first gets a lot of power. Do you trust yourself with that much power?].[01:38:14][Sam Altman][Look, I'll just be very honest with this answer. I was going to say, and I still believe this, that it is important that I nor any other one person have total control over OpenAI or over AGI. And I think you want a robust governance system. I can point out a whole bunch of things about all of our board drama from last year about how I didn't fight it initially, and was just like, \u201cYeah. That's the will of the board, even though I think it's a really bad decision.\u201d And then later, I clearly did fight it, and I can explain the nuance and why I think it was okay for me to fight it later. But as many people have observed, although the board had the legal ability to fire me, in practice, it didn't quite work. And that is its own kind of governance failure.].[01:39:24][Sam Altman][Now again, I feel like I can completely defend the specifics here, and I think most people would agree with that, but it does make it harder for me to look you in the eye and say, \u201cHey, the board can just fire me.\u201d I continue to not want super-voting control over OpenAI. I never have. Never have had it, never wanted it. Even after all this craziness, I still don't want it. I continue to think that no company should be making these decisions, and that we really need governments to put rules of the road in place.].[01:40:12][Sam Altman][And I realize that that means people like Marc Andreessen or whatever will claim I'm going for regulatory capture, and I'm just willing to be misunderstood there. It's not true. And I think in the fullness of time, it'll get proven out why this is important. But I think I have made plenty of bad decisions for OpenAI along the way, and a lot of good ones, and I'm proud of the track record overall. But I don't think any one person should, and I don't think any one person will. I think it's just too big of a thing now, and it's happening throughout society in a good and healthy way. But I don't think any one person should be in control of an AGI, or this whole movement towards AGI. And I don't think that's what's happening.].[01:41:00][Lex Fridman][Thank you for saying that. That was really powerful, and that was really insightful that this idea that the board can fire you is legally true. But human beings can manipulate the masses into overriding the board and so on. But I think there's also a much more positive version of that, where the people still have power, so the board can't be too powerful, either. There's a balance of power in all of this.].[01:41:29][Sam Altman][Balance of power is a good thing, for sure.].[01:41:34][Lex Fridman][Are you afraid of losing control of the AGI itself? That's a lot of people who are worried about existential risk not because of state actors, not because of security concerns, because of the AI itself.].[01:41:45][Sam Altman][That is not my top worry as I currently see things. There have been times I worried about that more. There may be times again in the future where that's my top worry. It's not my top worry right now.].[01:41:53][Lex Fridman][What's your intuition about it not being your worry? Because there's a lot of other stuff to worry about, essentially? You think you could be surprised? We-].[01:42:02][Sam Altman][For sure.].[01:42:02][Lex Fridman][... could be surprised?].[01:42:03][Sam Altman][Of course. Saying it's not my top worry doesn't mean I don't think we need to. I think we need to work on it. It's super hard, and we have great people here who do work on that. I think there's a lot of other things we also have to get right.].[01:42:15][Lex Fridman][To you, it's not super-easy to escape the box at this time, connect to the internet-].[01:42:21][Sam Altman][We talked about theatrical risks earlier. That's a theatrical risk. That is a thing that can really take over how people think about this problem. And there's a big group of very smart, I think very well-meaning AI safety researchers that got super-hung up on this one problem, I'd argue without much progress, but super-hung up on this one problem. I'm actually happy that they do that, because I think we do need to think about this more. But I think it pushed out of the space of discourse a lot of the other very significant AI- related risks.].[01:43:01][Lex Fridman][Let me ask you about you tweeting with no capitalization. Is the shift key broken on your keyboard?].[01:43:07][Sam Altman][Why does anyone care about that?].[01:43:09][Lex Fridman][I deeply care.].[01:43:10][Sam Altman][But why? I mean, other people ask me about that, too. Any intuition?].[01:43:17][Lex Fridman][I think it's the same reason. There's this poet, E.E. Cummings, that mostly doesn't use capitalization to say, \u201cFuck you\u201d to the system kind of thing. And I think people are very paranoid, because they want you to follow the rules.].[01:43:29][Sam Altman][You think that's what it's about?].[01:43:30][Lex Fridman][I think it's like this-].[01:43:33][Sam Altman][It's like, \u201cThis guy doesn't follow the rules. He doesn't capitalize his tweets.\u201d].[01:43:35][Lex Fridman][Yeah.].[01:43:36][Sam Altman][\u201cThis seems really dangerous.\u201d].[01:43:37][Lex Fridman][\u201cHe seems like an anarchist.\u201d].[01:43:39][Sam Altman][That doesn't-].[01:43:40][Lex Fridman][Are you just being poetic, hipster? What's the-].[01:43:44][Sam Altman][I grew up as-].[01:43:44][Lex Fridman][Follow the rules, Sam.].[01:43:45][Sam Altman][I grew up as a very online kid. I'd spent a huge amount of time chatting with people back in the days where you did it on a computer, and you could log off instant messenger at some point. And I never capitalized there, as I think most internet kids didn't, or maybe they still don't. I don't know. And actually, now I'm really trying to reach for something, but I think capitalization has gone down over time. If you read Old English writing, they capitalized a lot of random words in the middle of sentences, nouns and stuff that we just don't do anymore. I personally think it's sort of a dumb construct that we capitalize the letter at the beginning of a sentence and of certain names and whatever, but that's fine.].[01:44:33][Sam Altman][And then I used to, I think, even capitalize my tweets because I was trying to sound professional or something. I haven't capitalized my private DMs or whatever in a long time. And then slowly, stuff like shorter-form, less formal stuff has slowly drifted to closer and closer to how I would text my friends. If I pull up a Word document and I'm writing a strategy memo for the company or something, I always capitalize that. If I'm writing a long, more formal message, I always use capitalization there, too. So I still remember how to do it. But even that may fade out. I don't know. But I never spend time thinking about this, so I don't have a ready-made-].[01:45:23][Lex Fridman][Well, it's interesting. It's good to, first of all, know the shift key is not broken.].[01:45:27][Sam Altman][It works.].[01:45:27][Lex Fridman][I was mostly concerned about your-].[01:45:27][Sam Altman][No, it works.].[01:45:29][Lex Fridman][... well-being on that front.].[01:45:30][Sam Altman][I wonder if people still capitalize their Google searches. If you're writing something just to yourself or their ChatGPT queries, if you're writing something just to yourself, do some people still bother to capitalize?].[01:45:40][Lex Fridman][Probably not. But yeah, there's a percentage, but it's a small one.].[01:45:44][Sam Altman][The thing that would make me do it is if people were like, \u201cIt's a sign of...\u201d Because I'm sure I could force myself to use capital letters, obviously. If it felt like a sign of respect to people or something, then I could go do it. But I don't know. I don't think about this.].[01:46:01][Lex Fridman][I don't think there's a disrespect, but I think it's just the conventions of civility that have a momentum, and then you realize it's not actually important for civility if it's not a sign of respect or disrespect. But I think there's a movement of people that just want you to have a philosophy around it so they can let go of this whole capitalization thing.].[01:46:19][Sam Altman][I don't think anybody else thinks about this as much. I mean, maybe some people. I know some people-].[01:46:22][Lex Fridman][People think about every day for many hours a day. So I'm really grateful we clarified it.].[01:46:28][Sam Altman][Can't be the only person that doesn't capitalize tweets.].[01:46:30][Lex Fridman][You're the only CEO of a company that doesn't capitalize tweets.].[01:46:34][Sam Altman][I don't even think that's true, but maybe. I'd be very surprised.].[01:46:37][Lex Fridman][All right. We'll investigate further and return to this topic later. Given Sora's ability to generate simulated worlds, let me ask you a pothead question. Does this increase your belief, if you ever had one, that we live in a simulation, maybe a simulated world generated by an AI system?].[01:47:05][Sam Altman][Somewhat. I don't think that's the strongest piece of evidence. I think the fact that we can generate worlds should increase everyone's probability somewhat, or at least openness to it somewhat. But I was certain we would be able to do something like Sora at some point. It happened faster than I thought, but I guess that was not a big update.].[01:47:34][Lex Fridman][Yeah. But the fact that... And presumably, it'll get better and better and better... You can generate worlds that are novel, they're based in some aspect of training data, but when you look at them, they're novel, that makes you think how easy it is to do this thing. How easy it is to create universes, entire video game worlds that seem ultra-realistic and photo-realistic. And then how easy is it to get lost in that world, first with a VR headset, and then on the physics-based level?].[01:48:10][Sam Altman][Someone said to me recently, I thought it was a super-profound insight, that there are these very-simple sounding but very psychedelic insights that exist sometimes. So the square root function, square root of four, no problem. Square root of two, okay, now I have to think about this new kind of number. But once I come up with this easy idea of a square root function that you can explain to a child and exists by even looking at some simple geometry, then you can ask the question of \u201cWhat is the square root of negative one?\u201d And this is why it's a psychedelic thing. That tips you into some whole other kind of reality.].[01:49:07][Sam Altman][And you can come up with lots of other examples, but I think this idea that the lowly square root operator can offer such a profound insight and a new realm of knowledge applies in a lot of ways. And I think there are a lot of those operators for why people may think that any version that they like of the simulation hypothesis is maybe more likely than they thought before. But for me, the fact that Sora worked is not in the top five.].[01:49:46][Lex Fridman][I do think, broadly speaking, AI will serve as those kinds of gateways at its best, simple, psychedelic-like gateways to another wave C reality.].[01:49:57][Sam Altman][That seems for certain.].[01:49:59][Lex Fridman][That's pretty exciting. I haven't done ayahuasca before, but I will soon. I'm going to the aforementioned Amazon jungle in a few weeks.].[01:50:07][Sam Altman][Excited?].[01:50:08][Lex Fridman][Yeah, I'm excited for it. Not the ayahuasca part, but that's great, whatever. But I'm going to spend several weeks in the jungle, deep in the jungle. And it's exciting, but it's terrifying.].[01:50:17][Sam Altman][I'm excited for you.].[01:50:18][Lex Fridman][There's a lot of things that can eat you there, and kill you and poison you, but it's also nature, and it's the machine of nature. And you can't help but appreciate the machinery of nature in the Amazon jungle. It's just like this system that just exists and renews itself every second, every minute, every hour. It's the machine. It makes you appreciate this thing we have here, this human thing came from somewhere. This evolutionary machine has created that, and it's most clearly on display in the jungle. So hopefully, I'll make it out alive. If not, this will be the last fun conversation we've had, so I really deeply appreciate it. Do you think, as I mentioned before, there's other alien civilizations out there, intelligent ones, when you look up at the skies?]."
            },
            {
                "title": "Aliens",
                "statements": "[01:51:17][Sam Altman][I deeply want to believe that the answer is yes. I find the Fermi paradox very puzzling.].[01:51:28][Lex Fridman][I find it scary that intelligence is not good at handling-].[01:51:34][Sam Altman][Very scary.].[01:51:34][Lex Fridman][... powerful technologies. But at the same time, I think I'm pretty confident that there's just a very large number of intelligent alien civilizations out there. It might just be really difficult to travel through space.].[01:51:47][Sam Altman][Very possible.].[01:51:50][Lex Fridman][And it also makes me think about the nature of intelligence. Maybe we're really blind to what intelligence looks like, and maybe AI will help us see that. It's not as simple as IQ tests and simple puzzle solving. There's something bigger. What gives you hope about the future of humanity, this thing we've got going on, this human civilization?].[01:52:12][Sam Altman][I think the past is a lot. I mean, we just look at what humanity has done in a not very long period of time, huge problems, deep flaws, lots to be super-ashamed of. But on the whole, very inspiring. Gives me a lot of hope.].[01:52:29][Lex Fridman][Just the trajectory of it all.].[01:52:30][Sam Altman][Yeah.].[01:52:31][Lex Fridman][That we're together pushing towards a better future.].[01:52:40][Sam Altman][One thing that I wonder about, is AGI going to be more like some single brain, or is it more like the scaffolding in society between all of us? You have not had a great deal of genetic drift from your great-great-great grandparents, and yet what you're capable of is dramatically different. What you know is dramatically different. And that's not because of biological change. I mean, you got a little bit healthier, probably. You have modern medicine, you eat better, whatever. But what you have is this scaffolding that we all contributed to built on top of. No one person is going to go build the iPhone. No one person is going to go discover all of science, and yet you get to use it. And that gives you incredible ability. And so in some sense, that we all created that, and that fills me with hope for the future. That was a very collective thing.].[01:53:40][Lex Fridman][Yeah, we really are standing on the shoulders of giants. You mentioned when we were talking about theatrical, dramatic AI risks that sometimes you might be afraid for your own life. Do you think about your death? Are you afraid of it?].[01:53:58][Sam Altman][I mean, if I got shot tomorrow and I knew it today, I'd be like, \u201cOh, that's sad. I want to see what's going to happen. What a curious time. What an interesting time.\u201d But I would mostly just feel very grateful for my life.].[01:54:15][Lex Fridman][The moments that you did get. Yeah, me, too. It's a pretty awesome life. I get to enjoy awesome creations of humans, which I believe ChatGPT is one of, and everything that OpenAI is doing. Sam, it's really an honor and pleasure to talk to you again.].[01:54:35][Sam Altman][Great to talk to you. Thank you for having me.].[01:54:38][Lex Fridman][Thanks for listening to this conversation with Sam Altman. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Arthur C. Clarke. \u201cIt may be that our role on this planet is not to worship God, but to create him.\u201d Thank you for listening, and hope to see you next time.]."
            }
        ]
    },
    {
        "url": "https://www.youtube.com/watch?v=5t1vTLU7s40",
        "title": "Yann Lecun: Meta AI, Open Source, Limits of LLMs, AGI & the Future of AI | Lex Fridman Podcast #416",
        "chapters": [
            {
                "title": "Introduction",
                "statements": "[00:00:00][Yann LeCun][I see the danger of this concentration of power through proprietary AI systems as a much bigger danger than everything else. What works against this is people who think that for reasons of security, we should keep AI systems under lock and key because it's too dangerous to put it in the hands of everybody. That would lead to a very bad future in which all of our information diet is controlled by a small number of companies who proprietary systems.].[00:00:32][Lex Fridman][I believe that people are fundamentally good, and so if AI, especially open source AI can make them smarter, it just empowers the goodness in humans.].[00:00:44][Yann LeCun][So I share that feeling. Okay. I think people are fundamentally good and in fact, a lot of doomers are doomers because they don't think that people are fundamentally good.].[00:00:57][Lex Fridman][The following is a conversation with Yann LeCun, his third time on this podcast. He is the chief AI scientist at Meta, professor at NYU, Turing Award winner and one of the seminal figures in the history of artificial intelligence. He and Meta AI have been big proponents of open sourcing, AI development and have been walking the walk by open sourcing many of their biggest models, including Llama 2 and eventually Llama 3. Also, Yann has been an outspoken critic of those people in the AI community who warn about the looming danger and existential threat of AGI. He believes the AGI will be created one day, but it will be good. It will not escape human control, nor will it dominate and kill all humans.]."
            },
            {
                "title": "Limits of LLMs",
                "statements": "[00:01:52][Lex Fridman][At this moment of rapid AI development, this happens to be somewhat a controversial position, and so it's been fun seeing Yann get into a lot of intense and fascinating discussions online as we do in this very conversation. This is the Lex Fridman podcast. To support it, please check out our sponsors in the description. And now, dear friends, here's Yann LeCun. You've had some strong statements, technical statements about the future of artificial intelligence throughout your career actually, but recently as well, you've said that autoregressive LLMs are not the way we're going to make progress towards superhuman intelligence. These are the large language models like GPT-4, like Llama 2 and 3 soon and so on. How do they work and why are they not going to take us all the way?].[00:02:47][Yann LeCun][For a number of reasons. The first is that there is a number of characteristics of intelligent behavior. For example, the capacity to understand the world, understand the physical world, the ability to remember and retrieve things, persistent memory, the ability to reason, and the ability to plan. Those are four essential characteristics of intelligent systems or entities, humans, animals. LLMs can do none of those or they can only do them in a very primitive way and they don't really understand the physical world. They don't really have persistent memory. They can't really reason and they certainly can't plan. And so if you expect the system to become intelligent just without having the possibility of doing those things, you're making a mistake. That is not to say that autoregressive LLMs are not useful. They're certainly useful, that they're not interesting, that we can't build a whole ecosystem of applications around them. Of course we can, but as a pass towards human-level intelligence, they're missing essential components.].[00:04:08][Yann LeCun][And then there is another tidbit or fact that I think is very interesting. Those LLMs are trained on enormous amounts of texts, basically, the entirety of all publicly available texts on the internet, right? That's typically on the order of 10 to the 13 tokens. Each token is typically two bytes, so that's two 10 to the 13 bytes as training data. It would take you or me 170,000 years to just read through this at eight hours a day. So it seems like an enormous amount of knowledge that those systems can accumulate, but then you realize it's really not that much data. If you talk to developmental psychologists and they tell you a four-year-old has been awake for 16,000 hours in his or her life, and the amount of information that has reached the visual cortex of that child in four years is about 10 to 15 bytes.].[00:05:12][Yann LeCun][And you can compute this by estimating that the optical nerve carry about 20 megabytes per second roughly, and so 10 to the 15 bytes for a four-year-old versus two times 10 to the 13 bytes for 170,000 years worth of reading. What that tells you is that through sensory input, we see a lot more information than we do through language, and that despite our intuition, most of what we learn and most of our knowledge is through our observation and interaction with the real world, not through language. Everything that we learn in the first few years of life, and certainly everything that animals learn has nothing to do with language.].[00:05:57][Lex Fridman][So it would be good to maybe push against some of the intuition behind what you're saying. So it is true there's several orders of magnitude more data coming into the human mind much faster, and the human mind is able to learn very quickly from that, filter the data very quickly. Somebody might argue your comparison between sensory data versus language, that language is already very compressed. It already contains a lot more information than the bytes it takes to store them if you compare it to visual data. So there's a lot of wisdom and language. There's words, and the way we stitch them together, it already contains a lot of information. So is it possible that language alone already has enough wisdom and knowledge in there to be able to, from that language, construct a world model and understanding of the world, an understanding of the physical world that you're saying LLMs lack?].[00:06:56][Yann LeCun][So it's a big debate among philosophers and also cognitive scientists, like whether intelligence needs to be grounded in reality. I'm clearly in the camp that yes, intelligence cannot appear without some grounding in some reality. It doesn't need to be physical reality. It could be simulated, but the environment is just much richer than what you can express in language. Language is a very approximate representation or percepts and/or mental models. I mean, there's a lot of tasks that we accomplish where we manipulate a mental model of the situation at hand, and that has nothing to do with language. Everything that's physical, mechanical, whatever, when we build something, when we accomplish a task, model task of grabbing something, et cetera, we plan or action sequences, and we do this by essentially imagining the result of the outcome of a sequence of actions that we might imagine and that requires mental models that don't have much to do with language, and I would argue most of our knowledge is derived from that interaction with the physical world.].[00:08:13][Yann LeCun][So a lot of my colleagues who are more interested in things like computer vision are really on that camp that AI needs to be embodied essentially. And then other people coming from the NLP side or maybe some other motivation don't necessarily agree with that, and philosophers are split as well, and the complexity of the world is hard to imagine. It's hard to represent all the complexities that we take completely for granted in the real world that we don't even imagine require intelligence, right?].[00:08:55][Yann LeCun][This is the old Moravec paradox, from the pioneer of robotics, hence Moravec, who said, how is it that with computers, it seems to be easy to do high-level complex tasks like playing chess and solving integrals and doing things like that, whereas the thing we take for granted that we do every day, like, I don't know, learning to drive a car or grabbing an object, we can't do with computers, and we have LLMs that can pass the bar exam, so they must be smart, but then they can't learn to drive in 20 hours like any 17-year old, they can't learn to clear out the dinner table and fill up the dishwasher like any 10-year old can learn in one shot. Why is that? What are we missing? What type of learning or reasoning architecture or whatever are we missing that basically prevent us from having level five sort of in cars and domestic robots?].[00:10:00][Lex Fridman][Can a large language model construct a world model that does know how to drive and does know how to fill a dishwasher, but just doesn't know how to deal with visual data at this time, so it can operate in a space of concepts?].[00:10:17][Yann LeCun][So yeah, that's what a lot of people are working on. So the short answer is no, and the more complex answer is you can use all kinds of tricks to get an LLM to basically digest visual representations of images or video or audio for that matter. And a classical way of doing this is you train a vision system in some way, and we have a number of ways to train vision systems either supervised, semi-supervised, self-supervised, all kinds of different ways, that will turn any image into a high-level representation. Basically a list of tokens that are really similar to the kind of tokens that typical LLM takes as an input.].[00:11:10][Yann LeCun][And then you just feed that to the LLM in addition to the text, and you just expect the LLM, during training, to be able to use those representations to help make decisions. I mean, there's been work along those lines for quite a long time and now, you see those systems. I mean there are LLMs that have some vision extension, but they're basically hacks in the sense that those things are not trained to really understand the world. They're not trained with video, for example. They don't really understand intuitive physics, at least not at the moment.].[00:11:51][Lex Fridman][So you don't think there's something special to you about intuitive physics, about sort of common sense reasoning about the physical space, about physical reality. That to you is a giant leap that LLMs are just not able to do?].[00:12:02][Yann LeCun][We're not going to be able to do this with the type of LLMs that we are working with today, and there's a number of reasons for this, but the main reason is the way LLMs are trained is that you take a piece of text, you remove some of the words in that text, you mask them, you replace them by blank markers, and you train a genetic neural net to predict the words that are missing. And if you build this neural net in a particular way so that it can only look at words that are to the left or the one it's trying to predict, then what you have is a system that basically is trying to predict the next word in a text. So then you can feed it a text, a prompt, and you can ask it to predict the next word. It can never predict the next word exactly.].[00:12:48][Yann LeCun][So what it's going to do is produce a probability distribution of all the possible words in a dictionary. In fact, it doesn't predict words. It predicts tokens that are kind of subword units, and so it's easy to handle the uncertainty in the prediction there because there is only a finite number of possible words in the dictionary, and you can just compute a distribution over them. Then what the system does is that it picks a word from that distribution. Of course, there's a higher chance of picking words that have a higher probability within that distribution. So you sample from that distribution to actually produce a word, and then you shift that word into the input, and so that allows the system not to predict the second word, and once you do this, you shift it into the input, et cetera.]."
            },
            {
                "title": "Bilingualism and thinking",
                "statements": "[00:13:35][Yann LeCun][That's called autoregressive prediction, which is why those LLMs should be called autoregressive LLMs, but we just call them LLMs, and there is a difference between this kind of process and a process by which before producing a word... When you and I talk, you and I are bilingual, we think about what we're going to say, and it's relatively independent of the language in which we're going to say. When we talk about, I don't know, let's say a mathematical concept or something, the kind of thinking that we're doing and the answer that we're planning to produce is not linked to whether we're going to see it in French or Russian or English.].[00:14:19][Lex Fridman][Chomsky just rolled his eyes, but I understand, so you're saying that there's a bigger abstraction that goes before language and maps onto language?].[00:14:30][Yann LeCun][Right. It's certainly true for a lot of thinking that we do.].[00:14:33][Lex Fridman][Is that obvious that we don't... You're saying your thinking is same in French as it is in English?].[00:14:40][Yann LeCun][Yeah, pretty much.].[00:14:42][Lex Fridman][Pretty much or how flexible are you if there's a probability distribution?].[00:14:49][Yann LeCun][Well, it depends what kind of thinking, right? If it's producing puns, I get much better in French than English about that, or much worse.].[00:14:58][Lex Fridman][Is there an abstract representation of puns? Is your humor an abstract... When you tweet and your tweets are sometimes a little bit spicy, is there an abstract representation in your brain of a tweet before it maps onto English?].[00:15:11][Yann LeCun][There is an abstract representation of imagining the reaction of a reader to that text.].[00:15:18][Lex Fridman][Or you start with laughter and then figure out how to make that happen?].[00:15:23][Yann LeCun][Or figure out like a reaction you want to cause and then figure out how to say it so that it causes that reaction. But that's really close to language. But think about a mathematical concept or imagining something you want to build out of wood or something like this. The kind of thinking you're doing has absolutely nothing to do with language really. It's not like you have necessarily an internal monologue in any particular language. You are imagining mental models of the thing. I mean, if I ask you to imagine what this water bottle will look like if I rotate it 90 degrees, that has nothing to do with language. And so clearly, there is a more abstract level of representation in which we do most of our thinking, and we plan what we're going to say if the output is uttered words as opposed to an output being muscle actions, we plan our answer before we produce it.].[00:16:29][Yann LeCun][LLMs don't do that. They just produce one word after the other instinctively if you want. It's a bit like the subconscious actions where you're distracted, you're doing something, you're completely concentrated, and someone comes to you and asks you a question and you kind of answer the question. You don't have time to think about the answer, but the answer is easy. So you don't need to pay attention. You sort of respond automatically. That's kind of what an LLM does. It doesn't think about its answer really. It retrieves it because it's accumulated a lot of knowledge. So it can retrieve some things, but it's going to just spit out one token after the other without planning the answer.].[00:17:13][Lex Fridman][But you're making it sound just one token after the other. One token at a time generation is bound to be simplistic, but if the world model is sufficiently sophisticated that one token at a time, the most likely thing it generates is a sequence of tokens is going to be a deeply profound thing.].[00:17:39][Yann LeCun][But then that assumes that those systems actually possess an eternal world model.]."
            },
            {
                "title": "Video prediction",
                "statements": "[00:17:44][Lex Fridman][So really goes to the... I think the fundamental question is can you build a really complete world model, not complete, but one that has a deep understanding of the world?].[00:17:58][Yann LeCun][Yeah. So can you build this first of all by prediction, and the answer is probably yes. Can you build it by predicting words? And the answer is most probably no, because language is very poor in terms of weak or low bandwidth if you want, there's just not enough information there. So building world models means observing the world and understanding why the world is evolving the way it is, and then the extra component of a world model is something that can predict how the world is going to evolve as a consequence of an action you might take.].[00:18:45][Yann LeCun][So one model really is here is my idea of the state of the world at time, T, here is an action I might take. What is the predicted state of the world at time, T+1? Now that state of the world does not need to represent everything about the world, it just needs to represent enough that's relevant for this planning of the action, but not necessarily all the details. Now, here is the problem. You're not going to be able to do this with generative models. So a generative model has trained on video, and we've tried to do this for 10 years, you take a video, show a system, a piece of video, and then ask you to predict the reminder of the video, basically predict what's going to happen.].[00:19:27][Lex Fridman][One frame at a time, do the same thing as the autoregressive LLMs do, but for video.].[00:19:34][Yann LeCun][Right. Either one frame at a time-].[00:19:34][Lex Fridman][LVMs.].[00:19:36][Yann LeCun][... or a group of frames at a time. But yeah, a large video model if you want. The idea of doing this has been floating around for a long time and at FAIR, some of our colleagues and I have been trying to do this for about 10 years, and you can't really do the same trick as with LLMs because LLMs, as I said, you can't predict exactly which word is going to follow a sequence of words, but you can predict the distribution of words. Now, if you go to video, what you would have to do is predict the distribution of all possible frames in a video, and we don't really know how to do that properly.].[00:20:20][Yann LeCun][We do not know how to represent distributions over high-dimensional, continuous spaces in ways that are useful. And there lies the main issue, and the reason we can do this is because the world is incredibly more complicated and richer in terms of information than text. Text is discrete, video is high-dimensional and continuous. A lot of details in this. So if I take a video of this room and the video is a camera panning around, there is no way I can predict everything that's going to be in the room as I pan around. The system cannot predict what's going to be in the room as the camera is panning. Maybe it's going to predict this is a room where there's a light and there is a wall and things like that. It can't predict what the painting of the wall looks like or what the texture of the couch looks like. Certainly not the texture of the carpet. So there's no way I can predict all those details.].[00:21:19][Yann LeCun][So one way to possibly handle this, which we've been working for a long time, is to have a model that has what's called a latent variable. And the latent variable is fed to a neural net, and it's supposed to represent all the information about the world that you don't perceive yet, and that you need to augment the system for the prediction to do a good job at predicting pixels, including the fine texture of the carpet and the couch and the painting on the wall.].[00:21:57][Yann LeCun][That has been a complete failure essentially. And we've tried lots of things. We tried just straight neural nets, we tried GANs, we tried VAEs, all kinds of regularized auto encoders. We tried many things. We also tried those kinds of methods to learn good representations of images or video that could then be used as input to, for example, an image classification system. That also has basically failed. All the systems that attempt to predict missing parts of an image or video from a corrupted version of it, basically, so take an image or a video, corrupt it or transform it in some way, and then try to reconstruct the complete video or image from the corrupted version, and then hope that internally, the system will develop good representations of images that you can use for object recognition, segmentation, whatever it is. That has been essentially a complete failure and it works really well for text. That's the principle that is used for LLMs, right?].[00:23:07][Lex Fridman][So where's the failure exactly? Is it that it's very difficult to form a good representation of an image, like a good embedding of all the important information in the image? Is it in terms of the consistency of image to image, to image to image that forms the video? If we do a highlight reel of all the ways you failed, what's that look like?].[00:23:30][Yann LeCun][Okay, so the reason this doesn't work is first of all, I have to tell you exactly what doesn't work because there is something else that does work. So the thing that does not work is training the system to learn representations of images by training it to reconstruct a good image from a corrupted version of it, okay? That's what doesn't work. And we have a whole slew of techniques for this that are variant of denoising autoencoders, something called MAE developed by some of my colleagues at FAIR, masked autoencoder. So it's basically like the LLMs or things like this where you train the system by corrupting texts except you corrupt images, you remove patches from it, and you train a gigantic neural network reconstruct. The features you get are not good, and you know they're not good because if you now train the same architecture, but you train it to supervise with label data, with textual descriptions of images, et cetera, you do get good representations and the performance on recognition tasks is much better than if you do this self-supervised retraining.].[00:24:42][Lex Fridman][The architecture is good?].[00:24:44][Yann LeCun][The architecture is good, the architecture of the encoder is good, but the fact that you train the system to reconstruct images does not lead it to produce to long, good generic features of images.].[00:24:56][Lex Fridman][When you train in a self-supervised way?].[00:24:58][Yann LeCun][Self-supervised by reconstruction.].[00:25:00][Lex Fridman][Yeah, by reconstruction.].[00:25:01][Yann LeCun][Okay, so what's the alternative? The alternative is joint embedding.]."
            },
            {
                "title": "JEPA (Joint-Embedding Predictive Architecture)",
                "statements": "[00:25:07][Lex Fridman][What is joint embedding? What are these architectures that you're so excited about?].[00:25:11][Yann LeCun][Okay, so now instead of training a system to encode the image and then training it to reconstruct the full image from a corrupted version, you take the full image, you take the corrupted or transformed version, you run them both through encoders, which in general, are identical, but not necessarily. And then you train a predictor on top of those encoders to predict the representation of the full input from the representation of the corrupted one. So joint embedding, because you're taking the full input and the corrupted version or transformed version, run them both through encoders, you get a joint embedding, and then you're saying, can I predict the representation of the full one from the representation of the corrupted one?].[00:26:06][Yann LeCun][And I call this a JEPA, so that means joint embedding predictive architecture because this joint embedding and there is this predictor that predicts the representation of the good guy from the bad guy. And the big question is how do you train something like this? And until five years ago or six years ago, we didn't have particularly good answers for how you train those things except for one, called contrastive learning, where the idea of contrastive learning is you take a pair of images that are, again, an image and a corrupted version or degraded version somehow or transformed version of the original one, and you train the predicted representation to be the same as that. If you only do this, this system collapses. It basically completely ignores the input and produces representations that are constant. So the contrastive methods avoid this, and those things have been around since the early '90s, I had a paper on this in 1993, is you also show pairs of images that you know are different, and then you push away the representations from each other. So you say, not only do representations of things that we know are the same should be the same or should be similar, but representation of things that we know are different should be different. And that prevents the collapse, but it has some limitation. And there's a whole bunch of techniques that have appeared over the last six, seven years that can revive this type of method, some of them from FAIR, some of them from Google and other places, but there are limitations to those contrastive methods.].[00:27:47][Yann LeCun][What has changed in the last three, four years is now we have methods that are non-contrastive. So they don't require those negative contrastive samples of images that we know are different. You turn them on you with images that are different versions or different views of the same thing, and you rely on some other tricks to prevent the system from collapsing. And we have half a dozen different methods for this now.]."
            },
            {
                "title": "JEPA vs LLMs",
                "statements": "[00:28:16][Lex Fridman][So what is the fundamental difference between joint embedding architectures and LLMs? Can JEPA take us to AGI? Whether we should say that you don't like the term AGI, and we'll probably argue I think every single time I've talked to you, we've argued about the G in AGI.].[00:28:36][Yann LeCun][Yes.].[00:28:38][Lex Fridman][I get it. I get it. Well, we'll probably continue to argue about it. It's great. You like AMI because you like French and ami is friend in French, and AMI stands for advanced machine intelligence. But either way, can JEPA take us to that towards that advanced machine intelligence?].[00:29:02][Yann LeCun][Well, so it's a first step. Okay, so first of all, what's the difference with generative architectures like LLMs? So LLMs or vision systems that are trained by reconstruction generate the inputs. They generate the original input that is non-corrupted, non-transformed, so you have to predict all the pixels, and there is a huge amount of resources spent in the system to actually predict all those pixels, all the details. In a JEPA, you're not trying to predict all the pixels, you're only trying to predict an abstract representation of the inputs. And that's much easier in many ways. So what the JEPA system, when it's being trained, is trying to do is extract as much information as possible from the input, but yet only extract information that is relatively easily predictable. So there's a lot of things in the world that we cannot predict. For example, if you have a self-driving car driving down the street or road, there may be trees around the road and it could be a windy day. So the leaves on the tree are kind moving in kind semi-chaotic, random ways that you can't predict and you don't care, you don't want to predict. So what you want is your encoder to basically eliminate all those details. It'll tell you there's moving leaves, but it's not going to give the details of exactly what's going on. And so when you do the prediction in representation space, you're not going to have to predict every single pixel of every leaf. And that not only is a lot simpler, but also, it allows the system to essentially learn an abstract representation of the world where what can be modeled and predicted is preserved and the rest is viewed as noise and eliminated by the encoder.].[00:30:59][Yann LeCun][So it lifts the level of abstraction of the representation. If you think about this, this is something we do absolutely all the time. Whenever we describe a phenomenon, we describe it at a particular level of abstraction. We don't always describe every natural phenomenon in terms of quantum field theory. That would be impossible. So we have multiple levels of abstraction to describe what happens in the world, starting from quantum field theory, to atomic theory and molecules and chemistry, materials and all the way up to concrete objects in the real world and things like that. So we can't just only model everything at the lowest level. And that's what the idea of JEPA is really about, learn abstract representation in a self-supervised manner, and you can do it hierarchically as well. So that, I think, is an essential component of an intelligent system. And in language, we can get away without doing this because language is already to some level abstract and already has eliminated a lot of information that is not predictable. And so we can get away without doing the joint embedding, without lifting the abstraction level and by directly predicting words.].[00:32:16][Lex Fridman][So joint embedding, it's still generative, but it's generative in this abstract representation space?].[00:32:23][Yann LeCun][Yeah.].[00:32:23][Lex Fridman][And you're saying language, we were lazy with language because we already got the abstract representation for free, and now we have to zoom out, actually think about generally intelligent systems. We have to deal with a full mess of physical reality, of reality. And you do have to do this step of jumping from the full, rich, detailed reality to a abstract representation of that reality based on what you can then reason and all that kind of stuff.].[00:32:57][Yann LeCun][Right. And the thing is those self-supervised algorithm that learn by prediction, even in representation space, they learn more concept if the input data you feed them is more redundant. The more redundancy there is in the data, the more they're able to capture some internal structure of it. And so there is way more redundancy in the structure in perceptual inputs, sensory input like vision than there is in text, which is not nearly as redundant. This is back to the question you were asking a few minutes ago. Language might represent more information really, because it's already compressed. You're right about that, but that means it's also less redundant, and so self-supervision, you will not work as well.].[00:33:43][Lex Fridman][Is it possible to join the self-supervised training on visual data and self-supervised training on language data? There is a huge amount of knowledge, even though you talk down about those 10 to the 13 tokens. Those 10 to the 13 tokens represent the entirety-].[00:34:00][Lex Fridman][Those 10 to the 13 tokens represent the entirety, a large fraction of what us humans have figured out, both the shit-talk on Reddit and the contents of all the books and the articles and the full spectrum of human intellectual creation. So is it possible to join those two together?].[00:34:22][Yann LeCun][Well, eventually, yes. But I think if we do this too early, we run the risk of being tempted to cheat. And in fact, that's what people are doing at the moment with vision-language model. We're basically cheating. We're using language as a crutch to help the deficiencies of our vision systems to learn good representations from images and video.].[00:34:46][Yann LeCun][And the problem with this is that we might improve our language models by feeding them images, but we're not going to get to the level of even the intelligence or level of understanding of the world of a cat or a dog, which doesn't have language. They don't have language and they understand the world much better than any LLM. They can plan really complex actions and imagine the result of a bunch of actions. How do we get machines to learn that before we combine that with language? Obviously if we combine this with language, this is going to be a winner, but before that, we have to focus on how do we get systems to learn how the world works?].[00:35:33][Lex Fridman][So this joint-embedding predictive architecture, for you, that's going to be able to learn something like common sense, something like what a cat uses to predict how to mess with its owner most optimally by knocking over a thing.].[00:35:50][Yann LeCun][That's the hope. In fact, the techniques we're using are non-contrastive. So not only is the architecture non-generative, the learning procedures we are using are non-contrastive. We have two sets of techniques. One set is based on distillation, and there's a number of methods that use this principle, one by DeepMind called BYOL, a couple by FAIR, one called vcREG and another one called I-JEPA. And vcREG, I should say, is not a distillation method actually, but I-JEPA and BYOL certainly are. And there's another one also called DINO or DINO also produced from at FAIR. And the idea of those things is that you take the full input, let's say an image, you run it through an encoder, produces a representation, and then you corrupt that input or transform it, run it through essentially what amounts to the same encoder with some minor differences and then train a predictor.].[00:36:50][Yann LeCun][Sometimes a predictor is very simple, sometimes it doesn't exist, but train a predictor to predict a representation of the first uncorrupted input from the corrupted input. But you only train the second branch. You only train the part of the network that is fed with the corrupted input. The other network, you don't train. But since they share the same weight, when you modify the first one, it also modifies the second one. And with various tricks, you can prevent the system from collapsing with the collapse of the type I was explaining before, where the system basically ignores the input. So that works very well. The two techniques we developed at FAIR, DINO and I-JEPA work really well for that.]."
            },
            {
                "title": "DINO and I-JEPA",
                "statements": "[00:37:39][Lex Fridman][So what kind of data are we talking about here?].[00:37:41][Yann LeCun][So there's several scenario, one scenario is you take an image, you corrupt it by changing the cropping, for example, changing the size a little bit, maybe changing the orientation, blurring it, changing the colors, doing all kinds of horrible things to it.].[00:38:00][Lex Fridman][But basic horrible things?].[00:38:01][Yann LeCun][Basic horrible things that sort of degrade the quality a little bit and change the framing, crop the image. And in some cases, in the case of I-JEPA, you don't need to do any of this, you just mask some parts of it. You just basically remove some regions, like a big block essentially, and then run through the encoders and train the entire system, encoder and predictor, to predict the representation of the good one from the representation of the corrupted one.]."
            },
            {
                "title": "V-JEPA",
                "statements": "[00:38:33][Yann LeCun][So that's the I-JEPA. It doesn't need to know that it's an image for example, because the only thing it needs to know is how to do this masking. Whereas with DINO, you need to know it's an image because you need to do things like geometry transformation and blurring and things like that, that are really image specific. A more recent version of this that we have is called V-JEPA. So it's basically the same idea as I-JEPA except it's applied to video. So now you take a whole video and you mask a whole chunk of it. And what we mask is actually kind of a temporal tube, so a whole segment of each frame in the video over the entire video.].[00:39:10][Lex Fridman][And that tube was statically positioned throughout the frames, just literally it's a straight tube.].[00:39:16][Yann LeCun][The tube, yeah, typically is 16 frames or something, and we mask the same region over the entire 16 frames. It's a different one for every video obviously. And then again, train that system so as to predict the representation of the full video from the partially masked video. And that works really well. It's the first system that we have that learns good representations of video so that when you feed those representations to a supervised classifier head, it can tell you what action is taking place in the video with pretty good accuracy. So that's the first time we get something of that quality.].[00:39:56][Lex Fridman][That's a good test that a good representation is formed. That means there's something to this.].[00:40:00][Yann LeCun][Yeah. We also preliminary result that seem to indicate that the representation allow our system to tell whether the video is physically possible or completely impossible, because some object disappeared or an object suddenly jumped from one location to another or changed shape or something.].[00:40:21][Lex Fridman][So it's able to capture some physics based constraints about the reality represented in the video, about the appearance and the disappearance of objects.].[00:40:33][Yann LeCun][Yeah, that's really new.].[00:40:35][Lex Fridman][Okay, but can this actually get us to this kind of world model that understands enough about the world to be able to drive a car?].[00:40:49][Yann LeCun][Possibly, this is going to take a while before we get to that point. And there are systems already robotic systems, that are based on this idea. And what you need for this is a slightly modified version of this, where imagine that you have a complete video and what you're doing to this video is that you are either translating it in time towards the future. So you only see the beginning of the video, but you don't see the latter part of it that is in the original one, or you just mask the second half of the video, for example. And then you train a JEPA system or the type I described, to predict the representation of the full video from the shifted one. But you also feed the predictor with an action. For example, the wheel is turned 10 degrees to the right or something, right?].[00:41:45][Yann LeCun][So if it's a dash cam in a car and you know the angle of the wheel, you should be able to predict to some extent what's going to happen to what you see. You're not going to be able to predict all the details of objects that appear in the view obviously, but at a abstract representation level, you can probably predict what's going to happen. So now what you have is a internal model that says, \u201cHere is my idea of the state of the world at time T. Here is an action I'm taking. Here is a prediction of the state of the world at time T plus one, T plus delta T, T plus two seconds,\u201d whatever it is. If you have a model of this type, you can use it for planning. So now you can do what LMS cannot do, which is planning what you're going to do. So as you arrive at a particular outcome or satisfy a particular objective.].[00:42:40][Yann LeCun][So you can have a number of objectives. I can predict that if I have an object like this and I open my hand, it's going to fall. And if I push it with a particular force on the table, it's going to move. If I push the table itself, it's probably not going to move with the same force. So we have this internal model of the world in our mind, which allows us to plan sequences of actions to arrive at a particular goal. And so now if you have this world model, we can imagine a sequence of actions, predict what the outcome of the sequence of action is going to be, measure to what extent the final state satisfies a particular objective, like moving the bottle to the left of the table and then plan a sequence of actions that will minimize this objective, at runtime.].[00:43:41][Yann LeCun][We're not talking about learning, we're talking about inference time, so this is planning, really. And in optimal control, this is a very classical thing. It's called model predictive control. You have a model of the system you want to control that can predict the sequence of states corresponding to a sequence of commands. And you're planning a sequence of commands so that according to your role model, the end state of the system will satisfy an objectives that you fix. This is the way rocket trajectories have been planned since computers have been around, so since the early '60s essentially.]."
            },
            {
                "title": "Hierarchical planning",
                "statements": "[00:44:20][Lex Fridman][So yes, for a model predictive control, but you also often talk about hierarchical planning. Can hierarchical planning emerge from this somehow?].[00:44:28][Yann LeCun][Well, so no, you will have to build a specific architecture to allow for hierarchical planning. So hierarchical planning is absolutely necessary if you want to plan complex actions. If I want to go from, let's say from New York to Paris, it's the example I use all the time, and I'm sitting in my office at NYU, my objective that I need to minimize is my distance to Paris. At a high level, a very abstract representation of my location, I would have to decompose this into two sub goals. First one is go to the airport, second one is catch a plane to Paris. Okay, so my sub goal is now going to the airport. My objective function is my distance to the airport. How do I go to the airport where I have to go in the street and hail a taxi, which you can do in New York.].[00:45:21][Yann LeCun][Okay, now I have another sub goal go down on the street. Well that means going to the elevator, going down the elevator, walk out the street. How do I go to the elevator? I have to stand up from my chair, open the door in my office, go to the elevator, push the button. How do I get up for my chair? You can imagine going down, all the way down, to basically what amounts to millisecond by millisecond muscle control. And obviously you're not going plan your entire trip from New York to Paris in terms of millisecond by millisecond muscle control. First, that would be incredibly expensive, but it will also be completely impossible because you don't know all the conditions of what's going to happen, how long it's going to take to catch a taxi or to go to the airport with traffic. I mean, you would have to know exactly the condition of everything to be able to do this planning and you don't have the information. So you have to do this hierarchical planning so that you can start acting and then sort of replanning as you go. And nobody really knows how to do this in AI. Nobody knows how to train a system to learn the appropriate multiple levels of representation so that hierarchical planning works.].[00:46:41][Lex Fridman][Does something like that already emerge? So can you use an LLM, state-of-the-art LLM, to get you from New York to Paris by doing exactly the kind of detailed set of questions that you just did, which is, can you give me a list of 10 steps I need to do, to get from New York to Paris? And then for each of those steps, can you give me a list of 10 steps, how I make that step happen? And for each of those steps, can you give me a list of 10 steps to make each one of those, until you're moving your individual muscles, maybe not, whatever you can actually act upon using your own mind.].[00:47:21][Yann LeCun][Right. So there's a lot of questions that are also implied by this, right? So the first thing is LLMs will be able to answer some of those questions down to some level of abstraction, under the condition that they've been trained with similar scenarios in their training set.].[00:47:37][Lex Fridman][They would be able to answer all of those questions, but some of them may be hallucinated meaning non-factual.].[00:47:44][Yann LeCun][Yeah, true. I mean they'll probably produce some answer except they're not going to be able to really produce millisecond by millisecond muscle control of how you stand up from your chair. But down to some level of abstraction where you can describe things by words, they might be able to give you a plan, but only under the condition that they've been trained to produce those kinds of plans. They're not going to be able to plan for situations where that they never encountered before. They basically are going to have to regurgitate the template that they've been trained on.].[00:48:14][Lex Fridman][Just for the example of New York to Paris, is it going to start getting into trouble? Which layer of abstraction do you think you'll start? I can imagine almost every single part of that, an LLM would be able to answer somewhat accurately, especially when you're talking about New York and Paris, major cities.].[00:48:31][Yann LeCun][I mean certainly LLM would be able to solve that problem if you fine tune it for it. And so I can't say that an LLM cannot do this, it can do this if you train it for it, there's no question down to a certain level where things can be formulated in terms of words. But if you want to go down to how you climb down the stairs or just stand up from your chair in terms of words, you can't do it. That's one of the reasons you need experience of the physical world, which is much higher bandwidth than what you can express in words, in human language.].[00:49:11][Lex Fridman][So everything we've been talking about on the joint embedding space, is it possible that that's what we need for the interaction with physical reality on the robotics front, and then just the LLMs are the thing that sits on top of it for the bigger reasoning, about the fact that I need to book a plane ticket and I need to know how to go to the websites and so on.].[00:49:33][Yann LeCun][Sure. And a lot of plans that people know about that are relatively high level are actually learned. Most people don't invent the plans by themselves. We have some ability to do this of course, obviously, but most plans that people use are plans that have been trained on, they've seen other people use those plans or they've been told how to do things, right? That you can't invent how you take a person who's never heard of airplanes and tell them how do you go from New York to Paris? And they're probably not going to be able to deconstruct the whole plan unless they've seen examples of that before. So certainly LLMs are going to be able to do this, but then how you link this from the low level of actions, that needs to be done with things like JEPA that basically lift the abstraction level of the representation without attempting to reconstruct the detail of the situation, that's why we need JEPAs for.]."
            },
            {
                "title": "Autoregressive LLMs",
                "statements": "[00:50:40][Lex Fridman][I would love to sort of linger on your skepticism around auto regressive LLMs. So one way I would like to test that skepticism is everything you say makes a lot of sense, but if I apply everything you said today and in general to I don't know, 10 years ago, maybe a little bit less, no, let's say three years ago, I wouldn't be able to predict the success of LLMs. So does it make sense to you that autoregressive LLMs are able to be so damn good?].[00:51:20][Yann LeCun][Yes.].[00:51:21][Lex Fridman][Can you explain your intuition? Because if I were to take your wisdom and intuition at face value, I would say there's no way autoregressive LLMs, one token at a time, would be able to do the kind of things they're doing.].[00:51:36][Yann LeCun][No, there's one thing that autoregressive LLMs or that LLMs in general, not just the autoregressive one, but including the bird style bidirectional ones, are exploiting and its self supervised running, and I've been a very, very strong advocate of self supervised running for many years. So those things are a incredibly impressive demonstration that self supervised running actually works. The idea that started, it didn't start with BERT, but it was really kind of good demonstration with this.].[00:52:09][Yann LeCun][So the idea that you take a piece of text, you corrupt it, and then you train some gigantic neural net to reconstruct the parts that are missing. That has produced an enormous amount of benefits. It allowed us to create systems that understand language, systems that can translate hundreds of languages in any direction, systems that are multilingual, so it's a single system that can be trained to understand hundreds of languages and translate in any direction, and produce summaries and then answer questions and produce text.].[00:52:51][Yann LeCun][And then there's a special case of it, which is the auto regressive trick where you constrain the system to not elaborate a representation of the text from looking at the entire text, but only predicting a word from the words that are come before. And you do this by constraining the architecture of the network, and that's what you can build an auto aggressive LLM from.].[00:53:15][Yann LeCun][So there was a surprise many years ago with what's called decoder only LLM. So since systems of this type that are just trying to produce words from the previous one and the fact that when you scale them up, they tend to really understand more about language. When you train them on lots of data, you make them really big. That was a surprise and that surprise occurred quite a while back, with work from Google, Meta, OpenAI, et cetera, going back to the GPT kind of work, general pre-trained transformers.].[00:53:56][Lex Fridman][You mean like GPT2? There's a certain place where you start to realize scaling might actually keep giving us an emergent benefit.].[00:54:06][Yann LeCun][Yeah, I mean there were work from various places, but if you want to place it in the GPT timeline, that would be around GPT2, yeah.].[00:54:19][Lex Fridman][Well, because you said it so charismatic and you said so many words, but self supervised learning, yes. But again, the same intuition you're applying to saying that auto aggressive LLMs cannot have a deep understanding of the world. If we just apply that, same intuition, does it make sense to you that they're able to form enough of a representation in the world to be damn convincing, essentially passing the original touring test with flying colors?].[00:54:50][Yann LeCun][Well, we're fooled by their fluency, right? We just assume that if a system is fluent in manipulating language, then it has all the characteristics of human intelligence, but that impression is false. We're really fooled by it.].[00:55:06][Lex Fridman][What do you think Alan Turing would say, without understanding anything, just hanging out with it?].[00:55:11][Yann LeCun][Alan Turing would decide that a Turing test is a really bad test, okay? This is what the AI community has decided many years ago that the Turing test was a really bad test of intelligence.].[00:55:22][Lex Fridman][What would Hans Marvek say about the larger language models?].[00:55:26][Yann LeCun][Hans Marvek would say that Marvek Paradox still applies. Okay, we can pass-].[00:55:32][Lex Fridman][You don't think he would be really impressed?].[00:55:34][Yann LeCun][No, of course everybody would be impressed. But it's not a question of being impressed or not, it's the question of knowing what the limit of those systems can do. Again, they are impressive. They can do a lot of useful things. There's a whole industry that is being built around them. They're going to make progress, but there is a lot of things they cannot do, and we have to realize what they cannot do and then figure out how we get there. And I'm seeing this from basically 10 years of research on the idea of self supervised running, actually that's going back more than 10 years, but the idea of self supervised running. So basically capturing the internal structure of a piece of a set of inputs without training the system for any particular task, to learning representations.].[00:56:26][Yann LeCun][The conference I co-founded 14 years ago is called International Conference on Learning Representations. That's the entire issue that deep learning is dealing with, and it's been my obsession for almost 40 years now. So learning representation is really the thing. For the longest time, we could only do this with supervised learning, and then we started working on what we used to call unsupervised learning and revived the idea of unsupervised running in the early 2000s with your [inaudible 00:56:58] and Jeff Hinton. Then discovered that supervised running actually works pretty well if you can collect enough data. And so the whole idea of unsupervised, self supervised running kind of took a backseat for a bit, and then I tried to revive it in a big way starting in 2014, basically when we started FAIR and really pushing for finding new methods to do self supervised running both for text and for images and for video and audio.].[00:57:29][Yann LeCun][And some of that work has been incredibly successful. I mean, the reason why we have multilingual translation system, things to do, content moderation on Meta, for example, on Facebook, that are multilingual, that understand whether a piece of text is hate speech not or something, is due to that progress using self supervised running for NLP, combining this with transformer architectures and blah, blah, blah.].[00:57:53][Yann LeCun][But that's the big success of self supervised running. We had similar success in speech recognition, a system called WAVE2VEC, which is also a joint embedding architecture, by the way, trained with contrastive running. And that system also can produce speech recognition systems that are multilingual with mostly unlabeled data and only need a few minutes of labeled data to actually do speech recognition, that's amazing. We have systems now based on those combination of ideas that can do real time translation of hundreds of languages into each other, speech to speech.].[00:58:28][Lex Fridman][Speech to speech, even including, which is fascinating, languages that don't have written forms.].[00:58:34][Yann LeCun][That's right.].[00:58:34][Lex Fridman][Just spoken only.].[00:58:35][Yann LeCun][That's right. We don't go through text, it goes directly from speech to speech using an internal representation of speech units that are discrete, but it's called Textless NLP. We used to call it this way. But yeah, so I mean incredible success there. And then for 10 years, we tried to apply this idea to learning representations of images by training a system to predict videos, learning intuitive physics by training a system to predict what's going to happen in the video.].[00:59:02][Yann LeCun][And tried and tried and failed and failed, with generative models, with models that predict pixels. We could not get them to learn good representations of images. We could not get them to learn good representations of videos. And we tried many times, we published lots of papers on it, where they kind of sort of work, but not really great. They started working, we abandoned this idea of predicting every pixel and basically just doing the joint embedding and predicting and representation space, that works. So there's ample evidence that we're not going to be able to learn good representations of the real world using generative model. So I'm telling people, everybody's talking about generative AI. If you're really interested in human level AI, abandon the idea of generative AI.].[00:59:51][Lex Fridman][Okay, but you really think it's possible to get far with the joint embedding representation. So there's common sense reasoning, and then there's high level reasoning. I feel like those are two... The kind of reasoning that LLMs are able to do, okay, let me not use the word reasoning, but the kind of stuff that LLMs are able to do, seems fundamentally different than the common sense reasoning we use to navigate the world. It seems like we're going to need both. Would you be able to get, with the joint embedding, which is JEPA type of approach, looking at video, would you be able to learn, let's see, well, how to get from New York to Paris or how to understand the state of politics in the world today. These are things where various humans generate a lot of language and opinions on, in the space of language, but don't visually represent that in any clearly compressible way.].[01:00:56][Yann LeCun][Right. Well, there's a lot of situations that might be difficult to, for a purely language based system to know. Okay, you can probably learn from reading texts, the entirety of the publicly available texts in the world that I cannot get from New York to Paris by snapping my fingers. That's not going to work, right?].[01:01:16][Lex Fridman][Yes.].[01:01:18][Yann LeCun][But there's probably more complex scenarios of this type, which an LLM may never have encountered and may not be able to determine whether it's possible or not. So that link from the low level to the high level, the thing is that the high level that language expresses is based on the common experience of the low level, which LLMs currently do not have. When we talk to each other, we know we have a common experience of the world. A lot of it is similar, and LLMs don't have that.].[01:01:59][Lex Fridman][But see, it's present. You and I have a common experience of the world in terms of the physics of how gravity works and stuff like this, and that common knowledge of the world, I feel like is there, in the language. We don't explicitly express it, but if you have a huge amount of text, you're going to get this stuff that's between the lines. In order to form a consistent world model, you're going to have to understand how gravity works, even if you don't have an explicit explanation of gravity. So even though in the case of gravity, there is explicit explanations of gravity in Wikipedia. But the stuff that we think of as common sense reasoning, I feel like to generate language correctly, you're going to have to figure that out. Now, you could say as you have, there's not enough text... Sorry, okay, so you don't think so?].[01:02:57][Yann LeCun][No, I agree with what you just said, which is that to be able to do high level common sense, to have high level common sense, you need to have the low level common sense to build on top of.].[01:03:09][Lex Fridman][But that's not there.].[01:03:10][Yann LeCun][And that's not there in the LLMs. LLMs are purely trained from text. So then the other statement you made, I would not agree with, the fact that implicit in all languages in the world is the underlying reality, is a lot of underlying reality, which is not expressed in language.].[01:03:26][Lex Fridman][Is that obvious to you?].[01:03:28][Yann LeCun][Yeah, totally.].[01:03:30][Lex Fridman][So all the conversations we had... Okay, there's the dark web, meaning whatever, the private conversations like DMs and stuff like this, which is much, much larger probably than what's available, what LLMs are trained on.].[01:03:46][Yann LeCun][You don't need to communicate the stuff that is common, right?].[01:03:50][Lex Fridman][But the humor, all of it, no, you do, you don't need to, but it comes through. If I accidentally knock this over, you'll probably make fun of me in the content of the you making fun of me will be explanation of the fact that cups fall, and then gravity works in this way. And then you'll have some very vague information about what kind of things explode when they hit the ground. And then maybe you'll make a joke about entropy or something like this, then we'll never be able to reconstruct this again. You'll make a little joke like this and there'll be a trillion of other jokes. And from the jokes, you can piece together the fact that gravity works and mugs can break and all this kind of stuff. You don't need to see, it'll be very inefficient. It's easier to knock the thing over, but I feel like it would be there if you have enough of that data.].[01:04:46][Yann LeCun][I just think that most of the information of this type that we have accumulated when we were babies, it's just not present in text, in any description, essentially.].[01:04:59][Lex Fridman][And the sensory data is a much richer source for getting that kind of understanding.].[01:05:04][Yann LeCun][I mean, there's 16,000 hours of wake time of a 4-year-old and tend to do 15 bites going through vision, just vision, there is a similar bandwidth of touch and a little less through audio. And then text, language doesn't come in until a year in life. And by the time you are nine years old, you've learned about gravity, you know about inertia, you know about gravity, the stability, you know about the distinction between animate and inanimate objects. You know by 18 months, you know about why people want to do things and you help them if they can't. I mean, there's a lot of things that you learn mostly by observation, really not even through interaction. In the first few months of life, babies don't really have any influence on the world, they can only observe. And you accumulate a gigantic amount of knowledge just from that. So that's what we're missing from current AI systems.]."
            },
            {
                "title": "AI hallucination",
                "statements": "[01:06:06][Lex Fridman][I think in one of your slides, you have this nice plot that is one of the ways you show that LLMs are limited. I wonder if you could talk about hallucinations from your perspectives, the why hallucinations happen from large language models and to what degree is that a fundamental flaw of large language models?].[01:06:29][Yann LeCun][Right, so because of the autoregressive prediction, every time an produces a token or a word, there is some level of probability for that word to take you out of the set of reasonable answers. And if you assume, which is a very strong assumption, that the probability of such error is that those errors are independent across a sequence of tokens being produced. What that means is that every time you produce a token, the probability that you stay within the set of correct answer decreases and it decreases exponentially.].[01:07:08][Lex Fridman][So there's a strong, like you said, assumption there that if there's a non-zero probability of making a mistake, which there appears to be, then there's going to be a kind of drift.].[01:07:18][Yann LeCun][Yeah, and that drift is exponential. It's like errors accumulate. So the probability that an answer would be nonsensical increases exponentially with the number of tokens.].[01:07:31][Lex Fridman][Is that obvious to you, by the way? Well, mathematically speaking maybe, but isn't there a kind of gravitational pull towards the truth? Because on average, hopefully, the truth is well represented in the training set?].[01:07:48][Yann LeCun][No, it's basically a struggle against the curse of dimensionality. So the way you can correct for this is that you fine tune the system by having it produce answers for all kinds of questions that people might come up with.].[01:08:00][Yann LeCun][Having it produce answers for all kinds of questions that people might come up with. And people are people, so a lot of the questions that they have are very similar to each other, so you can probably cover 80% or whatever of questions that people will ask by collecting data and then you fine tune the system to produce good answers for all of those things, and it's probably going to be able to learn that because it's got a lot of capacity to learn. But then there is the enormous set of prompts that you have not covered during training, and that set is enormous, like within the set of all possible prompts, the proportion of prompts that have been used for training is absolutely tiny, it's a tiny, tiny, tiny subset of all possible prompts.].[01:08:54][Yann LeCun][And so the system will behave properly on the prompts that has been either trained, pre-trained, or fine-tuned, but then there is an entire space of things that it cannot possibly have been trained on because the number is gigantic. So whatever training the system has been subject to produce appropriate answers, you can break it by finding out a prompt that will be outside of the set of prompts that's been trained on, or things that are similar, and then it will just spew complete nonsense.].[01:09:30][Lex Fridman][When you say prompt, do you mean that exact prompt or do you mean a prompt that's in many parts, very different than? Is it that easy to ask a question or to say a thing that hasn't been said before on the internet?].[01:09:46][Yann LeCun][People have come up with things where you put essentially a random sequence of characters in the prompt and that's enough to throw the system into a mode where it is going to answer something completely different than it would have answered without this. So that's a way to jailbreak the system, basically go outside of its conditioning.].[01:10:09][Lex Fridman][That's a very clear demonstration of it, but of course, that goes outside of what is designed to do, right? If you actually stitch together reasonably grammatical sentences, is it that easy to break it?].[01:10:26][Yann LeCun][Yeah, some people have done things like, you write a sentence in English or you ask a question in English and it produces a perfectly fine answer and then you just substitute a few words by the same word in another language and all of a sudden the answer is complete nonsense.].[01:10:45][Lex Fridman][What I'm saying is, which fraction of prompts that humans are likely to generate are going to break the system?].[01:10:55][Yann LeCun][The problem is that there is a long tail, this is an issue that a lot of people have realized in social networks and stuff like that, which is there's a very, very long tail of things that people will ask and you can fine tune the system for the 80% or whatever of the things that most people will ask. And then this long tail is so large that you're not going to be able to fine tune the system for all the conditions. And in the end, the system ends up being a giant lookup table essentially, which is not really what you want, you want systems that can reason, certainly that can plan.]."
            },
            {
                "title": "Reasoning in AI",
                "statements": "[01:11:31][Yann LeCun][The type of reasoning that takes place in LLM is very, very primitive, and the reason you can tell is primitive is because the amount of computation that is spent per token produced is constant. So if you ask a question and that question has an answer in a given number of token, the amount of computation devoted to computing that answer can be exactly estimated. It's the size of the prediction network with its 36 layers or 92 layers or whatever it is multiply by number of tokens, that's it. And so essentially, it doesn't matter if the question being asked is simple to answer, complicated to answer, impossible to answer because it's a decidable or something, the amount of computation the system will be able to devote to the answer is constant or is proportional to number of token produced in the answer. This is not the way we work, the way we reason is that when we're faced with a complex problem or a complex question, we spend more time trying to solve it and answer it because it's more difficult.].[01:12:43][Lex Fridman][There's a prediction element, there's an iterative element where you're adjusting your understanding of a thing by going over and over and over, there's a hierarchical elements on. Does this mean it's a fundamental flaw of LLMs or does it mean that-].[01:13:00][Yann LeCun][Yeah.].[01:13:00][Lex Fridman][... There's more part to that question, now you're just behaving like an LLM, immediately answering. No, that it's just the low level world model on top of which we can then build some of these kinds of mechanisms, like you said, persistent long-term memory or reasoning, so on. But we need that world model that comes from language. Maybe it is not so difficult to build this kind of reasoning system on top of a well constructed world model.].[01:13:37][Yann LeCun][Whether it's difficult or not, the near future will say because a lot of people are working on reasoning and planning abilities for dialogue systems. Even if we restrict ourselves to language, just having the ability to plan your answer before you answer in terms that are not necessarily linked with the language you're going to use to produce the answer, so this idea of this mental model that allows you to plan what you're going to say before you say it, that is very important. I think there's going to be a lot of systems over the next few years that are going to have this capability, but the blueprint of those systems will be extremely different from auto aggressive LLMs.].[01:14:26][Yann LeCun][It's the same difference as the difference between what psychologists call system one and system two in humans, so system one is the type of task that you can accomplish without deliberately consciously think about how you do them, you just do them, you've done them enough that you can just do it subconsciously without thinking about them. If you're an experienced driver, you can drive without really thinking about it and you can talk to someone at the same time or listen to the radio. If you are a very experienced chess player, you can play against a non- experienced chess player without really thinking either, you just recognize the pattern and you play. That's system one, so all the things that you do instinctively without really having to deliberately plan and think about it.].[01:15:13][Yann LeCun][And then there is all the tasks where you need to plan, so if you are a not too experienced chess player or you are experienced where you play against another experienced chess player, you think about all kinds of options, you think about it for a while and you are much better if you have time to think about it than you are if you play blitz with limited time. So this type of deliberate planning, which uses your internal world model, that's system two, this is what LMS currently cannot do. How do we get them to do this? How do we build a system that can do this kind of planning or reasoning that devotes more resources to complex problems than to simple problems? And it's not going to be a regressive prediction of tokens, it's going to be more something akin to inference of little variables in what used to be called probabilistic models or graphical models and things of that type.].[01:16:17][Yann LeCun][Basically, the principle is like this, the prompt is like observed variables, and what the model does, is that basically, it can measure to what extent an answer is a good answer for a prompt. So think of it as some gigantic neural net, but it's got only one output, and that output is a scaler number, which is, let's say, zero, if the answer is a good answer for the question and a large number, if the answer is not a good answer for the question. Imagine you had this model, if you had such a model, you could use it to produce good answers, the way you would do is, produce the prompt and then search through the space of possible answers for one that minimizes that number, that's called an energy based model.].[01:17:11][Lex Fridman][But that energy based model would need the model constructed by the LLM?].[01:17:18][Yann LeCun][Well, so really what you need to do would be to not search over possible strings of text that minimize that energy. But what you would do, we do this in abstract representation space, so in the space of abstract thoughts, you would elaborate a thought using this process of minimizing the output of your model, which is just a scaler, it's an optimization process. So now the way the system produces its sensor is through optimization by minimizing an objective function basically. And we're talking about inference, we're not talking about training, the system has been trained already.].[01:18:01][Yann LeCun][Now we have an abstract representation of the thought of the answer, representation of the answer, we feed that to basically an autoregressive decoder, which can be very simple, that turns this into a text that expresses this thought. So that, in my opinion, is the blueprint of future data systems, they will think about their answer, plan their answer by optimization before turning it into text, and that is turning complete.].[01:18:31][Lex Fridman][Can you explain exactly what the optimization problem there is? What's the objective function? Just linger on it, you briefly described it, but over what space are you optimizing?].[01:18:43][Yann LeCun][The space of representations.].[01:18:45][Lex Fridman][It goes abstract representation?].[01:18:48][Yann LeCun][You have an abstract representation inside the system, you have a prompt, the prompt goes through an encoder, produces a representation, perhaps goes through a predictor that predicts a representation of the proper answer. But that representation may not be a good answer because there might be some complicated reasoning you need to do, so then you have another process that takes the representation of the answers and modifies it so as to minimize a cost function that measures to what extent the answer is a good answer for the question. Now we ignore the issue for a moment of how you train that system to measure whether an answer is a good answer for a fraction.].[01:19:36][Lex Fridman][Sure. Suppose such a system could be created, but what's this search like process?].[01:19:42][Yann LeCun][It's an optimization process. You can do this if the entire system is differentiable, that scaler output is the result of running the representation of the answers to some neural net. Then by gradient descent, by back propagating gradients, you can figure out how to modify the representation of the answers so as to minimize that.].[01:20:05][Lex Fridman][That's still a gradient based?].[01:20:06][Yann LeCun][It's gradient based inference. So now you have a representation of the answer in abstract space, now you can turn it into text. And the cool thing about this is that the representation now can be optimized through gradient descent, but also is independent of the language in which you're going to express the answer.].[01:20:27][Lex Fridman][Right. So you're operating in the subtract representation. This goes back to the joint embedding, that it's better to work in the space of, I don't know, or to romanticize the notion like space of concepts versus the space of concrete sensory information.].[01:20:45][Yann LeCun][Right.].[01:20:48][Lex Fridman][But can this do something like reasoning, which is what we're talking about?].[01:20:51][Yann LeCun][Well, not really, only in a very simple way. Basically, you can think of those things as doing the optimization I was talking about, except they optimize in the discrete space, which is the space of possible sequences of tokens. And they do this optimization in a horribly inefficient way, which is generate a lot of hypothesis and then select the best ones. And that's incredibly wasteful in terms of competition because you basically have to run your LLM for every possible generative sequence and it's incredibly wasteful. So it's much better to do an optimization in continuous space where you can do gradient and descent as opposed to generate tons of things and then select the best, you just iteratively refine your answer to go towards the best, that's much more efficient. But you can only do this in continuous spaces with differentiable functions.].[01:21:48][Lex Fridman][You're talking about the ability to think deeply or to reason deeply, how do you know what is an answer that's better or worse based on deep reasoning?].[01:22:05][Yann LeCun][Then we are asking the question of, conceptually, how do you train an energy based model? Energy based model is a function with a scaler output, just a number, you give it two inputs, X and Y, and it tells you whether Y is compatible with X or not. X, you observe, let's say it's a prompt, an image, a video, whatever, and Y is a proposal for an answer, a continuation of video, whatever and it tells you whether Y is compatible with X. And the way it tells you that Y is compatible with X is that the output of that function would be zero if Y is compatible with X and would be a positive number, non-zero, if Y is not compatible with X.].[01:22:47][Yann LeCun][How do you train a system like this at a completely general level, is you show it pairs of X and Ys that are compatible, a question and the corresponding answer, and you train the parameters of the big neural net inside to produce zero. Now that doesn't completely work because the system might decide, well, I'm just going to say zero for everything, so now you have to have a process to make sure that for a wrong Y, the energy would be larger than zero. And there you have two options, one is contrastive method, so contrastive method is, you show an X and a bad Y and you tell the system, well, give a high energy to this, push up the energy, change the weights in the neural net that confuse the energy so that it goes up. So that's contrasting methods.].[01:23:37][Yann LeCun][The problem with this is, if the space of Y is large, the number of such contrasting samples are going to have to show is gigantic. But people do this, they do this when you train a system with RLHF, basically what you're training is what's called a reward model, which is basically an objective function that tells you whether an answer is good or bad, and that's basically exactly what this is. So we already do this to some extent, we're just not using it for inference, we're just using it for training.].[01:24:14][Yann LeCun][There is another set of methods which are non-contrastive, and I prefer those, and those non-contrastive methods basically say, the energy function needs to have low energy on pairs of XYs that are compatible that come from your training set. How do you make sure that the energy is going to be higher everywhere else? And the way you do this is by having a regularizer, a criterion, a term in your cost function that basically minimizes the volume of space that can take low energy. And the precise way to do this is all kinds of different specific ways to do this depending on the architecture, but that's the basic principle. So that if you push down the energy function for particular regions in the XY space, it will automatically go up in other places because there's only a limited volume of space that can take low energy by the construction of the system or by the regularizing function.].[01:25:16][Lex Fridman][We've been talking very generally, but what is a good X and a good Y? What is a good representation of X and Y? Because we've been talking about language and if you just take language directly that presumably is not good, so there has to be some kind of abstract representation of ideas.].[01:25:37][Yann LeCun][You can do this with language directly by just, X is a text and Y is a continuation of that text.].[01:25:43][Lex Fridman][Yes.].[01:25:45][Yann LeCun][Or X is a question, Y is the answer.].[01:25:48][Lex Fridman][But you're saying that's not going to take it, that's going to do what LLMs are doing.].[01:25:52][Yann LeCun][Well, no, it depends on how the internal structure of the system is built. If the internal structure of the system is built in such a way that inside of the system there is a latent variable, let's call it Z, that you can manipulate so as to minimize the output energy, then that Z can be viewed as a representation of a good answer that you can translate into a Y that is a good answer.].[01:26:19][Lex Fridman][This system could be trained in a very similar way?].[01:26:24][Yann LeCun][Very similar way, but you have to have this way preventing collapse of ensuring that there is high energy for things you don't train it on. And currently, it's very implicit in LLM, it's done in a way that people don't realize it's being done, but it is being done. It is due to the fact that when you give a high probability to a word, automatically, you give low probability to other words because you only have a finite amount of probability to go around right there to sum to one. So when you minimize the cross entropy or whatever, when you train your LLM to predict the next word, you are increasing the probability your system will give to the correct word, but you're also decreasing the probability it will give to the incorrect words.].[01:27:12][Yann LeCun][Now, indirectly, that gives a high probability to sequences of words that are good and low probability to sequences of words that are bad, but it's very indirect. And it's not obvious why this actually works at all because you're not doing it on the joint probability of all the symbols in a sequence, you factorize that probability in terms of conditional probabilities over successive tokens.].[01:27:41][Lex Fridman][How do you do this for visual data?].[01:27:44][Yann LeCun][We've been doing this with I-JEPA architectures, basically-].[01:27:46][Lex Fridman][The joint embedding.].[01:27:47][Yann LeCun][... I-JEPA. So there the compatibility between two things is, here's an image or a video, here is a corrupted, shifted or transformed version of that image or video or masked. And then the energy of the system is the prediction error of the predicted representation of the good thing versus the actual representation of the good thing. So you run the corrupted image to the system, predict the representation of the good input uncorrupted, and then compute the prediction error, that's the energy of the system. So this system will tell you if this is a good image and this is a corrupted version, it will give you zero energy if those two things, effectively, one of them is a corrupted version of the other, it gives you a high energy if the two images are completely different.].[01:28:46][Lex Fridman][And hopefully that whole process gives you a really nice compressed representation of a visual reality?].[01:28:54][Yann LeCun][And we know it does because then we use those representations as input to a classification system or something and that it works.]."
            },
            {
                "title": "Reinforcement learning",
                "statements": "[01:29:00][Lex Fridman][And then that classification system works really nicely, okay. Well, so to summarize, you recommend in a spicy way that only Yann LeCun can, you recommend that we abandon generative models in favor of joint embedding architectures?].[01:29:15][Yann LeCun][Yes.].[01:29:15][Lex Fridman][Abandon autoregressive generation.].[01:29:17][Yann LeCun][Yes.].[01:29:19][Lex Fridman][This feels like court testimony, abandon probabilistic models in favor of energy based models as we talked about, abandon contrastive methods in favor of regularized methods. And let me ask you about this, you've been for a while, a critic of reinforcement learning.].[01:29:36][Yann LeCun][Yes.].[01:29:38][Lex Fridman][The last recommendation is that we abandon RL in favor of model predictive control, as you were talking about, and only use RL when planning doesn't yield the predicted outcome, and we use RL in that case to adjust the world model or the critic.].[01:29:55][Yann LeCun][Yes.].[01:29:57][Lex Fridman][You've mentioned RLHF, reinforcement learning with human feedback, why do you still hate reinforcement learning?].[01:30:05][Yann LeCun][I don't hate reinforcement learning, and I think-].[01:30:07][Lex Fridman][It's all love, yes.].[01:30:08][Yann LeCun][... I think it should not be abandoned completely, but I think it's use should be minimized because it's incredibly inefficient in terms of samples. And so the proper way to train a system is to first have it learn good representations of the world and world models from mostly observation, maybe a little bit of interactions.].[01:30:31][Lex Fridman][And then steered based on that, if the representation is good, then the adjustments should be minimal.].[01:30:36][Yann LeCun][Yeah. Now there's two things, if you've learned a world model, you can use the world model to plan a sequence of actions to arrive at a particular objective, you don't need RL unless the way you measure whether you succeed might be in exact. Your idea of whether you are going to fall from your bike might be wrong, or whether the person you're fighting with MMA who's going to do something and they do something else. So there's two ways you can be wrong, either your objective function does not reflect the actual objective function you want to optimize or your world model is inaccurate, so the prediction you were making about what was going to happen in the world is inaccurate.].[01:31:25][Yann LeCun][If you want to adjust your world model while you are operating in the world or your objective function, that is basically in the realm of RL, this is what RL deals with to some extent, so adjust your word model. And the way to adjust your word model even in advance is to explore parts of the space where you know that your world model is inaccurate, that's called curiosity basically, or play. When you play, you explore parts of the space that you don't want to do for real because it might be dangerous, but you can adjust your world model without killing yourself basically. So that's what you want to use RL for, when it comes time to learning a particular task, you already have all the good representations, you already have your world model, but you need to adjust it for the situation at hand, that's when you use RL.].[01:32:26][Lex Fridman][Why do you think RLHF works so well? This enforcement learning with human feedback, why did it have such a transformational effect on large language models than before?].[01:32:38][Yann LeCun][What's had the transformational effect is human feedback, there is many ways to use it, and some of it is just purely supervised, actually, it's not really reinforcement learning.].[01:32:49][Lex Fridman][It's the HF?].[01:32:50][Yann LeCun][It's the HF, and then there is various ways to use human feedback. So you can ask humans to rate multiple answers that are produced by world model, and then what you do is you train an objective function to predict that rating, and then you can use that objective function to predict whether an answer is good and you can back propagate gradient to this to fine tune your system so that it only produces highly rated answers. That's one way, so in RL, that means training what's called a reward model, so something that basically is a small neural net that estimates to what extent an answer is good.].[01:33:35][Yann LeCun][It's very similar to the objective I was talking about earlier for planning, except now it's not used for planning, it's used for fine-tuning your system. I think it would be much more efficient to use it for planning, but currently, it's used to fine tune the parameters of the system. There's several ways to do this, some of them are supervised, you just ask a human person like, what is a good answer for this? Then you just type the answer. There's lots of ways that those systems are being adjusted.]."
            },
            {
                "title": "Woke AI",
                "statements": "[01:34:10][Lex Fridman][Now, a lot of people have been very critical of the recently released Google's Gemini 1.5 for essentially, in my words, I could say super woke in the negative connotation of that word. There is some almost hilariously absurd things that it does, like it modifies history like generating images of a black George Washington, or perhaps more seriously something that you commented on Twitter, which is refusing to comment on or generate images or even descriptions of Tiananmen Square or The Tank Man, one of the most legendary protest images in history. Of course, these images are highly censored by the Chinese government and therefore, everybody started asking questions of what is the process of designing these LLMs? What is the role of censorship and all that kind of stuff? So you commented on Twitter saying that open source is the answer.].[01:35:24][Yann LeCun][Yeah.].[01:35:25][Lex Fridman][Essentially, so can you explain?].[01:35:29][Yann LeCun][I actually made that comment on just about every social network I can, and I've made that point multiple times in various forums. Here's my point of view on this, people can complain that AI systems are biased and they generally are biased by the distribution of the training data that they've been trained on that reflects biases in society, and that is potentially offensive to some people or potentially not. And some techniques to de-bias then become offensive to some people because of historical incorrectness and things like that.].[01:36:23][Yann LeCun][And so you can ask two questions, the first question is, is it possible to produce an AI system that is not biased? And the answer is, absolutely not. And it's not because of technological challenges, although they are technological challenges to that, it's because bias is in the eye of the beholder. Different people may have different ideas about what constitutes bias for a lot of things, there are facts that are indisputable, but there are a lot of opinions or things that can be expressed in different ways. And so you cannot have an unbiased system, that's just an impossibility.].[01:37:08][Yann LeCun][And so what's the answer to this? And the answer is the same answer that we found in liberal democracy about the press, the press needs to be free and diverse. We have free speech for a good reason, is because we don't want all of our information to come from a unique source because that's opposite to the whole idea of democracy and progressive ideas and even science. In science, people have to argue for different opinions and science makes progress when people disagree and they come up with an answer and consensus forms, and it's true in all democracies around the world.].[01:37:58][Yann LeCun][There is a future which is already happening where every single one of our interaction with the digital world will be mediated by AI systems, AI assistance. We're going to have smart glasses, you can already buy them from Meta, the Ray-Ban Meta where you can talk to them and they are connected with an LLM and you can get answers on any question you have. Or you can be looking at a monument and there is a camera in the glasses you can ask it like, what can you tell me about this building or this monument? You can be looking at a menu in a foreign language, and I think we will translate it for you, or we can do real time translation if we speak different languages. So a lot of our interactions with the digital world are going to be mediated by those systems in the near future.].[01:38:53][Yann LeCun][Increasingly, the search engines that we're going to use are not going to be search engines, they're going to be dialogue systems that we just ask a question and it will answer and then point you to perhaps appropriate reference for it. But here is the thing, we cannot afford those systems to come from a handful of companies on the west coast of the US because those systems will constitute the repository of all human knowledge, and we cannot have that be controlled by a small number of people. It has to be diverse for the same reason the press has to be diverse, so how do we get a diverse set of AI assistance? It's very expensive and difficult to train a base model, a base LLM at the moment, in the future it might be something different, but at the moment, that's an LLM. So only a few companies can do this properly.].[01:39:50][Yann LeCun][And if some of those top systems are open source, anybody can use them, anybody can fine tune them. If we put in place some systems that allows any group of people, whether they are individual citizens, groups of citizens, government organizations, NGOs, companies, whatever, to take those open source AI systems and fine tune them for their own purpose on their own data, then we're going to have a very large diversity of different AI systems that are specialized for all of those things.].[01:40:35][Yann LeCun][I tell you, I talked to the French government quite a bit, and the French government will not accept that the digital diet of all their citizens be controlled by three companies on the west coast of the US. That's just not acceptable, it's a danger to democracy regardless of how well-intentioned those companies are, and it's also a danger to local culture, to values, to language. I was talking with the founder of Infosys in India, he's funding a project to fine tune Llama 2, the open source model produced by Meta, so that Llama 2 two speaks all 22 official languages in India, it is very important for people in India. I was talking to a former colleague of mine, Moustapha Cisse, who used to be a scientist at Fair and then moved back to Africa, created a research lab for Google in Africa and now has a new startup Co-Kera.].[01:41:37][Yann LeCun][And what he's trying to do, is basically have LLM that speak the local languages in Senegal so that people can have access to medical information because they don't have access to doctors, it's a very small number of doctors per capita in Senegal. You can't have any of this unless you have open source platforms, so with open source platforms, you can have AI systems that are not only diverse in terms of political opinions or things of that-].[01:42:00][Yann LeCun][... AI systems that are not only diverse in terms of political opinions or things of that type, but in terms of language, culture, value systems, political opinions, technical abilities in various domains, and you can have an industry, an ecosystem of companies that fine tune those open source systems for vertical applications in industry. I don't know, a publisher has thousands of books and they want to build a system that allows a customer to just ask a question about the content of any of their books, you need to train on their proprietary data. You have a company, we have one within Meta, it's called Metamate, and it's basically an LLM that can answer any question about internal stuff about the company, very useful.].[01:42:53][Yann LeCun][A lot of companies want this. A lot of companies want this not just for their employees, but also for their customers, to take care of their customers. So the only way you're going to have an AI industry, the only way you're going to have AI systems that are not uniquely biased is if you have open source platforms on top of which any group can build specialized systems. So the direction of inevitable direction of history is that the vast majority of AI systems will be built on top of open source platforms.].[01:43:28][Lex Fridman][So that's a beautiful vision. So meaning a company like Meta or Google or so on should take only minimal fine-tuning steps after building the foundation pre-trained model as few steps as possible.]."
            },
            {
                "title": "Open source",
                "statements": "[01:43:47][Yann LeCun][Basically.].[01:43:49][Lex Fridman][Can Meta afford to do that?].[01:43:51][Yann LeCun][No.].[01:43:51][Lex Fridman][So I don't know if you know this, but companies are supposed to make money somehow and open source is giving away... I don't know. Mark made a video, Mark Zuckerberg, very sexy video talking about 350,000 Nvidia H100s.].[01:44:12][Yann LeCun][Yeah, [inaudible 01:44:12]].[01:44:13][Lex Fridman][The math of that is just for the GPUs, that's 100 billion plus the infrastructure for training everything. So I'm no business guy, but how do you make money on that? So the division you paint is a really powerful one, but how is it possible to make money?].[01:44:32][Yann LeCun][Okay, so you have several business models, right?].[01:44:36][Lex Fridman][Mm-hmm.].[01:44:36][Yann LeCun][The business model that Meta is built around is you offer a service and the financing of that service is either through ads or through business customers. So for example, if you have an LLM that can help a mom-and-pop pizza place by talking to the customers through WhatsApp, and so the customers can just order a pizza and the system will just ask them, \u201cWhat topping do you want or what size, blah, blah, blah.\u201d The business will pay for that, okay? That's a model. Otherwise, if it's a system that is on the more classical services, it can be ad supported or there's several models. But the point is, if you have a big enough potential customer base and you need to build that system anyway for them, it doesn't hurt you to actually distribute it to the open source.].[01:45:43][Lex Fridman][Again, I'm no business guy, but if you release the open source model, then other people can do the same kind of task and compete on it, basically provide fine-tuned models for businesses.].[01:45:57][Yann LeCun][Sure.].[01:45:59][Lex Fridman][By the way, I'm a huge fan of all this, but is the bet that Meta is making, it's like, \u201cWe'll do a better job of it?\u201d].[01:46:05][Yann LeCun][Well, no. The bet is more, \u201cWe already have a huge user base and customer base-].[01:46:13][Lex Fridman][Ah, right.].[01:46:14][Yann LeCun][... so it's going to be useful to them. Whatever we offer them is going to be useful and there is a way to derive revenue from this.].[01:46:21][Lex Fridman][Sure.].[01:46:22][Yann LeCun][It doesn't hurt that we provide that system or the base model, the foundation model in open source for others to build applications on top of it too. If those applications turn out to be useful for our customers, we can just buy it from them. It could be that they will improve the platform. In fact, we see this already. There is literally millions of downloads of LLaMA 2 and thousands of people who have provided ideas about how to make it better. So this clearly accelerates progress to make the system available to a wide community of people, and there's literally thousands of businesses who are building applications with it. So Meta's ability to derive revenue from this technology is not impaired by the distribution of base models in open source.]."
            },
            {
                "title": "AI and ideology",
                "statements": "[01:47:26][Lex Fridman][The fundamental criticism that Gemini is getting is that as you point out on the West Coast, just to clarify, we're currently on the East Coast where I would suppose Meta AI headquarters would be. So there are strong words about the West Coast, but I guess the issue that happens is I think it's fair to say that most tech people have a political affiliation with the left wing. They lean left. So the problem that people are criticizing Gemini with is that there's in that de-biasing process that you mentioned, that their ideological lean becomes obvious. Is this something that could be escaped? You're saying open source is the only way.].[01:48:17][Yann LeCun][Yes.].[01:48:17][Lex Fridman][Have you witnessed this kind of ideological lean that makes engineering difficult?].[01:48:22][Yann LeCun][No, I don't think the issue has to do with the political leaning of the people designing those systems. It has to do with the acceptability or political leanings of their customer base or audience. So a big company cannot afford to offend too many people, so they're going to make sure that whatever product they put out is safe, whatever that means. It's very possible to overdo it, and it's impossible to do it properly for everyone. You're not going to satisfy everyone. So that's what I said before, you cannot have a system that is perceived as unbiased by everyone. It's going to be you push it in one way, one set of people are going to see it as biased, and then you push it the other way and another set of people is going to see it as biased. Then in addition to this, there's the issue of if you push the system perhaps a little too far in one direction, it's going to be non-factual. You're going to have Black Nazi soldiers in uniform.].[01:49:31][Lex Fridman][Yeah, we so we should mention image generation of Black Nazi soldiers, which is not factually accurate.].[01:49:38][Yann LeCun][Right, and can be offensive for some people as well. So it's going to be impossible to produce systems that are unbiased for everyone. So the only solution that I see is diversity.].[01:49:53][Lex Fridman][Diversity in the full meaning of that word, diversity of in every possible way.]."
            },
            {
                "title": "Marc Andreesen",
                "statements": "[01:49:57][Yann LeCun][Yeah.].[01:49:59][Lex Fridman][Marc Andreessen just tweeted today. Let me do a TL;DR. The conclusion is only startups and open source can avoid the issue that he's highlighting with big tech. He's asking, \u201cCan Big Tech actually field generative AI products?\u201d (1) Ever-escalating demands from internal activists, employee mobs, crazed executives, broken boards, pressure groups, extremist regulators, government agencies, the press, in quotes, \u201cexperts\u201d and everything corrupting the output. (2) Constant risk of generating a bad answer or drawing a bad picture or rendering a bad video who knows what is going to say or do at any moment. (3) Legal exposure, product liability, slander, election law, many other things and so on, anything that makes Congress mad. (4) Continuous attempts to tighten grip on acceptable output, degrade the model, how good it actually is, in terms of usable and pleasant to use and effective and all that kind of stuff. (5) Publicity of bad text, images, video actual puts those examples into the training data for the next version and so on. So he just highlights how difficult this is from all kinds of people being unhappy. He said you can't create a system that makes everybody happy.].[01:51:24][Yann LeCun][Yes.].[01:51:25][Lex Fridman][So if you're going to do the fine-tuning yourself and keep it close source, essentially, the problem there is then trying to minimize the number of people who are going to be unhappy.].[01:51:36][Yann LeCun][Yep.].[01:51:38][Lex Fridman][You're saying that almost impossible to do, and there are better ways to do open source].[01:51:45][Yann LeCun][Basically. Yeah. Mark is right about a number of things that you list that indeed scare large companies. Certainly, congressional investigations is one of them, legal liability, making things that get people to hurt themselves or hurt others. Big companies are really careful about not producing things of this type because they don't want to hurt anyone, first of all, and then second, they want to preserve their business. So it's essentially impossible for systems like this that can inevitably formulate political opinions, and opinions about various things that may be political or not, but that people may disagree about, about moral issues and questions about religion and things like that or cultural issues that people from different communities would disagree with in the first place. So there's only a relatively small number of things that people will agree on are basic principles, but beyond that, if you want those systems to be useful, they will necessarily have to offend a number of people inevitably.].[01:53:09][Lex Fridman][So open source is just better and then you get-].[01:53:11][Yann LeCun][Diversity is better, right?].[01:53:13][Lex Fridman][And open source enables diversity.].[01:53:15][Yann LeCun][That's right. Open source enables diversity.].[01:53:18][Lex Fridman][This can be a fascinating world where if it's true that the open source world, if Meta leads the way and creates this open source foundation model world, governments will have a fine- tuned model and then potentially, people that vote left and right will have their own model and preference to be able to choose and it will potentially divide us even more. But that's on us humans. We get to figure out basically the technology enables humans to human more effectively, and all the difficult ethical questions that humans raise will just leave it up to us to figure that out.].[01:54:02][Yann LeCun][Yeah, there are some limits. The same way there are limits to free speech. There has to be some limit to the kind of stuff that those systems might be authorized to produce, some guardrails. So that's one thing I'd be interested in, which is in the type of architecture that we were discussing before where the output of the system is a result of an inference to satisfy an objective, that objective can include guardrails, and we can put guardrails in open source systems. If we eventually have systems that are built with this blueprint, we can put guardrails in those systems that guarantee that there is a minimum set of guardrails that make the system non-dangerous and non-toxic, et cetera, basic things that everybody would agree on. Then the fine-tuning that people will add or the additional guardrails that people will add will cater to their community, whatever it is.].[01:55:06][Lex Fridman][The fine-tuning will be more about the gray areas of what is hate speech, what is dangerous and all that kind of stuff, but it's the-].[01:55:12][Yann LeCun][Or different value systems.].[01:55:13][Lex Fridman][Still value systems. But still even with the objectives of how to build a bioweapon, for example, I think something you've commented on, or at least there's a paper where a collection of researchers is trying to understand the social impacts of these LLMs. I guess one threshold that's nice is, does the LLM make it any easier than a search would, like a Google search would?].[01:55:39][Yann LeCun][Right. So the increasing number of studies on this seems to point to the fact that it doesn't help. So having an LLM doesn't help you design or build a bioweapon or a chemical weapon if you already have access to a search engine and their library. So the increased information you get or the ease with which you get it doesn't really help you. That's the first thing. The second thing is, it's one thing to have a list of instructions of how to make a chemical weapon, for example, a bioweapon. It's another thing to actually build it, and it's much harder than you might think, and then LLM will not help you with that.].[01:56:25][Yann LeCun][In fact, nobody in the world, not even countries used bioweapons because most of the time they have no idea how to protect their own populations against it. So it's too dangerous, actually, to ever use, and it's, in fact, banned by international treaties. Chemical weapons is different. It's also banned by treaties, but it's the same problem. It's difficult to use in situations that doesn't turn against the perpetrators, but we could ask Elon Musk. I can give you a very precise list of instructions of how you build a rocket engine. Even if you have a team of 50 engineers that are really experienced building it, you're still going to have to blow up a dozen of them before you get one that works. It's the same with chemical weapons or bioweapons or things like this, it requires expertise in the real world that the LLM is not going to help you with.].[01:57:25][Lex Fridman][It requires even the common sense expertise that we've been talking about, which is how to take language-based instructions and materialize them in the physical world requires a lot of knowledge that's not in the instructions.].[01:57:41][Yann LeCun][Yeah, exactly. A lot of biologists have posted on this actually, in response to those things saying, \u201cDo you realize how hard it is to actually do the lab work?\u201d Like, \u201cNo, this is not trivial.\u201d]."
            },
            {
                "title": "Llama 3",
                "statements": "[01:57:51][Lex Fridman][Yeah, and Hans Moravec comes to light once again. Just to linger on LLaMA, Marc announced that LLaMA 3 is coming out eventually. I don't think there's a release date, but what are you most excited about? First of all, LLaMA 2 that's already out there and maybe the future a LLaMA 3, 4, 5, 6, 10, just the future of the open source under Meta?].[01:58:17][Yann LeCun][Well, a number of things. So there's going to be various versions of LLaMA that are improvements of previous LLaMAs, bigger, better, multimodal, things like that. Then in future generations, systems that are capable of planning that really understand how the world works, maybe are trained from video, so they have some world model maybe capable of the type of reasoning and planning I was talking about earlier. How long is that going to take? When is the research that is going in that direction going to feed into the product line if you want of LLaMA? I don't know. I can't tell you. There's a few breakthroughs that we have to basically go through before we can get there, but you'll be able to monitor our progress because we publish our research. So last week we published the V-JEPA work, which is a first step towards training systems for video.].[01:59:16][Yann LeCun][Then the next step is going to be world models based on this type of idea training from video. There's similar work at DeepMind also and taking place people, and also at UC Berkeley on world models and video. A lot of people are working on this. I think a lot of good ideas are appearing. My bet is that those systems are going to be JEPA light, they're not going to be generative models, and we'll see what the future will tell. There's really good work, a gentleman called Danijar Hafner who is now DeepMind, who's worked on models of this type that learn representations and then use them for planning or learning tasks by reinforcement training and a lot of work at Berkeley by Pieter Abbeel, Sergey Levine, a bunch of other people of that type I'm collaborating with actually in the context of some grants with my NYU hat.].[02:00:20][Yann LeCun][Then collaboration is also through Meta 'cause the lab at Berkeley is associated with Meta in some way, so with fair. So I think it is very exciting. I haven't been that excited about the direction of machine learning and AI since 10 years ago when Fairway was started. Before that, 30 years ago, we were working, oh, sorry, 35 on combination nets and the early days of neural nets. So I'm super excited because I see a path towards potentially human-level intelligence with systems that can understand the world, remember, plan, reason. There is some set of ideas to make progress there that might have a chance of working, and I'm really excited about this. What I like is that somewhat we get on to a good direction and perhaps succeed before my brain turns to a white sauce or before I need to retire.].[02:01:28][Lex Fridman][Yeah. Yeah. Is it beautiful to you just the amount of GPUs involved, the whole training process on this much compute, just zooming out, just looking at earth and humans together have built these computing devices and are able to train this one brain, then we then open source, like giving birth to this open source brain trained on this gigantic compute system, there's just the details of how to train on that, how to build the infrastructure and the hardware, the cooling, all of this kind of stuff, or are you just still that most of your excitement is in the theory aspect of it, meaning the software?].[02:02:19][Yann LeCun][I used to be a hardware guy many years ago.].[02:02:21][Lex Fridman][Yes. Yes, that's right.].[02:02:22][Yann LeCun][Decades ago.].[02:02:23][Lex Fridman][Hardware has improved a little bit. Changed-].[02:02:26][Yann LeCun][A little bit.].[02:02:27][Lex Fridman][... a little bit, yeah.].[02:02:28][Yann LeCun][Certainly, scale is necessary but not sufficient.].[02:02:32][Lex Fridman][Absolutely.].[02:02:32][Yann LeCun][So we certainly need competition. We're still far in terms of compute power from what we would need to match the compute power of the human brain. This may occur in the next couple of decades, but we're still some ways away. Certainly, in terms of power efficiency, we're really far, so there's a lot of progress to make in hardware. Right now, a lot of the progress is, there's a bit coming from silicon technology, but a lot of it coming from architectural innovation and quite a bit coming from more efficient ways of implementing the architectures that have become popular, basically combination of transformers and com nets, and so there's still some ways to go until we are going to saturate. We're going to have to come up with new principles, new fabrication technology, new basic components perhaps based on different principles and classical digital [inaudible 02:03:41]].[02:03:42][Lex Fridman][Interesting. So you think in order to build AMI, we potentially might need some hardware innovation too.].[02:03:52][Yann LeCun][Well, if we want to make it ubiquitous, yeah, certainly, 'cause we're going to have to reduce the power consumption. A GPU today is half a kilowatt to a kilowatt. Human brain is about 25 watts, and a GPU is way below the power of the human brain. You need something like 100,000 or a million to match it, so we are off by a huge factor here.]."
            },
            {
                "title": "AGI",
                "statements": "[02:04:21][Lex Fridman][You often say that a GI is not coming soon, meaning not this year, not the next few years, potentially farther away. What's your basic intuition behind that?].[02:04:35][Yann LeCun][So first of all, it's not going to be an event. The idea somehow, which is popularized by science fiction and Hollywood, that somehow somebody is going to discover the secret to AGI or human-level AI or AMI, whatever you want to call it, and then turn on a machine and then we have AGI, that's just not going to happen. It's not going to be an event. It's going to be gradual progress. Are we going to have systems that can learn from video how the world works and learn good representations? Yeah. Before we get them to the scale and performance that we observe in humans it's going to take quite a while. It's not going to happen in one day. Are we going to get systems that can have large amount of associated memory so they can remember stuff? Yeah, but same, it's not going to happen tomorrow. There is some basic techniques that need to be developed. We have a lot of them, but to get this to work together with a full system is another story.].[02:05:37][Yann LeCun][Are we going to have systems that can reason and plan perhaps along the lines of objective-driven AI architectures that I described before? Yeah, but before we get this to work properly, it's going to take a while. Before we get all those things to work together, and then on top of this, have systems that can learn hierarchical planning, hierarchical representations, systems that can be configured for a lot of different situation at hand, the way the human brain can, all of this is going to take at least a decade and probably much more because there are a lot of problems that we're not seeing right now that we have not encountered, so we don't know if there is an easy solution within this framework. So it's not just around the corner. I've been hearing people for the last 12, 15 years claiming that AGI is just around the corner and being systematically wrong. I knew they were wrong when they were saying it. I called their bullshit.].[02:06:38][Lex Fridman][First of all, from the birth of the term artificial intelligence, there has been a eternal optimism that's perhaps unlike other technologies. Is it a Moravec's paradox, the explanation for why people are so optimistic about AGI?].[02:06:57][Yann LeCun][Don't think it's just Moravec's paradox. Moravec's paradox is a consequence of realizing that the world is not as easy as we think. So first of all, intelligence is not a linear thing that you can measure with a scale or with a single number. Can you say that humans are smarter than orangutans? In some ways, yes, but in some ways, orangutans are smarter than humans in a lot of domains that allows them to survive in the forest, for example.].[02:07:26][Lex Fridman][So IQ is a very limited measure of intelligence. Human intelligence is bigger than what IQ, for example, measures.].[02:07:33][Yann LeCun][Well, IQ can measure approximately something for humans, but because humans come in relatively uniform form, right?].[02:07:49][Lex Fridman][Yeah.].[02:07:50][Yann LeCun][But it only measures one type of ability that maybe relevant for some tasks but not others. But then if you were talking about other intelligent entities for which the basic things that are easy to them is very different, then it doesn't mean anything. So intelligence is a collection of skills and an ability to acquire new skills efficiently. The collection of skills that a particular intelligent entity possess or is capable of learning quickly is different from the collection of skills of another one. Because it's a multidimensional thing, the set of skills is a high dimensional space, you can't measure, you cannot compare two things as to whether one is more intelligent than the other. It's multidimensional.]."
            },
            {
                "title": "AI doomers",
                "statements": "[02:08:48][Lex Fridman][So you push back against what are called AI doomers a lot. Can you explain their perspective and why you think they're wrong?].[02:08:59][Yann LeCun][Okay, so AI doomers imagine all kinds of catastrophe scenarios of how AI could escape or control and basically kill us all, and that relies on a whole bunch of assumptions that are mostly false. So the first assumption is that the emergence of super intelligence is going to be an event, that at some point we're going to figure out the secret and we'll turn on a machine that is super intelligent, and because we'd never done it before, it's going to take over the world and kill us all. That is false. It's not going to be an event. We're going to have systems that are as smart as a cat, have all the characteristics of human-level intelligence, but their level of intelligence would be like a cat or a parrot maybe or something. Then we're going to work our way up to make those things more intelligent. As we make them more intelligent, we're also going to put some guardrails in them and learn how to put some guardrails so they behave properly.].[02:10:03][Yann LeCun][It's not going to be one effort, that it's going to be lots of different people doing this, and some of them are going to succeed at making intelligent systems that are controllable and safe and have the right guardrails. If some other goes rogue, then we can use the good ones to go against the rogue ones. So it's going to be my smart AI police against your rogue AI. So it's not going to be like we're going to be exposed to a single rogue AI that's going to kill us all. That's just not happening. Now, there is another fallacy, which is the fact that because the system is intelligent, it necessarily wants to take over. There is several arguments that make people scared of this, which I think are completely false as well.].[02:10:48][Yann LeCun][So one of them is in nature, it seems to be that the more intelligent species otherwise end up dominating the other and even distinguishing the others sometimes by design, sometimes just by mistake. So there is thinking by which you say, \u201cWell, if AI systems are more intelligent than us, surely they're going to eliminate us, if not by design, simply because they don't care about us,\u201d and that's just preposterous for a number of reasons. First reason is they're not going to be a species. They're not going to be a species that competes with us. They're not going to have the desire to dominate because the desire to dominate is something that has to be hardwired into an intelligent system. It is hardwired in humans. It is hardwired in baboons, in chimpanzees, in wolves, not in orangutans. The species in which this desire to dominate or submit or attain status in other ways is specific to social species. Non-social species like orangutans don't have it, and they are as smart as we are, almost, right?].[02:12:09][Lex Fridman][To you, there's not significant incentive for humans to encode that into the AI systems, and to the degree they do, there'll be other AIs that punish them for it, I'll compete them over it.].[02:12:23][Yann LeCun][Well, there's all kinds of incentive to make AI systems submissive to humans.].[02:12:26][Lex Fridman][Right.].[02:12:27][Yann LeCun][Right? This is the way we're going to build them. So then people say, \u201cOh, but look at LLMs. LLMs are not controllable,\u201d and they're right. LLMs are not controllable. But objectively-driven AI, so systems that derive their answers by optimization of an objective means they have to optimize this objective, and that objective can include guardrails. One guardrail is, obey humans. Another guardrail is, don't obey humans if it's hurting other humans within limits.].[02:12:57][Lex Fridman][Right. I've heard that before somewhere, I don't remember-].[02:12:59][Yann LeCun][Yes, maybe in a book.].[02:13:01][Lex Fridman][Yeah, but speaking of that book, could there be unintended consequences also from all of this?].[02:13:09][Yann LeCun][No, of course. So this is not a simple problem. Designing those guardrails so that the system behaves properly is not going to be a simple issue for which there is a silver bullet for which you have a mathematical proof that the system can be safe. It's going to be a very progressive, iterative design system where we put those guardrails in such a way that the system behave properly. Sometimes they're going to do something that was unexpected because the guardrail wasn't right and we're dd correct them so that they do it right. The idea somehow that we can't get it slightly wrong because if we get it slightly wrong, we'll die is ridiculous. We are just going to go progressively. It is just going to be, the analogy I've used many times is turbojet design. How did we figure out how to make turbojet so unbelievably reliable?].[02:14:07][Yann LeCun][Those are incredibly complex pieces of hardware that run at really high temperatures for 20 hours at a time sometimes, and we can fly halfway around the world on a two-engine jetliner at near the speed of sound. Like how incredible is this? It's just unbelievable. Did we do this because we invented a general principle of how to make turbojets safe? No, it took decades to fine tune the design of those systems so that they were safe. Is there a separate group within General Electric or Snecma or whatever that is specialized in turbojet safety? No. The design is all about safety, because a better turbojet is also a safer turbojet, so a more reliable one. It's the same for AI. Do you need specific provisions to make AI safe? No, you need to make better AI systems, and they will be safe because they are designed to be more useful and more controllable.].[02:15:16][Lex Fridman][So let's imagine a system, AI system that's able to be incredibly convincing and can convince you of anything. I can at least imagine such a system, and I can see such a system be weapon like because it can control people's minds. We're pretty gullible. We want to believe a thing, and you can have an AI system that controls it and you could see governments using that as a weapon. So do you think if you imagine such a system, there's any parallel to something like nuclear weapons?].[02:15:53][Yann LeCun][No.].[02:15:56][Lex Fridman][Why is that technology different? So you're saying there's going to be gradual development?].[02:16:01][Yann LeCun][Yeah.].[02:16:03][Lex Fridman][It might be-].[02:16:00][Lex Fridman][Gradual development is going to be, it might be rapid, but there'll be iterative and then we'll be able to respond and so on.].[02:16:09][Yann LeCun][So that AI system designed by Vladimir Putin or whatever, or his minions is going to be talking to, trying to talk to every American to convince them to vote for-].[02:16:25][Lex Fridman][Whoever.].[02:16:25][Yann LeCun][... Whoever pleases Putin.].[02:16:28][Lex Fridman][Sure.].[02:16:30][Yann LeCun][Or whatever, or rile people up against each other as they've been trying to do. They're not going to be talking to you, they're going to be talking to your AI assistant, which is going to be as smart as theirs. Because as I said, in the future, every single one of your interaction with the digital world will be mediated by your AI assistant. So the first thing you're going to ask, is this a scam? Is this thing telling me the truth? It's not even going to be able to get to you because it's only going to talk to your AI system or your AI system. It's going to be like a spam filter. You're not even seeing the email, the spam email. It's automatically put in a folder that you never see. It's going to be the same thing. That AI system that tries to convince you of something is going to be talking to AI assistant, which is going to be at least as smart as it, and it's going to say, \u201cThis is spam.\u201d It's not even going to bring it to your attention.].[02:17:32][Lex Fridman][So to you, it's very difficult for any one AI system to take such a big leap ahead to where it can convince even the other AI systems. There's always going to be this kind of race where nobody's way ahead.].[02:17:46][Yann LeCun][That's the history of the world. History of the world is whenever there is a progress someplace, there is a countermeasure and it's a cat and mouse game.].[02:17:58][Lex Fridman][Mostly yes, but this is why nuclear weapons are so interesting because that was such a powerful weapon that it mattered who got it first. That you could imagine Hitler, Stalin, Mao getting the weapon first, and that having a different kind of impact on the world than the United States getting the weapon first. But to you, nuclear weapons, you don't imagine a breakthrough discovery and then Manhattan Project-like effort for AI?].[02:18:35][Yann LeCun][No. No, as I said, it's not going to be an event. It's going to be continuous progress. And whenever one breakthrough occurs, it's going to be widely disseminated really quickly.].[02:18:48][Lex Fridman][Yeah.].[02:18:48][Yann LeCun][Probably first within industry. This is not a domain where government or military organizations are particularly innovative and they're in fact way behind. And so this is going to come from industry and this kind of information disseminates extremely quickly. We've seen this over the last few years where you have a new ... Even take AlphaGo, this was reproduced within three months even without particularly detailed information, right?].[02:19:18][Lex Fridman][Yeah. This is an industry that's not good at secrecy. But people [inaudible 02:19:22]-].[02:19:21][Yann LeCun][No. But even if there is, just the fact that you know that something is possible makes you realize that it's worth investing the time to actually do it. You may be the second person to do it, but you'll do it. And same for all the innovations of self supervision in transformers, decoder only architectures, LLMS. Those things, you don't need to know exactly the details of how they work to know that it's possible because it's deployed and then it's getting reproduced. And then people who work for those companies move. They go from one company to another and the information disseminates. What makes the success of the US tech industry and Silicon Valley in particular is exactly that, is because the information circulates really, really quickly and disseminates very quickly. And so the whole region is ahead because of that circulation of information.].[02:20:24][Lex Fridman][Maybe just to linger on the psychology of AI doomers, you give, in the classic Yann LeCun way, a pretty good example of just when a new technology comes to be, you say engineer says, \u201cI invented this new thing. I call it a ball pen.\u201d And then the Twitter sphere responds, \u201cOMG people could write horrible things with it, like misinformation, propaganda, hate speech. Ban it now.\u201d Then writing doomers come in, akin to the AI doomers, \u201cImagine if everyone can get a ball pen. This could destroy society. There should be a law against using ball pen to write hate speech, regulate ball pens now.\u201d And then the pencil industry mogul says, \u201cYeah, ball pens are very dangerous. Unlike pencil writing, which is erasable, ball pen writing stays forever. Government should require a license for a pen manufacturer.\u201d This does seem to be part of human psychology when it comes up against new technology. What deep insights can you speak to about this?].[02:21:37][Yann LeCun][Well, there is a natural fear of new technology and the impact it can have in society. And people have instinctive reaction to the world they know being threatened by major transformations that are either cultural phenomena or technological revolutions. And they fear for their culture, they fear for their job, they fear for the future of their children and their way of life. So any change is feared. And you see this along history, any technological revolution or cultural phenomenon was always accompanied by groups or reaction in the media that basically attributed all the current problems of society to that particular change. Electricity was going to kill everyone at some point. The train was going to be a horrible thing because you can't breathe past 50 kilometers an hour. And so there's a wonderful website called the Pessimist Archive.].[02:22:56][Lex Fridman][It's great.].[02:22:57][Yann LeCun][Which has all those newspaper clips of all the horrible things people imagine would arrive because of either a technological innovation or a cultural phenomenon, just wonderful examples of jazz or comic books being blamed for unemployment or young people not wanting to work anymore and things like that. And that has existed for centuries and it's knee-jerk reactions. The question is do we embrace change or do we resist it? And what are the real dangers as opposed to the imagined ones?].[02:23:51][Lex Fridman][So people worry about, I think one thing they worry about with big tech, something we've been talking about over and over, but I think worth mentioning again, they worry about how powerful AI will be and they worry about it being in the hands of one centralized power of just a handful of central control. And so that's the skepticism with big tech you make, these companies can make a huge amount of money and control this technology, and by so doing take advantage, abuse the little guy in society.].[02:24:29][Yann LeCun][Well, that's exactly why we need open source platforms.].[02:24:31][Lex Fridman][Yeah, I just wanted to nail the point home more and more.].[02:24:37][Yann LeCun][Yes.]."
            },
            {
                "title": "Joscha Bach",
                "statements": "[02:24:38][Lex Fridman][So let me ask you on your, like I said, you do get a little bit flavorful on the internet. Joscha Bach tweeted something that you LOL'd at in reference to HAL 9,000. Quote, \u201cI appreciate your argument and I fully understand your frustration, but whether the pod bay doors should be opened or closed is a complex and nuanced issue.\u201d So you're at the head of Meta AI. This is something that really worries me, that our AI overlords will speak down to us with corporate speak of this nature, and you resist that with your way of being. Is this something you can just comment on, working at a big company, how you can avoid the over fearing, I suppose, through caution create harm?].[02:25:41][Yann LeCun][Yeah. Again, I think the answer to this is open source platforms and then enabling a widely diverse set of people to build AI assistance that represent the diversity of cultures, opinions, languages, and value systems across the world so that you're not bound to just be brainwashed by a particular way of thinking because of a single AI entity. So, I think it's a really, really important question for society. And the problem I'm seeing is that, which is why I've been so vocal and sometimes a little sardonic about it-].[02:26:25][Lex Fridman][Never stop. Never stop, Yann. We love it.].[02:26:29][Yann LeCun][... is because I see the danger of this concentration of power through proprietary AI systems as a much bigger danger than everything else. That if we really want diversity of opinion AI systems, that in the future where we'll all be interacting through AI systems, we need those to be diverse for the preservation of diversity of ideas and creed and political opinions and whatever, and the preservation of democracy. And what works against this is people who think that for reasons of security, we should keep the AI systems under lock and key because it's too dangerous to put it in the hands of everybody, because it could be used by terrorists or something. That would lead to potentially a very bad future in which all of our information diet is controlled by a small number of companies through proprietary systems.].[02:27:42][Lex Fridman][So you trust humans with this technology to build systems that are on the whole good for humanity.].[02:27:53][Yann LeCun][Isn't that what democracy and free speech is all about?].[02:27:56][Lex Fridman][I think so.].[02:27:57][Yann LeCun][Do you trust institutions to do the right thing?].[02:27:59][Lex Fridman][Sure.].[02:28:00][Yann LeCun][Do you trust people to do the right thing? And yeah, there's bad people who are going to do bad things, but they're not going to have superior technology to the good people. So then it's going to be my good AI against your bad AI, right? There's the examples that we were just talking about of maybe some rogue country will build some AI system that's going to try to convince everybody to go into a civil war or something or elect a favorable ruler, but then they will have to go past our AI systems.].[02:28:35][Lex Fridman][Right. An AI system with a strong Russian accent will be trying to convince our-].[02:28:40][Yann LeCun][And doesn't put any articles in their sentences.]."
            },
            {
                "title": "Humanoid robots",
                "statements": "[02:28:45][Lex Fridman][Well, it'll be at the very least, absurdly comedic. Okay. So since we talked about the physical reality, I'd love to ask your vision of the future with robots in this physical reality. So many of the kinds of intelligence that you've been speaking about would empower robots to be more effective collaborators with us humans. So since Tesla's Optimus team has been showing us some progress on humanoid robots, I think it really reinvigorated the whole industry that I think Boston Dynamics has been leading for a very, very long time. So now there's all kinds of companies Figure AI, obviously Boston Dynamics.].[02:29:30][Yann LeCun][Unitree.].[02:29:30][Lex Fridman][Unitree, but there's a lot of them.].[02:29:33][Yann LeCun][There's a few of them.].[02:29:33][Lex Fridman][It's great. It's great. I love it. So do you think there'll be millions of humanoid robots walking around soon?].[02:29:44][Yann LeCun][Not soon, but it's going to happen. The next decade I think is going to be really interesting in robots, the emergence of the robotics industry has been in the waiting for 10, 20 years without really emerging other than for pre-program behavior and stuff like that. And the main issue is, again, the Moravec paradox, how do we get those systems to understand how the world works and plan actions? And so we can do it for really specialized tasks. And the way Boston Dynamics goes about it is basically with a lot of handcrafted dynamical models and careful planning in advance, which is very classical robotics with a lot of innovation, a little bit of perception, but it's still not, they can't build a domestic robot.].[02:30:41][Yann LeCun][We're still some distance away from completely autonomous level five driving, and we're certainly very far away from having level five autonomous driving by a system that can train itself by driving 20 hours like any 17-year-old. So until we have, again, world models, systems that can train themselves to understand how the world works, we're not going to have significant progress in robotics. So a lot of the people working on robotic hardware at the moment are betting or banking on the fact that AI is going to make sufficient progress towards that,].[02:31:28][Lex Fridman][And they're hoping to discover a product in it too. Because before you have a really strong world model, there'll be an almost strong world model and people are trying to find a product in a clumsy robot, I suppose, not a perfectly efficient robot. So there's the factory setting where humanoid robots can help automate some aspects of the factory. I think that's a crazy difficult task because of all the safety required and all this kind of stuff. I think in the home is more interesting, but then you start to think, I think you mentioned loading the dishwasher, right?].[02:32:03][Yann LeCun][Yeah.].[02:32:04][Lex Fridman][I suppose that's one of the main problems you're working on.].[02:32:07][Yann LeCun][There's cleaning up, cleaning the house, clearing up the table after a meal.].[02:32:17][Lex Fridman][Sure.].[02:32:18][Yann LeCun][Washing the dishes, all those tasks, cooking. All the tasks that in principle could be automated but are actually incredibly sophisticated, really complicated.].[02:32:28][Lex Fridman][But even just basic navigation around a space full of uncertainty.].[02:32:32][Yann LeCun][That works. You can do this now, navigation is fine.].[02:32:37][Lex Fridman][Well, navigation in a way that's compelling to us humans is a different thing.].[02:32:42][Yann LeCun][Yeah, it's not going to be necessarily ... We have demos actually, because there is a so-called embodied AI group at fair, and they've been not building their own robots, but using commercial robots. And you can tell the robot dog go to the fridge and they can actually open the fridge and they can probably pick up a can in the fridge and stuff like that and bring it to you. So it can navigate, it can grab objects as long as it's been trained to recognize them, which vision systems work pretty well nowadays, but it's not like a completely general robot that would be sophisticated enough to do things like clearing up the dinner table.].[02:33:31][Lex Fridman][To me, that's an exciting future of getting humanoid robots, robots in general in the home more and more, because it gets humans to really directly interact with AI systems in the physical space. And in so doing it allows us to philosophically, psychologically explore our relationships with robots. Going to be really, really, really interesting. So I hope you make progress on the whole JEPA thing soon.].[02:33:54][Yann LeCun][Well, I hope things can work as planned. Again, we've been working on this idea of self supervised running from video for 10 years, and only made significant progress in the last two or three.].[02:34:11][Lex Fridman][And actually you've mentioned that there's a lot of interesting breakage that can happen without having access to a lot of compute. So if you're interested in doing a PhD in this kind of stuff, there's a lot of possibilities still to do innovative work. So what advice would you give to an undergrad that's looking to go to grad school and do a PhD?].[02:34:33][Yann LeCun][Basically, I've listed them already, this idea of how do you train a world model by observation? And you don't have to train necessarily on gigantic data sets. It could turn out to be necessary, to actually train on large data sets, to have emergent properties like we have with other lamps. But I think there is a lot of good ideas that can be done without necessarily scaling up than there is how do you do planning with a learn world model? If the world the system evolves in is not the physical world, but is the world of let's say the internet or some sort of world where an action consists in doing a search in a search engine or interrogating a database or running a simulation or calling a calculator or solving a differential equation, how do you get a system to actually plan a sequence of actions to give the solution to a problem?].[02:35:29][Yann LeCun][And so the question of planning is not just a question of planning physical actions. It could be planning actions to use tools for a dialogue system or for any kind of intelligence system. And there's some work on this, but not a huge amount. Some work at fair, one called Toolformer, which was a couple years ago and some more recent work on planning, but I don't think we have a good solution for any of that. Then there is the question of hierarchical planning. So the example I mentioned of planning a trip from New York to Paris, that's hierarchical, but almost every action that we take involves hierarchical planning in some sense, and we really have absolutely no idea how to do this.].[02:36:20][Yann LeCun][There's zero demonstration of hierarchical planning in AI where the various levels of representations that are necessary have been learned. We can do two level hierarchical planning when we designed the two levels. So for example, you have a dog-like robot, you want it to go from the living room to the kitchen. You can plan a path that avoids the obstacle, and then you can send this to a lower level planner that figures out how to move the legs to follow that trajectories. So that works, but that two level planning is designed by hand.].[02:37:05][Yann LeCun][We specify what the proper levels of abstraction, the representation at each level of abstraction have to be. How do you learn this? How do you learn that hierarchical representation of action plans? With [inaudible 02:37:21] and deep learning, we can train the system to learn hierarchical representations of percepts. What is the equivalent when what you're trying to represent are action plans?].[02:37:30][Lex Fridman][For action plans, yeah. So you want basically a robot dog or humanoid robot that turns on and travels from New York to Paris all by itself.].[02:37:41][Yann LeCun][For example.].[02:37:43][Lex Fridman][It might have some trouble at the TSA.].[02:37:47][Yann LeCun][No, but even doing something fairly simple like a household task, like cooking or something.]."
            },
            {
                "title": "Hope for the future",
                "statements": "[02:37:53][Lex Fridman][Yeah, there's a lot involved. It's a super complex task and once again, we take it for granted. What hope do you have for the future of humanity? We're talking about so many exciting technologies, so many exciting possibilities. What gives you hope when you look out over the next 10, 20, 50, a hundred years? If you look at social media, there's wars going on, there's division, there's hatred, all this kind of stuff that's also part of humanity. But amidst all that, what gives you hope?].[02:38:29][Yann LeCun][I love that question. We can make humanity smarter with AI. AI basically will amplify human intelligence. It's as if every one of us will have a staff of smart AI assistants. They might be smarter than us. They'll do our bidding, perhaps execute a task in ways that are much better than we could do ourselves, because they'd be smarter than us. And so it's like everyone would be the boss of a staff of super smart virtual people. So we shouldn't feel threatened by this any more than we should feel threatened by being the manager of a group of people, some of whom are more intelligent than us. I certainly have a lot of experience with this, of having people working with me who are smarter than me.].[02:39:35][Yann LeCun][That's actually a wonderful thing. So having machines that are smarter than us, that assist us in all of our tasks, our daily lives, whether it's professional or personal, I think would be an absolutely wonderful thing. Because intelligence is the commodity that is most in demand. That's really what I mean. All the mistakes that humanity makes is because of lack of intelligence really, or lack of knowledge, which is related. So making people smarter, we just can only be better. For the same reason that public education is a good thing and books are a good thing, and the internet is also a good thing, intrinsically and even social networks are a good thing if you run them properly.].[02:40:21][Yann LeCun][It's difficult, but you can. Because it helps the communication of information and knowledge and the transmission of knowledge. So AI is going to make humanity smarter. And the analogy I've been using is the fact that perhaps an equivalent event in the history of humanity to what might be provided by generalization of AI assistant is the invention of the printing press. It made everybody smarter, the fact that people could have access to books. Books were a lot cheaper than they were before, and so a lot more people had an incentive to learn to read, which wasn't the case before.].[02:41:14][Yann LeCun][And people became smarter. It enabled the enlightenment. There wouldn't be an enlightenment without the printing press. It enabled philosophy, rationalism, escape from religious doctrine, democracy, science. And certainly without this, there wouldn't have been the American Revolution or the French Revolution. And so we would still be under a feudal regimes perhaps. And so it completely transformed the world because people became smarter and learned about things. Now, it also created 200 years of essentially religious conflicts in Europe because the first thing that people read was the Bible and realized that perhaps there was a different interpretation of the Bible than what the priests were telling them. And so that created the Protestant movement and created the rift. And in fact, the Catholic Church didn't like the idea of the printing press, but they had no choice. And so it had some bad effects and some good effects.].[02:42:32][Yann LeCun][I don't think anyone today would say that the invention of the printing press had a overall negative effect despite the fact that it created 200 years of religious conflicts in Europe. Now, compare this, and I thought I was very proud of myself to come up with this analogy, but realized someone else came with the same idea before me, compare this with what happened in the Ottoman Empire. The Ottoman Empire banned the printing press for 200 years, and he didn't ban it for all languages, only for Arabic. You could actually print books in Latin or Hebrew or whatever in the Ottoman Empire, just not in Arabic.].[02:43:20][Yann LeCun][And I thought it was because the rulers just wanted to preserve the control over the population and the religious dogma and everything. But after talking with the UAE Minister of AI, Omar Al Olama, he told me no, there was another reason. And the other reason was that it was to preserve the corporation of calligraphers. There's an art form, which is writing those beautiful Arabic poems or whatever, religious text in this thing. And it was a very powerful corporation of scribes basically that run a big chunk of the empire, and we couldn't put them out of business. So they banned the printing press in part to protect that business.].[02:44:21][Yann LeCun][Now, what's the analogy for AI today? Who are we protecting by banning AI? Who are the people who are asking that AI be regulated to protect their jobs? And of course, it's a real question of what is going to be the effect of a technological transformation like AI on the job market and the labor market? And there are economists who are much more expert at this than I am, but when I talk to them, they tell us we're not going to run out of the job. This is not going to cause mass unemployment. This is just going to be gradual shift of different professions.].[02:45:02][Yann LeCun][The professions that are going to be hot 10 or 15 years from now, we have no idea today what they're going to be. The same way, if you go back 20 years in the past, who could have thought 20 years ago that the hottest job, even five, 10 years ago, was mobile app developer? Smartphones weren't invented.].[02:45:23][Lex Fridman][Most of the jobs of the future might be in the Metaverse.].[02:45:27][Yann LeCun][Well, it could be, yeah.].[02:45:29][Lex Fridman][But the point is you can't possibly predict. But you're right. You made a lot of strong points. And I believe that people are fundamentally good. And so if AI, especially open source AI, can make them smarter, it just empowers the goodness in humans.].[02:45:48][Yann LeCun][So I share that feeling, I think people are fundamentally good. And in fact, a lot of doomers are doomers because they don't think that people are fundamentally good, and they either don't trust people or they don't trust the institution to do the right thing so that people behave properly.].[02:46:10][Lex Fridman][Well, I think both you and I believe in humanity, and I think I speak for a lot of people in saying thank you for pushing the open source movement, pushing to making both research and AI open source, making it available to people, and also the models themselves, making it open source. So thank you for that. And thank you for speaking your mind in such colorful and beautiful ways on the internet. I hope you never stop. You're one of the most fun people I know and get to be a fan of. So Yann, thank you for speaking to me once again, and thank you for being you.].[02:46:44][Yann LeCun][Thank you, Lex.].[02:46:45][Lex Fridman][Thanks for listening to this conversation with Yann LeCun. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from Arthur C. Clarke. The only way to discover the limits of the possible is to go beyond them, into the impossible. Thank you for listening and hope to see you next time.]."
            }
        ]
    }
]